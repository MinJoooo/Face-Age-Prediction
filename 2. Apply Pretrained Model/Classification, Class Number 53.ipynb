{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26360978",
   "metadata": {},
   "outputs": [],
   "source": [
    "#m$6+\".(RC6fC6H'\n",
    "import csv\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.transforms import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "214803fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: janghanju (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/janghanju/my-test-project/runs/j1yikfro\" target=\"_blank\">ethereal-bird-8</a></strong> to <a href=\"https://wandb.ai/janghanju/my-test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/janghanju/my-test-project/runs/j1yikfro?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f68ae94c2b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"my-test-project\", entity=\"janghanju\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b69a198",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_NUM = 0\n",
    "IS_CUDA = torch.cuda.is_available()\n",
    "#DEVICE  = 'cpu'\n",
    "DEVICE = torch.device('cuda:' + str(GPU_NUM) if IS_CUDA else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db4ca266",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = './train_v3'\n",
    "BATCH_SIZE  = 20\n",
    "\n",
    "LEARNING_RATE  = 0.001\n",
    "L2WEIGHT_DECAY = 0.001\n",
    "EPOCHS = 50\n",
    "\n",
    "SaveModelName = \"Woman_age_test\"\n",
    "\n",
    "wandb.config = {\n",
    "  \"learning_rate\": 0.001,\n",
    "  \"epochs\": 50,\n",
    "  \"batch_size\": 20\n",
    "}\n",
    "\n",
    "#ModelSavePath = \"./Saved_model/\" + SaveModelName + \"/\"\n",
    "#if not os.path.isdir(ModelSavePath):\n",
    "#    os.mkdir(ModelSavePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f0d6eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataManager():\n",
    "    def __init__(self, dataset_dir, batch_size):\n",
    "        self.batch_size  = batch_size\n",
    "        self.dataset_dir = dataset_dir\n",
    "    def Load_Dataset(self):\n",
    "        transform =  transforms.Compose([                               \n",
    "        transforms.Resize([224, 224]),                       \n",
    "        transforms.PILToTensor(),\n",
    "        transforms.ConvertImageDtype(torch.float),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        dataset = ImageFolder(self.dataset_dir, transform=transform)\n",
    "        print(f'Total data length : {len(dataset)}')\n",
    "        test_size = len(dataset)//5\n",
    "        train_size = len(dataset) - test_size\n",
    "\n",
    "        #train_data, val_ds, test_ds = random_split(dataset, [train_size, val_size, test_size])\n",
    "        train_data, test_data = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "        print(f'train data size : {len(train_data)} , test data size :{len(test_data)}')\n",
    "        return train_data, test_data\n",
    "    \n",
    "    def Load_DataLoader(self, train, test):\n",
    "        return DataLoader(train, num_workers=16, batch_size=self.batch_size, shuffle=True, pin_memory=True, drop_last=False), \\\n",
    "                DataLoader(test, num_workers=16, batch_size=self.batch_size, shuffle=True, pin_memory=True, drop_last=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52739cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    " transform =  transforms.Compose([                               \n",
    "        transforms.Resize([224, 224]),                       \n",
    "        transforms.PILToTensor(),\n",
    "        transforms.ConvertImageDtype(torch.float),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        #transforms.ToPILImage(),\n",
    "        ])\n",
    "dataset = ImageFolder('./train_v3', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7d08c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "126fc748",
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet import resnet18, resnet34, resnet50\n",
    "\n",
    "\n",
    "N_CLASSES = 53#18 ~ 70\n",
    "EPOCHS = 80\n",
    "def train_model(checkpoint_dir):\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.mkdir(checkpoint_dir)\n",
    "    \n",
    "    DM = DataManager(DATASET_DIR, BATCH_SIZE)\n",
    "    TRAIN_DATA, TEST_DATA = DM.Load_Dataset()\n",
    "    TRAIN_LOADER, TEST_LOADER = DM.Load_DataLoader(TRAIN_DATA, TEST_DATA)\n",
    "    \n",
    "    MODEL = resnet34()\n",
    "    #MODEL.fc = nn.Linear(MODEL.fc.in_features, N_CLASSES)\n",
    "    MODEL.fc = nn.Linear(MODEL.fc.in_features,1 ) #뒷부분 짤라내기\n",
    "\n",
    "    MODEL = nn.DataParallel(MODEL, output_device=0)\n",
    "    optimizer = optim.Adam(MODEL.parameters(), lr = LEARNING_RATE, weight_decay = L2WEIGHT_DECAY)\n",
    "    #criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
    "    criterion = nn.MSELoss().to(DEVICE)\n",
    "    \n",
    "    MODEL.to(DEVICE)\n",
    "    total_loss = []\n",
    "    total_acc = []\n",
    "  \n",
    "    for epoch in range(1, EPOCHS):\n",
    "        MODEL.train()\n",
    "        #print(f'epoch {epoch} starting')\n",
    "        with tqdm(TRAIN_LOADER, unit='batch') as train_epoch:\n",
    "            for i, (inputs, targets) in enumerate(train_epoch):\n",
    "                #print(inputs.shape)\n",
    "                inputs = inputs.to(DEVICE)\n",
    "                targets = targets.to(DEVICE).to(torch.float32).unsqueeze(1)\n",
    "                outputs = MODEL(inputs).to(torch.float32)\n",
    "                #print(targets[0], outputs[0])\n",
    "                loss = criterion(outputs, targets)#.to(torch.float32)#.to(torch.FloatTensor)#type(torch.FloatTensor)\n",
    "                #print(type(loss))\n",
    "                wandb.log({\"loss\": loss})\n",
    "                wandb.watch(MODEL)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_epoch.set_description(f'Training epoch {epoch}->')\n",
    "        MODEL.eval()\n",
    "        with torch.no_grad():\n",
    "            with tqdm(TEST_LOADER, unit='batch') as test_epoch:\n",
    "                for j, (val_inputs, val_targets) in enumerate(test_epoch):\n",
    "                    #print(val_inputs.shape)\n",
    "                    val_inputs = val_inputs.to(DEVICE)\n",
    "                    \n",
    "                    val_targets = val_targets.to(DEVICE).unsqueeze(1)\n",
    "                    val_outputs = MODEL(val_inputs)\n",
    "                    print(val_targets[0], val_outputs[0])\n",
    "                    val_loss = criterion(val_outputs, val_targets)\n",
    "                    val_targets_np =  val_targets.to('cpu').detach().numpy()\n",
    "                    val_outputs_np = val_outputs.to('cpu').detach().numpy()\n",
    "                    val_loss_mae = abs(val_targets_np - val_outputs_np)\n",
    "                    #val_outputs_np = np.argmax(val_outputs_np, axis =1).reshape(-1,1)\n",
    "                    #val_acc  = metrics.accuracy_score(val_targets_np, val_outputs_np)\n",
    "                    total_loss.append(val_loss.cpu().detach().numpy())\n",
    "                    total_acc.append(np.mean(val_loss_mae))\n",
    "                    test_epoch.set_description(f'Evaluating...->')\n",
    "        total_loss_mean = np.mean(total_loss)\n",
    "        total_acc_mean = np.mean(total_acc)\n",
    "        print(f'loss {total_loss_mean:.3f} | Acc {total_acc_mean:.3f}\\n') \n",
    "        \n",
    "        if epoch % 2 == 0:\n",
    "            print(f'result of epoch :{epoch} saving')\n",
    "            torch.save({\n",
    "            'epoch' : epoch,\n",
    "            'model_state_dict': MODEL.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': total_loss_mean,\n",
    "            'accuracy': total_acc_mean\n",
    "            }, f\"{checkpoint_dir}/last_checkpoint_{epoch}.pth\")\n",
    "\n",
    "        \n",
    "        \n",
    "def evaluate_model(checkpoint_dir):\n",
    "    DM = DataManager(DATASET_DIR, BATCH_SIZE)\n",
    "    TRAIN_DATA, TEST_DATA = DM.Load_Dataset()\n",
    "    TRAIN_LOADER, TEST_LOADER = DM.Load_DataLoader(TRAIN_DATA, TEST_DATA)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
    "    #criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
    "    MODEL = resnet34()\n",
    "    \n",
    "    #MODEL.fc = nn.Linear(MODEL.fc.in_features, N_CLASSES)\n",
    "    MODEL.fc = nn.Linear(MODEL.fc.in_features, 1) \n",
    "    \n",
    "    MODEL = nn.DataParallel(MODEL, output_device=0)\n",
    "    \n",
    "    LOAD_MODEL = True\n",
    "    if LOAD_MODEL:\n",
    "        checkpoint = torch.load(f\"{checkpoint_dir}/last_checkpoint.pth\")\n",
    "        MODEL.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    MODEL.to(DEVICE)\n",
    "    MODEL.eval()\n",
    "    result_pred, result_annotations = [], []\n",
    "    LOSS_TRACE,  LOSS_TRACE_FOR_TEST = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with tqdm(TEST_LOADER, unit='batch') as test_epoch:\n",
    "            for val_inputs, val_targets in test_epoch:\n",
    "                #print(val_inputs.shape, val_targets.shape)#, len(groups))\n",
    "                val_inputs = val_inputs.to(DEVICE)\n",
    "                val_targets = val_targets.to(DEVICE)\n",
    "                val_outputs = MODEL(val_inputs)\n",
    "\n",
    "                val_loss = criterion(val_outputs, val_targets)\n",
    "                val_loss_np = val_loss.cpu().detach().numpy()\n",
    "                LOSS_TRACE_FOR_TEST.append(val_loss_np)\n",
    "\n",
    "                y_pred_test_np  = val_outputs.to('cpu').detach().numpy()\n",
    "                y_pred_test_np  = np.argmax(y_pred_test_np, axis=1).reshape(-1, 1)\n",
    "                y_test_np       = val_targets.to('cpu').detach().numpy().reshape(-1, 1)\n",
    "\n",
    "                result_pred.extend(list(y_pred_test_np))\n",
    "                result_annotations.extend(list(y_test_np))\n",
    "\n",
    "                test_epoch.set_description(f'Evaluating...->')\n",
    "\n",
    "    result_pred_np = np.array(result_pred).reshape(-1, 1)\n",
    "    result_anno_np = np.array(result_annotations).reshape(-1, 1)\n",
    "    print('--------------------------------------------------------------')\n",
    "    ACC_TEST = metrics.accuracy_score(result_anno_np, result_pred_np)\n",
    "    print('Accuracy: ', ACC_TEST)\n",
    "    conf_mat = metrics.confusion_matrix(result_anno_np, result_pred_np)\n",
    "    print(metrics.classification_report(result_anno_np, result_pred_np))\n",
    "    print('Confustion Matrix: ')\n",
    "    print(conf_mat)\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = (N_CLASSES, N_CLASSES)\n",
    "    sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.show()\n",
    "    conf_mat_sum = np.sum(conf_mat, axis=1)\n",
    "    conf_mat_sum = np.reshape(conf_mat_sum, (N_CLASSES, 1))\n",
    "    sns.heatmap(conf_mat/conf_mat_sum, annot=True, fmt='.2%', cmap='Blues')\n",
    "    plt.show()\n",
    "    print('--------------------------------------------------------------\\n\\n')      \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d94aeea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eis/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:127: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.as_tensor(np.asarray(pic))\n"
     ]
    }
   ],
   "source": [
    "transform =  transforms.Compose([                               \n",
    "        transforms.Resize([256, 256]),                       \n",
    "        transforms.PILToTensor(),\n",
    "        transforms.ConvertImageDtype(torch.float),\n",
    "        #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "test = Image.open('./train/18/989.jpg')\n",
    "test = transform(test).unsqueeze(0)\n",
    "MODEL = resnet50()\n",
    "#MODEL.fc = nn.Linear(MODEL.fc.in_features, N_CLASSES)\n",
    "MODEL.fc = nn.Linear(MODEL.fc.in_features, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "809a39f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1217ba27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv2_x): Sequential(\n",
       "    (0): BottleNeck(\n",
       "      (residual_function): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BottleNeck(\n",
       "      (residual_function): Sequential(\n",
       "        (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BottleNeck(\n",
       "      (residual_function): Sequential(\n",
       "        (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (conv3_x): Sequential(\n",
       "    (0): BottleNeck(\n",
       "      (residual_function): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BottleNeck(\n",
       "      (residual_function): Sequential(\n",
       "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BottleNeck(\n",
       "      (residual_function): Sequential(\n",
       "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): BottleNeck(\n",
       "      (residual_function): Sequential(\n",
       "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (conv4_x): Sequential(\n",
       "    (0): BottleNeck(\n",
       "      (residual_function): Sequential(\n",
       "        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BottleNeck(\n",
       "      (residual_function): Sequential(\n",
       "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BottleNeck(\n",
       "      (residual_function): Sequential(\n",
       "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): BottleNeck(\n",
       "      (residual_function): Sequential(\n",
       "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (4): BottleNeck(\n",
       "      (residual_function): Sequential(\n",
       "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (5): BottleNeck(\n",
       "      (residual_function): Sequential(\n",
       "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (conv5_x): Sequential(\n",
       "    (0): BottleNeck(\n",
       "      (residual_function): Sequential(\n",
       "        (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BottleNeck(\n",
       "      (residual_function): Sequential(\n",
       "        (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BottleNeck(\n",
       "      (residual_function): Sequential(\n",
       "        (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78384f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1422]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abe3f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_train\n",
      "Total data length : 6790\n",
      "train data size : 5432 , test data size :1358\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82d4669a6d9949839c134cbea753a03a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/272 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests\n",
    "if __name__ == \"__main__\":\n",
    "    checkpoint_dir = f'test_run'\n",
    "    print(\"test_train\")\n",
    "    train_model(checkpoint_dir)\n",
    "    #evaluate_model(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2d8dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eb64fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Tests\n",
    "if __name__ == \"__main__\":\n",
    "    checkpoint_dir = f'test_run'\n",
    "    print(\"test_train\")\n",
    "    #train_model(checkpoint_dir)\n",
    "    evaluate_model(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e545b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3698db82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7b5c65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab48b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedb0db3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
