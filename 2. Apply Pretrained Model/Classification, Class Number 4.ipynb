{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "441cb283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c21071f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e6e458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet import resnet18, resnet34, resnet50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a92d9fe",
   "metadata": {},
   "source": [
    "for dir in ['youth', 'middle', 'mature', 'old']:\n",
    "    if not os.path.exists('./train_v2/'+dir):\n",
    "        os.mkdir('./train_v2/'+dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0be6d3e",
   "metadata": {},
   "source": [
    "youth = 28 #18~29 \n",
    "\n",
    "mature = 38 \n",
    "\n",
    "middle = 49 #30 ~ 49\n",
    "\n",
    "old = 70 # ~70\n",
    "\n",
    "DATA_DIR = \"./train/\"\n",
    "DES_DIR = \"./train_v2/\"\n",
    "age = 18\n",
    "while(age <= old):\n",
    "    data_dir = f'{DATA_DIR}{str(age)}'\n",
    "    for filename in sorted(os.listdir(data_dir)):\n",
    "        source = data_dir + '/' +filename\n",
    "        if age <= youth:\n",
    "            des = DES_DIR +'youth/'+str(age)+'_'+filename\n",
    "            \n",
    "        elif age > youth and age <= mature:\n",
    "            des = DES_DIR +'mature/'+str(age)+'_'+filename\n",
    "            \n",
    "        elif age > mature and age <= middle:\n",
    "            des = DES_DIR +'middle/'+str(age)+'_'+filename\n",
    "            \n",
    "        else:\n",
    "            des = DES_DIR +'old/'+str(age)+'_'+filename\n",
    "            \n",
    "        shutil.copy(source, des)\n",
    "    print(source, des)\n",
    "        \n",
    "    age = age + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e19af4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17707, 14492, 17074, 7132)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir('./train_v2/youth')), len(os.listdir('./train_v2/middle')) , len(os.listdir('./train_v2/mature')), len(os.listdir('./train_v2/old'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "122839ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = resnet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e98eb454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv2_x): Sequential(\n",
       "    (0): BottleNeck(\n",
       "      (residual_function): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BottleNeck(\n",
       "      (residual_function): Sequential(\n",
       "        (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BottleNeck(\n",
       "      (residual_function): Sequential(\n",
       "        (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (conv3_x): Sequential(\n",
       "    (0): BottleNeck(\n",
       "      (residual_function): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BottleNeck(\n",
       "      (residual_function): Sequential(\n",
       "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BottleNeck(\n",
       "      (residual_function): Sequential(\n",
       "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): BottleNeck(\n",
       "      (residual_function): Sequential(\n",
       "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (conv4_x): Sequential(\n",
       "    (0): BottleNeck(\n",
       "      (residual_function): Sequential(\n",
       "        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BottleNeck(\n",
       "      (residual_function): Sequential(\n",
       "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BottleNeck(\n",
       "      (residual_function): Sequential(\n",
       "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): BottleNeck(\n",
       "      (residual_function): Sequential(\n",
       "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (4): BottleNeck(\n",
       "      (residual_function): Sequential(\n",
       "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (5): BottleNeck(\n",
       "      (residual_function): Sequential(\n",
       "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (conv5_x): Sequential(\n",
       "    (0): BottleNeck(\n",
       "      (residual_function): Sequential(\n",
       "        (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BottleNeck(\n",
       "      (residual_function): Sequential(\n",
       "        (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BottleNeck(\n",
       "      (residual_function): Sequential(\n",
       "        (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23376ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.transforms import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4db8d144",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_NUM = 0\n",
    "IS_CUDA = torch.cuda.is_available()\n",
    "#DEVICE  = 'cpu'\n",
    "DEVICE = torch.device('cuda:' + str(GPU_NUM) if IS_CUDA else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e816a623",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = './train'\n",
    "BATCH_SIZE  = 40\n",
    "\n",
    "LEARNING_RATE  = 0.00008\n",
    "L2WEIGHT_DECAY = 0.001\n",
    "EPOCHS = 50\n",
    "\n",
    "SaveModelName = \"Woman_age_test\"\n",
    "\n",
    "#ModelSavePath = \"./Saved_model/\" + SaveModelName + \"/\"\n",
    "#if not os.path.isdir(ModelSavePath):\n",
    "#    os.mkdir(ModelSavePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a19efe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataManager():\n",
    "    def __init__(self, dataset_dir, batch_size):\n",
    "        self.batch_size  = batch_size\n",
    "        self.dataset_dir = dataset_dir\n",
    "    def Load_Dataset(self):\n",
    "        transform =  transforms.Compose([                               \n",
    "        transforms.Resize([64, 64]),                       \n",
    "        transforms.PILToTensor(),\n",
    "        transforms.ConvertImageDtype(torch.float),\n",
    "        #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        dataset = ImageFolder(self.dataset_dir, transform=transform)\n",
    "        print(f'Total data length : {len(dataset)}')\n",
    "        test_size = len(dataset)//5\n",
    "        train_size = len(dataset) - test_size\n",
    "\n",
    "        #train_data, val_ds, test_ds = random_split(dataset, [train_size, val_size, test_size])\n",
    "        train_data, test_data = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "        print(f'train data size : {len(train_data)} , test data size :{len(test_data)}')\n",
    "        return train_data, test_data\n",
    "    \n",
    "    def Load_DataLoader(self, train, test):\n",
    "        return DataLoader(train, num_workers=16, batch_size=self.batch_size, shuffle=True, pin_memory=True, drop_last=False), \\\n",
    "                DataLoader(test, num_workers=16, batch_size=self.batch_size, shuffle=True, pin_memory=True, drop_last=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c46566e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.resnet import resnet18 as _resnet18\n",
    "\n",
    "\n",
    "N_CLASSES = 53#4#18 ~ 70\n",
    "EPOCHS = 80\n",
    "def train_model(checkpoint_dir):\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.mkdir(checkpoint_dir)\n",
    "    \n",
    "    DM = DataManager(DATASET_DIR, BATCH_SIZE)\n",
    "    TRAIN_DATA, TEST_DATA = DM.Load_Dataset()\n",
    "    TRAIN_LOADER, TEST_LOADER = DM.Load_DataLoader(TRAIN_DATA, TEST_DATA)\n",
    "    \n",
    "    #MODEL = _resnet18(pretrained = True)\n",
    "    MODEL = resnet50()\n",
    "    MODEL.fc = nn.Linear(MODEL.fc.in_features, 1) #뒷부분 짤라내기\n",
    "\n",
    "    MODEL = nn.DataParallel(MODEL, output_device=0)\n",
    "    optimizer = optim.Adam(MODEL.parameters(), lr = LEARNING_RATE, weight_decay = L2WEIGHT_DECAY)\n",
    "    criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
    "    MODEL.to(DEVICE)\n",
    "    total_loss = []\n",
    "    total_acc = []\n",
    "  \n",
    "    for epoch in range(1, EPOCHS):\n",
    "        MODEL.train()\n",
    "        #print(f'epoch {epoch} starting')\n",
    "        with tqdm(TRAIN_LOADER, unit='batch') as train_epoch:\n",
    "            for i, (inputs, targets) in enumerate(train_epoch):\n",
    "                #print(inputs.shape)\n",
    "                inputs = inputs.to(DEVICE)\n",
    "                targets = targets.to(DEVICE)\n",
    "                outputs = MODEL(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_epoch.set_description(f'Training epoch {epoch}->')\n",
    "        MODEL.eval()\n",
    "        with torch.no_grad():\n",
    "            with tqdm(TEST_LOADER, unit='batch') as test_epoch:\n",
    "                for j, (val_inputs, val_targets) in enumerate(test_epoch):\n",
    "                    #print(val_inputs.shape)\n",
    "                    val_inputs = val_inputs.to(DEVICE)\n",
    "                    val_targets = val_targets.to(DEVICE)\n",
    "                    val_outputs = MODEL(val_inputs)\n",
    "                    val_loss = criterion(val_outputs, val_targets)\n",
    "                    val_targets_np =  val_targets.to('cpu').detach().numpy()\n",
    "                    val_outputs_np = val_outputs.to('cpu').detach().numpy()\n",
    "                    val_outputs_np = np.argmax(val_outputs_np, axis =1).reshape(-1,1)\n",
    "                    val_acc  = metrics.accuracy_score(val_targets_np, val_outputs_np)\n",
    "                    total_loss.append(val_loss.cpu().detach().numpy())\n",
    "                    total_acc.append(val_acc)\n",
    "                    test_epoch.set_description(f'Evaluating...->')\n",
    "        total_loss_mean = np.mean(total_loss)\n",
    "        total_acc_mean = np.mean(total_acc)\n",
    "        print(f'loss {total_loss_mean:.3f} | Acc {total_acc_mean:.3f}\\n') \n",
    "        if epoch// 2 == 0:\n",
    "            torch.save({\n",
    "            'epoch' : epoch,\n",
    "            'model_state_dict': MODEL.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': total_loss_mean,\n",
    "            'accuracy': total_acc_mean\n",
    "            }, f\"{checkpoint_dir}/last_checkpoint.pth\")\n",
    "\n",
    "        \n",
    "        \n",
    "def evaluate_model(checkpoint_dir):\n",
    "    DM = DataManager(DATASET_DIR, BATCH_SIZE)\n",
    "    TRAIN_DATA, TEST_DATA = DM.Load_Dataset()\n",
    "    TRAIN_LOADER, TEST_LOADER = DM.Load_DataLoader(TRAIN_DATA, TEST_DATA)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
    "    MODEL = _resnet18(pretrained = False)\n",
    "    MODEL.fc = nn.Linear(MODEL.fc.in_features, N_CLASSES)\n",
    "    MODEL = nn.DataParallel(MODEL, output_device=0)\n",
    "    \n",
    "    LOAD_MODEL = True\n",
    "    if LOAD_MODEL:\n",
    "        checkpoint = torch.load(f\"{checkpoint_dir}/last_checkpoint.pth\")\n",
    "        MODEL.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    MODEL.to(DEVICE)\n",
    "    MODEL.eval()\n",
    "    result_pred, result_annotations = [], []\n",
    "    LOSS_TRACE,  LOSS_TRACE_FOR_TEST = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with tqdm(TEST_LOADER, unit='batch') as test_epoch:\n",
    "            for val_inputs, val_targets in test_epoch:\n",
    "                #print(val_inputs.shape, val_targets.shape)#, len(groups))\n",
    "                val_inputs = val_inputs.to(DEVICE)\n",
    "                val_targets = val_targets.to(DEVICE)\n",
    "                val_outputs = MODEL(val_inputs)\n",
    "\n",
    "                val_loss = criterion(val_outputs, val_targets)\n",
    "                val_loss_np = val_loss.cpu().detach().numpy()\n",
    "                LOSS_TRACE_FOR_TEST.append(val_loss_np)\n",
    "\n",
    "                y_pred_test_np  = val_outputs.to('cpu').detach().numpy()\n",
    "                y_pred_test_np  = np.argmax(y_pred_test_np, axis=1).reshape(-1, 1)\n",
    "                y_test_np       = val_targets.to('cpu').detach().numpy().reshape(-1, 1)\n",
    "\n",
    "                result_pred.extend(list(y_pred_test_np))\n",
    "                result_annotations.extend(list(y_test_np))\n",
    "\n",
    "                test_epoch.set_description(f'Evaluating...->')\n",
    "\n",
    "    result_pred_np = np.array(result_pred).reshape(-1, 1)\n",
    "    result_anno_np = np.array(result_annotations).reshape(-1, 1)\n",
    "    print('--------------------------------------------------------------')\n",
    "    ACC_TEST = metrics.accuracy_score(result_anno_np, result_pred_np)\n",
    "    print('Accuracy: ', ACC_TEST)\n",
    "    conf_mat = metrics.confusion_matrix(result_anno_np, result_pred_np)\n",
    "    print(metrics.classification_report(result_anno_np, result_pred_np))\n",
    "    print('Confustion Matrix: ')\n",
    "    print(conf_mat)\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = (N_CLASSES, N_CLASSES)\n",
    "    sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.show()\n",
    "    conf_mat_sum = np.sum(conf_mat, axis=1)\n",
    "    conf_mat_sum = np.reshape(conf_mat_sum, (N_CLASSES, 1))\n",
    "    sns.heatmap(conf_mat/conf_mat_sum, annot=True, fmt='.2%', cmap='Blues')\n",
    "    plt.show()\n",
    "    print('--------------------------------------------------------------\\n\\n')      \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b412613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4275, 0.4275, 0.4235,  ..., 0.2235, 0.2196, 0.2196],\n",
       "         [0.4275, 0.4275, 0.4235,  ..., 0.2235, 0.2196, 0.2196],\n",
       "         [0.4275, 0.4275, 0.4235,  ..., 0.2196, 0.2157, 0.2157],\n",
       "         ...,\n",
       "         [0.6902, 0.6902, 0.6980,  ..., 0.1451, 0.1451, 0.1451],\n",
       "         [0.7020, 0.7020, 0.6980,  ..., 0.1451, 0.1451, 0.1451],\n",
       "         [0.7059, 0.7059, 0.6980,  ..., 0.1451, 0.1451, 0.1451]],\n",
       "\n",
       "        [[0.4902, 0.4902, 0.4863,  ..., 0.2353, 0.2235, 0.2235],\n",
       "         [0.4902, 0.4902, 0.4863,  ..., 0.2353, 0.2235, 0.2235],\n",
       "         [0.4902, 0.4902, 0.4863,  ..., 0.2314, 0.2196, 0.2196],\n",
       "         ...,\n",
       "         [0.6039, 0.6039, 0.6118,  ..., 0.1412, 0.1451, 0.1451],\n",
       "         [0.6157, 0.6157, 0.6118,  ..., 0.1412, 0.1451, 0.1451],\n",
       "         [0.6196, 0.6196, 0.6118,  ..., 0.1412, 0.1451, 0.1451]],\n",
       "\n",
       "        [[0.4510, 0.4510, 0.4471,  ..., 0.2392, 0.2314, 0.2314],\n",
       "         [0.4510, 0.4510, 0.4471,  ..., 0.2392, 0.2314, 0.2314],\n",
       "         [0.4510, 0.4510, 0.4471,  ..., 0.2353, 0.2275, 0.2275],\n",
       "         ...,\n",
       "         [0.5137, 0.5137, 0.5216,  ..., 0.1451, 0.1529, 0.1529],\n",
       "         [0.5255, 0.5255, 0.5216,  ..., 0.1451, 0.1529, 0.1529],\n",
       "         [0.5294, 0.5294, 0.5216,  ..., 0.1451, 0.1529, 0.1529]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform =  transforms.Compose([                               \n",
    "        transforms.Resize([256, 256]),                       \n",
    "        transforms.PILToTensor(),\n",
    "        transforms.ConvertImageDtype(torch.float),\n",
    "        #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "test = Image.open('./train/18/989.jpg')\n",
    "transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12efb613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_train\n",
      "Total data length : 56405\n",
      "train data size : 45124 , test data size :11281\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-0d0eec5ece46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcheckpoint_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'test_run'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m#evaluate_model(checkpoint_dir)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-9efbaf3f5d35>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(checkpoint_dir)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mMODEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#뒷부분 짤라내기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mMODEL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL2WEIGHT_DECAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, module, device_ids, output_device, dim)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc_device_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconvert_to_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "# Tests\n",
    "if __name__ == \"__main__\":\n",
    "    checkpoint_dir = f'test_run'\n",
    "    print(\"test_train\")\n",
    "    train_model(checkpoint_dir)\n",
    "    #evaluate_model(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5a518d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests\n",
    "if __name__ == \"__main__\":\n",
    "    checkpoint_dir = f'test_run'\n",
    "    print(\"test_train\")\n",
    "    #train_model(checkpoint_dir)\n",
    "    evaluate_model(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be39da7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90988db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
