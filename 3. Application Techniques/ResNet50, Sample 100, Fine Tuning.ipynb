{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'C:/Users/frank/data_analysis/age-classification'\n",
    "path = root_dir + '/archive/train/' #이미지 경로\n",
    "image_folders = os.listdir(path)\n",
    "image_folders.pop(0)\n",
    "image_paths = [path+image_folder for image_folder in image_folders]\n",
    "modified_path = root_dir + '/archive_sample100/train/' #샘플링된 이미지가 저장될 경로\n",
    "modified_image_paths = [modified_path+image_folder for image_folder in image_folders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified_path : archive_sample100. 100개 데이터만 샘플링한 것\n",
    "# 데이터를 바꾸고 싶으면 data_dir에 들어가는 path를 다른 것으로 바꿔주면 됨\n",
    "data_dir = modified_path\n",
    "img_height, img_width = 224, 224\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4983 files belonging to 53 classes.\n",
      "Using 3987 files for training.\n",
      "Found 4983 files belonging to 53 classes.\n",
      "Using 996 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 224, 224, 3)\n",
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preprocess_input = tf.keras.applications.resnet.preprocess_input\n",
    "\n",
    "IMG_SHAPE = (img_height, img_width) + (3,)\n",
    "base_model = tf.keras.applications.resnet.ResNet50(input_shape=IMG_SHAPE,\n",
    "                                            include_top=False,\n",
    "                                            weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 7, 7, 2048)\n"
     ]
    }
   ],
   "source": [
    "for image_batch, label_batch in train_ds:\n",
    "    feature_batch = base_model(image_batch)\n",
    "    print(feature_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 처음엔 base model은 train 안되게끔 하고, 임의로 맨 위층에 추가하는 layer만 train\n",
    "# fine tuning하기 전 last layer를 한 번 train해줘야 한다고 함\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 0\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=IMG_SHAPE)\n",
    "x = preprocess_input(inputs)\n",
    "x = base_model(x, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation='linear')(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=base_learning_rate),\n",
    "              loss='mse',\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "tf.__operators__.getitem (Sl (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "tf.nn.bias_add (TFOpLambda)  (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 23,589,761\n",
      "Trainable params: 2,049\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback함수를 이용해서 epoch 5번마다 checkpoint 생성\n",
    "# 파일 이름에 에포크 번호를 포함시킵니다(`str.format` 포맷)\n",
    "checkpoint_path = \"CP_ResNet50_Sample100_Fine50_2/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# 다섯 번째 에포크마다 가중치를 저장하기 위한 콜백을 만듭니다\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=1, \n",
    "    save_weights_only=True,\n",
    "    save_freq='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(checkpoint_path.format(epoch=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "125/125 [==============================] - ETA: 9:39 - loss: 830.7318 - mae: 25.49 - ETA: 4:07 - loss: 654.6231 - mae: 21.09 - ETA: 4:02 - loss: 607.9945 - mae: 20.35 - ETA: 3:57 - loss: 519.2740 - mae: 18.33 - ETA: 3:56 - loss: 484.7116 - mae: 17.80 - ETA: 3:55 - loss: 452.5436 - mae: 17.20 - ETA: 3:54 - loss: 431.1514 - mae: 16.74 - ETA: 3:54 - loss: 404.3497 - mae: 16.23 - ETA: 3:54 - loss: 384.9977 - mae: 15.86 - ETA: 3:54 - loss: 370.4767 - mae: 15.57 - ETA: 3:55 - loss: 360.0259 - mae: 15.38 - ETA: 3:56 - loss: 342.3027 - mae: 14.94 - ETA: 3:56 - loss: 335.6512 - mae: 14.84 - ETA: 3:56 - loss: 326.6812 - mae: 14.70 - ETA: 3:55 - loss: 317.8501 - mae: 14.52 - ETA: 3:54 - loss: 309.8047 - mae: 14.37 - ETA: 3:53 - loss: 304.9738 - mae: 14.30 - ETA: 3:52 - loss: 301.9004 - mae: 14.26 - ETA: 3:52 - loss: 296.3839 - mae: 14.16 - ETA: 3:51 - loss: 293.6794 - mae: 14.13 - ETA: 3:51 - loss: 284.7080 - mae: 13.87 - ETA: 3:51 - loss: 280.0763 - mae: 13.79 - ETA: 3:51 - loss: 278.1162 - mae: 13.79 - ETA: 3:51 - loss: 274.0337 - mae: 13.72 - ETA: 3:51 - loss: 270.2072 - mae: 13.62 - ETA: 3:51 - loss: 268.0723 - mae: 13.57 - ETA: 3:51 - loss: 264.3645 - mae: 13.47 - ETA: 3:52 - loss: 261.7715 - mae: 13.42 - ETA: 3:53 - loss: 259.7611 - mae: 13.38 - ETA: 3:54 - loss: 257.1732 - mae: 13.32 - ETA: 3:53 - loss: 253.4724 - mae: 13.24 - ETA: 3:52 - loss: 248.9656 - mae: 13.10 - ETA: 3:50 - loss: 246.2292 - mae: 13.03 - ETA: 3:49 - loss: 244.5464 - mae: 12.98 - ETA: 3:47 - loss: 242.5786 - mae: 12.93 - ETA: 3:45 - loss: 241.8112 - mae: 12.91 - ETA: 3:43 - loss: 242.0934 - mae: 12.94 - ETA: 3:40 - loss: 241.5740 - mae: 12.95 - ETA: 3:38 - loss: 241.8114 - mae: 12.97 - ETA: 3:35 - loss: 240.3553 - mae: 12.92 - ETA: 3:33 - loss: 239.4868 - mae: 12.89 - ETA: 3:30 - loss: 238.2934 - mae: 12.87 - ETA: 3:28 - loss: 237.8389 - mae: 12.87 - ETA: 3:25 - loss: 234.8997 - mae: 12.78 - ETA: 3:23 - loss: 233.7918 - mae: 12.74 - ETA: 3:21 - loss: 232.4608 - mae: 12.72 - ETA: 3:18 - loss: 231.0042 - mae: 12.67 - ETA: 3:16 - loss: 229.1782 - mae: 12.61 - ETA: 3:13 - loss: 228.6085 - mae: 12.61 - ETA: 3:10 - loss: 228.4269 - mae: 12.63 - ETA: 3:08 - loss: 228.1330 - mae: 12.63 - ETA: 3:06 - loss: 227.4650 - mae: 12.61 - ETA: 3:03 - loss: 227.1353 - mae: 12.60 - ETA: 3:00 - loss: 226.2991 - mae: 12.57 - ETA: 2:58 - loss: 224.8121 - mae: 12.52 - ETA: 2:55 - loss: 224.4713 - mae: 12.53 - ETA: 2:53 - loss: 223.8796 - mae: 12.51 - ETA: 2:50 - loss: 222.4950 - mae: 12.46 - ETA: 2:48 - loss: 221.7178 - mae: 12.44 - ETA: 2:46 - loss: 221.2163 - mae: 12.43 - ETA: 2:43 - loss: 219.9996 - mae: 12.40 - ETA: 2:41 - loss: 219.6466 - mae: 12.39 - ETA: 2:38 - loss: 218.3724 - mae: 12.35 - ETA: 2:35 - loss: 218.2444 - mae: 12.36 - ETA: 2:33 - loss: 217.0892 - mae: 12.32 - ETA: 2:31 - loss: 215.7852 - mae: 12.29 - ETA: 2:28 - loss: 215.0164 - mae: 12.27 - ETA: 2:26 - loss: 214.9188 - mae: 12.27 - ETA: 2:24 - loss: 214.6107 - mae: 12.27 - ETA: 2:21 - loss: 213.9225 - mae: 12.25 - ETA: 2:18 - loss: 213.1212 - mae: 12.22 - ETA: 2:16 - loss: 212.3858 - mae: 12.20 - ETA: 2:13 - loss: 212.5861 - mae: 12.21 - ETA: 2:11 - loss: 212.4857 - mae: 12.21 - ETA: 2:09 - loss: 212.1074 - mae: 12.20 - ETA: 2:06 - loss: 212.6138 - mae: 12.22 - ETA: 2:04 - loss: 212.4152 - mae: 12.22 - ETA: 2:02 - loss: 212.3034 - mae: 12.22 - ETA: 2:00 - loss: 211.3973 - mae: 12.19 - ETA: 1:58 - loss: 211.0277 - mae: 12.18 - ETA: 1:55 - loss: 210.6983 - mae: 12.17 - ETA: 1:53 - loss: 209.8887 - mae: 12.14 - ETA: 1:50 - loss: 209.7854 - mae: 12.14 - ETA: 1:48 - loss: 209.0232 - mae: 12.11 - ETA: 1:45 - loss: 208.4869 - mae: 12.10 - ETA: 1:43 - loss: 208.4469 - mae: 12.11 - ETA: 1:40 - loss: 208.1602 - mae: 12.10 - ETA: 1:37 - loss: 208.3411 - mae: 12.11 - ETA: 1:35 - loss: 207.7700 - mae: 12.10 - ETA: 1:32 - loss: 207.5853 - mae: 12.09 - ETA: 1:29 - loss: 206.9607 - mae: 12.07 - ETA: 1:27 - loss: 206.2665 - mae: 12.05 - ETA: 1:24 - loss: 205.5886 - mae: 12.03 - ETA: 1:22 - loss: 205.6253 - mae: 12.03 - ETA: 1:19 - loss: 204.9505 - mae: 12.02 - ETA: 1:16 - loss: 204.7811 - mae: 12.01 - ETA: 1:14 - loss: 203.7686 - mae: 11.97 - ETA: 1:11 - loss: 203.4969 - mae: 11.96 - ETA: 1:08 - loss: 203.2196 - mae: 11.95 - ETA: 1:06 - loss: 203.0561 - mae: 11.94 - ETA: 1:03 - loss: 202.7262 - mae: 11.93 - ETA: 1:01 - loss: 202.2111 - mae: 11.91 - ETA: 58s - loss: 201.4675 - mae: 11.8910 - ETA: 56s - loss: 201.1703 - mae: 11.881 - ETA: 53s - loss: 200.7484 - mae: 11.872 - ETA: 50s - loss: 200.5395 - mae: 11.869 - ETA: 48s - loss: 199.9997 - mae: 11.855 - ETA: 45s - loss: 199.4660 - mae: 11.838 - ETA: 42s - loss: 199.8491 - mae: 11.849 - ETA: 40s - loss: 199.5343 - mae: 11.838 - ETA: 37s - loss: 198.9063 - mae: 11.819 - ETA: 34s - loss: 198.4602 - mae: 11.809 - ETA: 32s - loss: 198.1996 - mae: 11.803 - ETA: 29s - loss: 197.7850 - mae: 11.787 - ETA: 26s - loss: 197.1683 - mae: 11.768 - ETA: 24s - loss: 196.8902 - mae: 11.767 - ETA: 21s - loss: 196.5845 - mae: 11.761 - ETA: 18s - loss: 196.2915 - mae: 11.751 - ETA: 16s - loss: 196.3413 - mae: 11.751 - ETA: 13s - loss: 196.1556 - mae: 11.748 - ETA: 10s - loss: 196.0379 - mae: 11.749 - ETA: 8s - loss: 195.5787 - mae: 11.734 - ETA: 5s - loss: 194.8893 - mae: 11.71 - ETA: 2s - loss: 194.8003 - mae: 11.71 - ETA: 0s - loss: 194.4599 - mae: 11.69 - 422s 3s/step - loss: 194.4599 - mae: 11.6983 - val_loss: 161.2169 - val_mae: 10.6416\n",
      "\n",
      "Epoch 00001: saving model to CP_ResNet50_Sample100_Fine50_2\\cp-0001.ckpt\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - ETA: 5:47 - loss: 189.3568 - mae: 12.07 - ETA: 5:42 - loss: 173.5950 - mae: 11.04 - ETA: 5:38 - loss: 177.0851 - mae: 11.11 - ETA: 5:38 - loss: 176.4657 - mae: 11.19 - ETA: 5:38 - loss: 169.2626 - mae: 11.03 - ETA: 5:41 - loss: 153.8668 - mae: 10.42 - ETA: 5:45 - loss: 150.7598 - mae: 10.34 - ETA: 5:45 - loss: 146.6680 - mae: 10.18 - ETA: 5:42 - loss: 148.4897 - mae: 10.27 - ETA: 5:37 - loss: 146.0653 - mae: 10.17 - ETA: 5:32 - loss: 148.7359 - mae: 10.25 - ETA: 5:27 - loss: 150.4973 - mae: 10.34 - ETA: 5:22 - loss: 150.9022 - mae: 10.35 - ETA: 5:17 - loss: 153.6767 - mae: 10.43 - ETA: 5:12 - loss: 153.7563 - mae: 10.46 - ETA: 5:06 - loss: 154.3445 - mae: 10.48 - ETA: 5:02 - loss: 153.7475 - mae: 10.47 - ETA: 4:58 - loss: 155.4730 - mae: 10.53 - ETA: 4:54 - loss: 155.0170 - mae: 10.52 - ETA: 4:51 - loss: 156.2176 - mae: 10.55 - ETA: 4:47 - loss: 156.1163 - mae: 10.51 - ETA: 4:43 - loss: 156.1061 - mae: 10.50 - ETA: 4:40 - loss: 155.9386 - mae: 10.50 - ETA: 4:36 - loss: 156.3713 - mae: 10.50 - ETA: 4:33 - loss: 156.9754 - mae: 10.53 - ETA: 4:31 - loss: 155.9698 - mae: 10.50 - ETA: 4:28 - loss: 156.8087 - mae: 10.54 - ETA: 4:26 - loss: 157.4951 - mae: 10.58 - ETA: 4:24 - loss: 158.9092 - mae: 10.60 - ETA: 4:23 - loss: 158.1789 - mae: 10.56 - ETA: 4:22 - loss: 159.8293 - mae: 10.62 - ETA: 4:22 - loss: 158.5254 - mae: 10.58 - ETA: 4:25 - loss: 158.7144 - mae: 10.59 - ETA: 4:25 - loss: 157.2974 - mae: 10.54 - ETA: 4:24 - loss: 157.4515 - mae: 10.53 - ETA: 4:22 - loss: 156.1183 - mae: 10.48 - ETA: 4:19 - loss: 156.1164 - mae: 10.48 - ETA: 4:16 - loss: 154.9015 - mae: 10.43 - ETA: 4:13 - loss: 155.9919 - mae: 10.47 - ETA: 4:10 - loss: 157.5480 - mae: 10.53 - ETA: 4:06 - loss: 159.2536 - mae: 10.60 - ETA: 4:03 - loss: 160.5688 - mae: 10.65 - ETA: 3:59 - loss: 160.1277 - mae: 10.63 - ETA: 3:56 - loss: 159.3965 - mae: 10.60 - ETA: 3:52 - loss: 158.4625 - mae: 10.57 - ETA: 3:49 - loss: 157.6729 - mae: 10.54 - ETA: 3:45 - loss: 157.6573 - mae: 10.53 - ETA: 3:42 - loss: 157.7949 - mae: 10.54 - ETA: 3:38 - loss: 157.9731 - mae: 10.55 - ETA: 3:35 - loss: 157.2339 - mae: 10.52 - ETA: 3:32 - loss: 157.8557 - mae: 10.56 - ETA: 3:29 - loss: 157.4619 - mae: 10.54 - ETA: 3:25 - loss: 157.0813 - mae: 10.52 - ETA: 3:22 - loss: 156.6418 - mae: 10.51 - ETA: 3:19 - loss: 156.3075 - mae: 10.49 - ETA: 3:16 - loss: 156.2644 - mae: 10.49 - ETA: 3:13 - loss: 155.5075 - mae: 10.46 - ETA: 3:10 - loss: 154.8713 - mae: 10.44 - ETA: 3:07 - loss: 154.0864 - mae: 10.41 - ETA: 3:04 - loss: 153.5186 - mae: 10.40 - ETA: 3:02 - loss: 154.2354 - mae: 10.41 - ETA: 3:00 - loss: 154.0590 - mae: 10.39 - ETA: 2:57 - loss: 153.7496 - mae: 10.38 - ETA: 2:55 - loss: 154.9409 - mae: 10.42 - ETA: 2:52 - loss: 154.6256 - mae: 10.41 - ETA: 2:49 - loss: 154.7137 - mae: 10.42 - ETA: 2:47 - loss: 154.1398 - mae: 10.40 - ETA: 2:43 - loss: 153.7056 - mae: 10.38 - ETA: 2:40 - loss: 153.3248 - mae: 10.37 - ETA: 2:37 - loss: 152.9375 - mae: 10.35 - ETA: 2:34 - loss: 152.9495 - mae: 10.34 - ETA: 2:31 - loss: 153.0058 - mae: 10.35 - ETA: 2:28 - loss: 153.0724 - mae: 10.35 - ETA: 2:25 - loss: 153.2477 - mae: 10.34 - ETA: 2:22 - loss: 153.4317 - mae: 10.36 - ETA: 2:19 - loss: 152.8039 - mae: 10.33 - ETA: 2:16 - loss: 152.8802 - mae: 10.34 - ETA: 2:13 - loss: 153.4044 - mae: 10.37 - ETA: 2:10 - loss: 153.6674 - mae: 10.38 - ETA: 2:07 - loss: 154.1089 - mae: 10.39 - ETA: 2:04 - loss: 154.0483 - mae: 10.38 - ETA: 2:01 - loss: 154.3961 - mae: 10.40 - ETA: 1:58 - loss: 154.3190 - mae: 10.40 - ETA: 1:55 - loss: 154.4256 - mae: 10.40 - ETA: 1:52 - loss: 154.0120 - mae: 10.38 - ETA: 1:50 - loss: 153.6369 - mae: 10.37 - ETA: 1:47 - loss: 153.9700 - mae: 10.38 - ETA: 1:44 - loss: 154.1675 - mae: 10.39 - ETA: 1:41 - loss: 154.4263 - mae: 10.40 - ETA: 1:39 - loss: 154.6156 - mae: 10.41 - ETA: 1:36 - loss: 154.4825 - mae: 10.41 - ETA: 1:34 - loss: 154.9993 - mae: 10.42 - ETA: 1:31 - loss: 154.6888 - mae: 10.41 - ETA: 1:28 - loss: 154.8023 - mae: 10.42 - ETA: 1:26 - loss: 154.4566 - mae: 10.41 - ETA: 1:23 - loss: 153.8910 - mae: 10.39 - ETA: 1:20 - loss: 153.6521 - mae: 10.37 - ETA: 1:17 - loss: 153.7031 - mae: 10.38 - ETA: 1:14 - loss: 153.6540 - mae: 10.37 - ETA: 1:11 - loss: 154.4527 - mae: 10.39 - ETA: 1:08 - loss: 154.4506 - mae: 10.39 - ETA: 1:05 - loss: 154.1084 - mae: 10.37 - ETA: 1:02 - loss: 154.0580 - mae: 10.36 - ETA: 59s - loss: 154.5129 - mae: 10.3797 - ETA: 56s - loss: 155.0414 - mae: 10.396 - ETA: 54s - loss: 154.8108 - mae: 10.387 - ETA: 51s - loss: 154.6292 - mae: 10.383 - ETA: 48s - loss: 154.6342 - mae: 10.386 - ETA: 45s - loss: 154.1897 - mae: 10.370 - ETA: 42s - loss: 154.0726 - mae: 10.364 - ETA: 39s - loss: 154.4605 - mae: 10.383 - ETA: 36s - loss: 153.9565 - mae: 10.361 - ETA: 33s - loss: 154.3758 - mae: 10.376 - ETA: 31s - loss: 154.1273 - mae: 10.366 - ETA: 28s - loss: 154.3614 - mae: 10.371 - ETA: 25s - loss: 154.2341 - mae: 10.367 - ETA: 22s - loss: 154.3103 - mae: 10.372 - ETA: 19s - loss: 153.9461 - mae: 10.357 - ETA: 16s - loss: 153.9172 - mae: 10.358 - ETA: 14s - loss: 153.6009 - mae: 10.348 - ETA: 11s - loss: 153.4594 - mae: 10.344 - ETA: 8s - loss: 153.5274 - mae: 10.347 - ETA: 5s - loss: 153.7440 - mae: 10.35 - ETA: 2s - loss: 153.9214 - mae: 10.35 - ETA: 0s - loss: 153.9874 - mae: 10.36 - 453s 4s/step - loss: 153.9874 - mae: 10.3617 - val_loss: 140.0270 - val_mae: 9.8012\n",
      "\n",
      "Epoch 00002: saving model to CP_ResNet50_Sample100_Fine50_2\\cp-0002.ckpt\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - ETA: 8:15 - loss: 113.2168 - mae: 8.417 - ETA: 7:43 - loss: 130.3709 - mae: 9.312 - ETA: 7:29 - loss: 123.5195 - mae: 9.042 - ETA: 7:12 - loss: 130.8732 - mae: 9.360 - ETA: 6:55 - loss: 130.6030 - mae: 9.378 - ETA: 6:38 - loss: 130.7801 - mae: 9.419 - ETA: 6:23 - loss: 131.8050 - mae: 9.520 - ETA: 6:11 - loss: 136.2796 - mae: 9.775 - ETA: 5:59 - loss: 135.1196 - mae: 9.648 - ETA: 5:52 - loss: 142.4010 - mae: 9.880 - ETA: 5:48 - loss: 142.6907 - mae: 9.871 - ETA: 5:41 - loss: 141.0549 - mae: 9.859 - ETA: 5:33 - loss: 142.9050 - mae: 9.970 - ETA: 5:25 - loss: 140.5827 - mae: 9.844 - ETA: 5:18 - loss: 139.2916 - mae: 9.746 - ETA: 5:12 - loss: 137.2722 - mae: 9.649 - ETA: 5:06 - loss: 142.4264 - mae: 9.863 - ETA: 5:00 - loss: 146.9657 - mae: 10.04 - ETA: 4:55 - loss: 144.9501 - mae: 9.9718 - ETA: 4:50 - loss: 145.8792 - mae: 10.00 - ETA: 4:45 - loss: 146.3342 - mae: 10.02 - ETA: 4:41 - loss: 145.8906 - mae: 10.01 - ETA: 4:37 - loss: 145.3258 - mae: 10.00 - ETA: 4:33 - loss: 142.6373 - mae: 9.8781 - ETA: 4:29 - loss: 144.9629 - mae: 9.935 - ETA: 4:25 - loss: 144.8530 - mae: 9.948 - ETA: 4:23 - loss: 146.8958 - mae: 10.00 - ETA: 4:20 - loss: 146.8859 - mae: 10.02 - ETA: 4:17 - loss: 145.7319 - mae: 9.9869 - ETA: 4:14 - loss: 144.7621 - mae: 9.957 - ETA: 4:11 - loss: 146.3162 - mae: 10.01 - ETA: 4:09 - loss: 145.4564 - mae: 9.9860 - ETA: 4:07 - loss: 145.2425 - mae: 9.956 - ETA: 4:05 - loss: 144.8902 - mae: 9.948 - ETA: 4:03 - loss: 143.4969 - mae: 9.893 - ETA: 4:02 - loss: 143.3576 - mae: 9.884 - ETA: 3:59 - loss: 142.5669 - mae: 9.847 - ETA: 3:57 - loss: 143.0447 - mae: 9.866 - ETA: 3:54 - loss: 142.1894 - mae: 9.839 - ETA: 3:51 - loss: 142.1263 - mae: 9.851 - ETA: 3:48 - loss: 141.5922 - mae: 9.840 - ETA: 3:45 - loss: 142.3772 - mae: 9.858 - ETA: 3:42 - loss: 142.8383 - mae: 9.860 - ETA: 3:39 - loss: 142.3927 - mae: 9.854 - ETA: 3:36 - loss: 142.5988 - mae: 9.868 - ETA: 3:32 - loss: 143.2933 - mae: 9.895 - ETA: 3:29 - loss: 142.6169 - mae: 9.890 - ETA: 3:26 - loss: 142.4941 - mae: 9.886 - ETA: 3:23 - loss: 143.1501 - mae: 9.904 - ETA: 3:20 - loss: 143.0864 - mae: 9.907 - ETA: 3:17 - loss: 142.6051 - mae: 9.890 - ETA: 3:14 - loss: 143.3064 - mae: 9.911 - ETA: 3:11 - loss: 144.7019 - mae: 9.963 - ETA: 3:08 - loss: 144.2978 - mae: 9.940 - ETA: 3:05 - loss: 144.7108 - mae: 9.938 - ETA: 3:02 - loss: 145.6215 - mae: 9.963 - ETA: 2:59 - loss: 145.5872 - mae: 9.967 - ETA: 2:56 - loss: 145.8205 - mae: 9.972 - ETA: 2:53 - loss: 145.6715 - mae: 9.972 - ETA: 2:51 - loss: 145.4949 - mae: 9.948 - ETA: 2:48 - loss: 145.7205 - mae: 9.962 - ETA: 2:46 - loss: 145.3251 - mae: 9.954 - ETA: 2:43 - loss: 144.8806 - mae: 9.938 - ETA: 2:41 - loss: 144.9634 - mae: 9.949 - ETA: 2:38 - loss: 144.7134 - mae: 9.921 - ETA: 2:36 - loss: 145.0564 - mae: 9.925 - ETA: 2:34 - loss: 145.5750 - mae: 9.932 - ETA: 2:32 - loss: 144.4232 - mae: 9.888 - ETA: 2:29 - loss: 144.3237 - mae: 9.887 - ETA: 2:27 - loss: 143.9746 - mae: 9.880 - ETA: 2:25 - loss: 144.9988 - mae: 9.918 - ETA: 2:22 - loss: 144.5279 - mae: 9.898 - ETA: 2:19 - loss: 144.2408 - mae: 9.885 - ETA: 2:17 - loss: 144.6122 - mae: 9.902 - ETA: 2:14 - loss: 144.3519 - mae: 9.894 - ETA: 2:11 - loss: 144.3559 - mae: 9.895 - ETA: 2:08 - loss: 145.0849 - mae: 9.921 - ETA: 2:05 - loss: 144.8986 - mae: 9.918 - ETA: 2:03 - loss: 144.8564 - mae: 9.912 - ETA: 2:00 - loss: 145.4043 - mae: 9.934 - ETA: 1:57 - loss: 145.9771 - mae: 9.952 - ETA: 1:54 - loss: 146.1870 - mae: 9.970 - ETA: 1:51 - loss: 146.1553 - mae: 9.966 - ETA: 1:49 - loss: 145.9753 - mae: 9.949 - ETA: 1:46 - loss: 146.4830 - mae: 9.966 - ETA: 1:43 - loss: 146.4361 - mae: 9.968 - ETA: 1:40 - loss: 146.9786 - mae: 9.986 - ETA: 1:38 - loss: 146.4048 - mae: 9.968 - ETA: 1:35 - loss: 146.1179 - mae: 9.960 - ETA: 1:32 - loss: 146.3208 - mae: 9.966 - ETA: 1:29 - loss: 146.9693 - mae: 9.988 - ETA: 1:27 - loss: 146.5616 - mae: 9.972 - ETA: 1:24 - loss: 146.3055 - mae: 9.965 - ETA: 1:21 - loss: 146.4193 - mae: 9.969 - ETA: 1:19 - loss: 146.4325 - mae: 9.970 - ETA: 1:16 - loss: 146.9618 - mae: 9.992 - ETA: 1:13 - loss: 147.2263 - mae: 10.00 - ETA: 1:11 - loss: 147.1371 - mae: 10.00 - ETA: 1:08 - loss: 147.6800 - mae: 10.01 - ETA: 1:06 - loss: 147.4001 - mae: 10.00 - ETA: 1:03 - loss: 147.6014 - mae: 10.01 - ETA: 1:00 - loss: 147.8259 - mae: 10.02 - ETA: 58s - loss: 147.5054 - mae: 10.0142 - ETA: 55s - loss: 147.2182 - mae: 9.999 - ETA: 52s - loss: 147.4733 - mae: 10.010 - ETA: 50s - loss: 146.8512 - mae: 9.985 - ETA: 47s - loss: 146.4906 - mae: 9.97 - ETA: 44s - loss: 146.7103 - mae: 9.99 - ETA: 42s - loss: 146.9154 - mae: 10.000 - ETA: 39s - loss: 146.3806 - mae: 9.975 - ETA: 36s - loss: 146.4989 - mae: 9.97 - ETA: 34s - loss: 146.5712 - mae: 9.97 - ETA: 31s - loss: 146.5855 - mae: 9.97 - ETA: 28s - loss: 146.4936 - mae: 9.97 - ETA: 26s - loss: 145.9909 - mae: 9.95 - ETA: 23s - loss: 146.3592 - mae: 9.97 - ETA: 20s - loss: 146.4243 - mae: 9.97 - ETA: 18s - loss: 146.4602 - mae: 9.97 - ETA: 15s - loss: 146.5556 - mae: 9.98 - ETA: 13s - loss: 146.0648 - mae: 9.96 - ETA: 10s - loss: 146.1074 - mae: 9.95 - ETA: 7s - loss: 146.0570 - mae: 9.9587 - ETA: 5s - loss: 146.1247 - mae: 9.965 - ETA: 2s - loss: 145.8803 - mae: 9.959 - ETA: 0s - loss: 146.1126 - mae: 9.968 - 414s 3s/step - loss: 146.1126 - mae: 9.9681 - val_loss: 136.4522 - val_mae: 9.6062\n",
      "\n",
      "Epoch 00003: saving model to CP_ResNet50_Sample100_Fine50_2\\cp-0003.ckpt\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - ETA: 5:20 - loss: 158.8909 - mae: 10.74 - ETA: 5:09 - loss: 149.2694 - mae: 10.28 - ETA: 4:59 - loss: 141.0398 - mae: 9.6234 - ETA: 4:55 - loss: 150.7991 - mae: 10.09 - ETA: 4:52 - loss: 149.5136 - mae: 10.11 - ETA: 4:49 - loss: 139.5572 - mae: 9.7302 - ETA: 4:46 - loss: 138.7538 - mae: 9.661 - ETA: 4:43 - loss: 137.1667 - mae: 9.588 - ETA: 4:41 - loss: 138.8055 - mae: 9.600 - ETA: 4:38 - loss: 144.0214 - mae: 9.808 - ETA: 4:36 - loss: 144.8284 - mae: 9.783 - ETA: 4:35 - loss: 145.3840 - mae: 9.823 - ETA: 4:34 - loss: 141.1665 - mae: 9.683 - ETA: 4:32 - loss: 143.7021 - mae: 9.806 - ETA: 4:30 - loss: 141.3511 - mae: 9.725 - ETA: 4:28 - loss: 140.7953 - mae: 9.720 - ETA: 4:27 - loss: 141.8834 - mae: 9.767 - ETA: 4:25 - loss: 143.2958 - mae: 9.782 - ETA: 4:23 - loss: 143.3404 - mae: 9.793 - ETA: 4:22 - loss: 143.3788 - mae: 9.817 - ETA: 4:21 - loss: 143.7298 - mae: 9.802 - ETA: 4:19 - loss: 144.1398 - mae: 9.843 - ETA: 4:17 - loss: 144.9806 - mae: 9.871 - ETA: 4:15 - loss: 145.0987 - mae: 9.858 - ETA: 4:12 - loss: 144.8788 - mae: 9.879 - ETA: 4:09 - loss: 142.6670 - mae: 9.770 - ETA: 4:06 - loss: 141.7139 - mae: 9.749 - ETA: 4:04 - loss: 140.1042 - mae: 9.701 - ETA: 4:01 - loss: 140.0993 - mae: 9.699 - ETA: 3:58 - loss: 138.4034 - mae: 9.631 - ETA: 3:55 - loss: 139.5497 - mae: 9.636 - ETA: 3:53 - loss: 139.7194 - mae: 9.645 - ETA: 3:50 - loss: 139.0420 - mae: 9.611 - ETA: 3:47 - loss: 138.4175 - mae: 9.596 - ETA: 3:45 - loss: 137.3361 - mae: 9.545 - ETA: 3:44 - loss: 139.8925 - mae: 9.631 - ETA: 3:42 - loss: 140.1614 - mae: 9.655 - ETA: 3:41 - loss: 140.5634 - mae: 9.675 - ETA: 3:38 - loss: 139.4708 - mae: 9.631 - ETA: 3:36 - loss: 140.5859 - mae: 9.676 - ETA: 3:34 - loss: 142.1220 - mae: 9.729 - ETA: 3:32 - loss: 141.2979 - mae: 9.682 - ETA: 3:30 - loss: 141.3725 - mae: 9.698 - ETA: 3:29 - loss: 142.4247 - mae: 9.727 - ETA: 3:27 - loss: 141.4799 - mae: 9.688 - ETA: 3:26 - loss: 140.9236 - mae: 9.679 - ETA: 3:25 - loss: 140.5493 - mae: 9.674 - ETA: 3:23 - loss: 140.7040 - mae: 9.689 - ETA: 3:21 - loss: 141.4218 - mae: 9.709 - ETA: 3:18 - loss: 141.0433 - mae: 9.705 - ETA: 3:16 - loss: 140.1899 - mae: 9.681 - ETA: 3:14 - loss: 140.0602 - mae: 9.667 - ETA: 3:11 - loss: 140.9404 - mae: 9.703 - ETA: 3:08 - loss: 140.6173 - mae: 9.700 - ETA: 3:05 - loss: 140.3750 - mae: 9.689 - ETA: 3:02 - loss: 140.5952 - mae: 9.697 - ETA: 2:59 - loss: 140.2307 - mae: 9.690 - ETA: 2:57 - loss: 140.6152 - mae: 9.712 - ETA: 2:54 - loss: 141.0163 - mae: 9.716 - ETA: 2:51 - loss: 141.2097 - mae: 9.716 - ETA: 2:48 - loss: 141.0848 - mae: 9.718 - ETA: 2:45 - loss: 140.8361 - mae: 9.706 - ETA: 2:42 - loss: 141.6907 - mae: 9.736 - ETA: 2:39 - loss: 141.3250 - mae: 9.719 - ETA: 2:37 - loss: 141.2966 - mae: 9.719 - ETA: 2:34 - loss: 141.1178 - mae: 9.715 - ETA: 2:31 - loss: 141.5996 - mae: 9.738 - ETA: 2:28 - loss: 141.6658 - mae: 9.739 - ETA: 2:26 - loss: 141.7014 - mae: 9.735 - ETA: 2:23 - loss: 141.4416 - mae: 9.723 - ETA: 2:20 - loss: 141.1274 - mae: 9.712 - ETA: 2:17 - loss: 140.6726 - mae: 9.687 - ETA: 2:15 - loss: 140.6850 - mae: 9.690 - ETA: 2:12 - loss: 140.4232 - mae: 9.683 - ETA: 2:09 - loss: 140.9680 - mae: 9.700 - ETA: 2:07 - loss: 141.0164 - mae: 9.703 - ETA: 2:04 - loss: 140.9231 - mae: 9.699 - ETA: 2:01 - loss: 141.0054 - mae: 9.704 - ETA: 1:59 - loss: 141.1161 - mae: 9.718 - ETA: 1:56 - loss: 140.7864 - mae: 9.703 - ETA: 1:53 - loss: 140.5640 - mae: 9.700 - ETA: 1:51 - loss: 140.8935 - mae: 9.719 - ETA: 1:48 - loss: 141.2040 - mae: 9.723 - ETA: 1:46 - loss: 141.3464 - mae: 9.738 - ETA: 1:43 - loss: 141.2037 - mae: 9.736 - ETA: 1:41 - loss: 141.1239 - mae: 9.730 - ETA: 1:39 - loss: 140.6744 - mae: 9.702 - ETA: 1:37 - loss: 140.2424 - mae: 9.688 - ETA: 1:34 - loss: 140.1356 - mae: 9.691 - ETA: 1:32 - loss: 140.4534 - mae: 9.695 - ETA: 1:29 - loss: 140.6100 - mae: 9.701 - ETA: 1:27 - loss: 140.9022 - mae: 9.716 - ETA: 1:24 - loss: 141.1918 - mae: 9.730 - ETA: 1:21 - loss: 141.9582 - mae: 9.748 - ETA: 1:19 - loss: 142.2583 - mae: 9.754 - ETA: 1:16 - loss: 142.2853 - mae: 9.751 - ETA: 1:13 - loss: 141.9827 - mae: 9.741 - ETA: 1:11 - loss: 141.3599 - mae: 9.712 - ETA: 1:08 - loss: 141.4397 - mae: 9.717 - ETA: 1:05 - loss: 141.3315 - mae: 9.715 - ETA: 1:02 - loss: 141.5736 - mae: 9.722 - ETA: 1:00 - loss: 141.6452 - mae: 9.729 - ETA: 57s - loss: 141.8732 - mae: 9.738 - ETA: 54s - loss: 141.7545 - mae: 9.73 - ETA: 52s - loss: 141.4765 - mae: 9.72 - ETA: 49s - loss: 141.1052 - mae: 9.71 - ETA: 47s - loss: 140.5176 - mae: 9.68 - ETA: 44s - loss: 140.2639 - mae: 9.68 - ETA: 41s - loss: 140.5140 - mae: 9.69 - ETA: 39s - loss: 140.2845 - mae: 9.68 - ETA: 36s - loss: 140.8131 - mae: 9.70 - ETA: 33s - loss: 141.6598 - mae: 9.73 - ETA: 31s - loss: 141.7564 - mae: 9.73 - ETA: 28s - loss: 141.5333 - mae: 9.72 - ETA: 26s - loss: 141.5088 - mae: 9.72 - ETA: 23s - loss: 141.5252 - mae: 9.72 - ETA: 20s - loss: 141.1944 - mae: 9.71 - ETA: 18s - loss: 141.2806 - mae: 9.71 - ETA: 15s - loss: 141.3509 - mae: 9.72 - ETA: 13s - loss: 141.2034 - mae: 9.72 - ETA: 10s - loss: 141.1633 - mae: 9.72 - ETA: 7s - loss: 141.2579 - mae: 9.7286 - ETA: 5s - loss: 141.3941 - mae: 9.736 - ETA: 2s - loss: 141.4384 - mae: 9.736 - ETA: 0s - loss: 141.2103 - mae: 9.726 - 404s 3s/step - loss: 141.2103 - mae: 9.7268 - val_loss: 133.8126 - val_mae: 9.4779\n",
      "\n",
      "Epoch 00004: saving model to CP_ResNet50_Sample100_Fine50_2\\cp-0004.ckpt\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - ETA: 7:38 - loss: 132.9597 - mae: 9.739 - ETA: 8:34 - loss: 131.9988 - mae: 9.705 - ETA: 9:04 - loss: 151.1831 - mae: 10.32 - ETA: 9:18 - loss: 136.1936 - mae: 9.7416 - ETA: 9:27 - loss: 136.6366 - mae: 9.725 - ETA: 9:14 - loss: 135.4984 - mae: 9.588 - ETA: 9:04 - loss: 129.4950 - mae: 9.452 - ETA: 8:48 - loss: 127.6797 - mae: 9.366 - ETA: 8:29 - loss: 132.0016 - mae: 9.489 - ETA: 8:11 - loss: 135.1398 - mae: 9.643 - ETA: 7:51 - loss: 136.1877 - mae: 9.671 - ETA: 7:33 - loss: 135.4884 - mae: 9.623 - ETA: 7:16 - loss: 139.1465 - mae: 9.740 - ETA: 7:01 - loss: 137.7953 - mae: 9.683 - ETA: 6:47 - loss: 142.5928 - mae: 9.810 - ETA: 6:34 - loss: 144.4141 - mae: 9.907 - ETA: 6:22 - loss: 145.2293 - mae: 9.972 - ETA: 6:12 - loss: 143.1461 - mae: 9.909 - ETA: 6:02 - loss: 143.8055 - mae: 9.949 - ETA: 5:53 - loss: 141.9204 - mae: 9.875 - ETA: 5:45 - loss: 144.5618 - mae: 9.951 - ETA: 5:37 - loss: 145.6739 - mae: 10.00 - ETA: 5:30 - loss: 143.4276 - mae: 9.9214 - ETA: 5:23 - loss: 143.9085 - mae: 9.916 - ETA: 5:17 - loss: 141.9845 - mae: 9.851 - ETA: 5:11 - loss: 140.3220 - mae: 9.783 - ETA: 5:05 - loss: 139.6865 - mae: 9.738 - ETA: 4:59 - loss: 139.7092 - mae: 9.743 - ETA: 4:54 - loss: 137.9633 - mae: 9.670 - ETA: 4:49 - loss: 137.0811 - mae: 9.659 - ETA: 4:44 - loss: 138.5365 - mae: 9.699 - ETA: 4:39 - loss: 138.6259 - mae: 9.698 - ETA: 4:35 - loss: 139.3813 - mae: 9.743 - ETA: 4:30 - loss: 140.7201 - mae: 9.767 - ETA: 4:26 - loss: 140.0357 - mae: 9.732 - ETA: 4:22 - loss: 140.3994 - mae: 9.735 - ETA: 4:18 - loss: 139.8111 - mae: 9.720 - ETA: 4:14 - loss: 140.1928 - mae: 9.718 - ETA: 4:11 - loss: 138.7457 - mae: 9.653 - ETA: 4:08 - loss: 138.8521 - mae: 9.650 - ETA: 4:05 - loss: 137.9429 - mae: 9.603 - ETA: 4:02 - loss: 138.1374 - mae: 9.615 - ETA: 3:59 - loss: 137.4914 - mae: 9.584 - ETA: 3:56 - loss: 136.5411 - mae: 9.549 - ETA: 3:54 - loss: 136.8327 - mae: 9.576 - ETA: 3:51 - loss: 137.2707 - mae: 9.600 - ETA: 3:48 - loss: 138.3975 - mae: 9.631 - ETA: 3:45 - loss: 138.6944 - mae: 9.654 - ETA: 3:41 - loss: 137.9965 - mae: 9.628 - ETA: 3:38 - loss: 136.4727 - mae: 9.556 - ETA: 3:34 - loss: 136.4941 - mae: 9.541 - ETA: 3:31 - loss: 136.7083 - mae: 9.552 - ETA: 3:28 - loss: 136.5413 - mae: 9.551 - ETA: 3:25 - loss: 137.5139 - mae: 9.586 - ETA: 3:21 - loss: 137.0811 - mae: 9.576 - ETA: 3:18 - loss: 137.7611 - mae: 9.604 - ETA: 3:14 - loss: 137.2378 - mae: 9.593 - ETA: 3:11 - loss: 137.2618 - mae: 9.585 - ETA: 3:08 - loss: 137.1042 - mae: 9.576 - ETA: 3:05 - loss: 136.2516 - mae: 9.541 - ETA: 3:01 - loss: 135.9755 - mae: 9.540 - ETA: 2:58 - loss: 135.8932 - mae: 9.529 - ETA: 2:55 - loss: 136.4991 - mae: 9.535 - ETA: 2:52 - loss: 136.4696 - mae: 9.534 - ETA: 2:49 - loss: 137.4542 - mae: 9.562 - ETA: 2:45 - loss: 137.1186 - mae: 9.555 - ETA: 2:42 - loss: 137.2785 - mae: 9.568 - ETA: 2:39 - loss: 137.0332 - mae: 9.559 - ETA: 2:36 - loss: 136.9173 - mae: 9.554 - ETA: 2:33 - loss: 136.5464 - mae: 9.533 - ETA: 2:30 - loss: 136.7124 - mae: 9.534 - ETA: 2:27 - loss: 136.9294 - mae: 9.544 - ETA: 2:24 - loss: 137.1252 - mae: 9.550 - ETA: 2:22 - loss: 137.5377 - mae: 9.562 - ETA: 2:19 - loss: 137.4041 - mae: 9.552 - ETA: 2:16 - loss: 137.0909 - mae: 9.547 - ETA: 2:14 - loss: 138.2465 - mae: 9.584 - ETA: 2:11 - loss: 138.0205 - mae: 9.582 - ETA: 2:08 - loss: 138.0245 - mae: 9.579 - ETA: 2:05 - loss: 138.1182 - mae: 9.585 - ETA: 2:02 - loss: 138.8276 - mae: 9.618 - ETA: 1:59 - loss: 138.5606 - mae: 9.611 - ETA: 1:56 - loss: 138.1799 - mae: 9.599 - ETA: 1:53 - loss: 138.3237 - mae: 9.608 - ETA: 1:50 - loss: 137.9488 - mae: 9.596 - ETA: 1:47 - loss: 137.6842 - mae: 9.588 - ETA: 1:44 - loss: 138.4994 - mae: 9.608 - ETA: 1:42 - loss: 138.3948 - mae: 9.609 - ETA: 1:39 - loss: 138.4541 - mae: 9.616 - ETA: 1:36 - loss: 138.0975 - mae: 9.599 - ETA: 1:33 - loss: 138.0796 - mae: 9.606 - ETA: 1:30 - loss: 138.2307 - mae: 9.615 - ETA: 1:27 - loss: 138.9392 - mae: 9.643 - ETA: 1:24 - loss: 138.5409 - mae: 9.627 - ETA: 1:22 - loss: 139.1065 - mae: 9.645 - ETA: 1:19 - loss: 138.6602 - mae: 9.626 - ETA: 1:16 - loss: 138.7336 - mae: 9.630 - ETA: 1:13 - loss: 138.6154 - mae: 9.632 - ETA: 1:10 - loss: 138.6416 - mae: 9.629 - ETA: 1:08 - loss: 138.9973 - mae: 9.646 - ETA: 1:05 - loss: 139.1711 - mae: 9.650 - ETA: 1:02 - loss: 139.1334 - mae: 9.647 - ETA: 1:00 - loss: 139.1765 - mae: 9.655 - ETA: 57s - loss: 138.8117 - mae: 9.648 - ETA: 55s - loss: 138.9388 - mae: 9.65 - ETA: 52s - loss: 138.9610 - mae: 9.66 - ETA: 49s - loss: 138.9347 - mae: 9.65 - ETA: 46s - loss: 138.7930 - mae: 9.64 - ETA: 44s - loss: 139.2924 - mae: 9.65 - ETA: 41s - loss: 139.2797 - mae: 9.65 - ETA: 38s - loss: 139.2423 - mae: 9.65 - ETA: 35s - loss: 139.3921 - mae: 9.65 - ETA: 33s - loss: 139.3922 - mae: 9.65 - ETA: 30s - loss: 138.9730 - mae: 9.64 - ETA: 27s - loss: 139.3230 - mae: 9.65 - ETA: 24s - loss: 139.3384 - mae: 9.66 - ETA: 21s - loss: 139.5760 - mae: 9.67 - ETA: 19s - loss: 139.3932 - mae: 9.67 - ETA: 16s - loss: 139.2332 - mae: 9.67 - ETA: 13s - loss: 139.2567 - mae: 9.67 - ETA: 10s - loss: 139.3717 - mae: 9.67 - ETA: 8s - loss: 139.4145 - mae: 9.6778 - ETA: 5s - loss: 139.1471 - mae: 9.670 - ETA: 2s - loss: 139.1662 - mae: 9.666 - ETA: 0s - loss: 138.9334 - mae: 9.656 - 421s 3s/step - loss: 138.9334 - mae: 9.6569 - val_loss: 130.3105 - val_mae: 9.3226\n",
      "\n",
      "Epoch 00005: saving model to CP_ResNet50_Sample100_Fine50_2\\cp-0005.ckpt\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - ETA: 5:27 - loss: 159.2164 - mae: 9.136 - ETA: 5:18 - loss: 127.8120 - mae: 8.653 - ETA: 5:14 - loss: 134.6448 - mae: 9.514 - ETA: 5:07 - loss: 133.6369 - mae: 9.399 - ETA: 5:02 - loss: 138.2536 - mae: 9.631 - ETA: 4:59 - loss: 134.7060 - mae: 9.513 - ETA: 4:56 - loss: 134.6336 - mae: 9.520 - ETA: 4:55 - loss: 139.7536 - mae: 9.698 - ETA: 4:53 - loss: 141.6418 - mae: 9.770 - ETA: 4:52 - loss: 139.4077 - mae: 9.740 - ETA: 4:51 - loss: 140.1067 - mae: 9.678 - ETA: 4:51 - loss: 137.4633 - mae: 9.577 - ETA: 4:51 - loss: 137.7534 - mae: 9.606 - ETA: 4:52 - loss: 136.8855 - mae: 9.572 - ETA: 4:53 - loss: 134.7850 - mae: 9.507 - ETA: 4:53 - loss: 132.6440 - mae: 9.407 - ETA: 4:51 - loss: 132.7110 - mae: 9.428 - ETA: 4:48 - loss: 133.2628 - mae: 9.464 - ETA: 4:45 - loss: 131.2180 - mae: 9.383 - ETA: 4:42 - loss: 132.6280 - mae: 9.401 - ETA: 4:38 - loss: 132.1009 - mae: 9.423 - ETA: 4:35 - loss: 131.6982 - mae: 9.428 - ETA: 4:31 - loss: 132.6818 - mae: 9.480 - ETA: 4:28 - loss: 133.7243 - mae: 9.528 - ETA: 4:24 - loss: 133.9281 - mae: 9.526 - ETA: 4:21 - loss: 133.5295 - mae: 9.466 - ETA: 4:17 - loss: 131.2331 - mae: 9.378 - ETA: 4:14 - loss: 129.8236 - mae: 9.332 - ETA: 4:11 - loss: 131.0257 - mae: 9.392 - ETA: 4:07 - loss: 130.1186 - mae: 9.351 - ETA: 4:04 - loss: 129.9622 - mae: 9.325 - ETA: 4:01 - loss: 130.5583 - mae: 9.342 - ETA: 3:58 - loss: 130.5496 - mae: 9.326 - ETA: 3:55 - loss: 130.1078 - mae: 9.309 - ETA: 3:52 - loss: 131.7186 - mae: 9.384 - ETA: 3:49 - loss: 131.2799 - mae: 9.368 - ETA: 3:46 - loss: 131.5910 - mae: 9.379 - ETA: 3:43 - loss: 132.2570 - mae: 9.410 - ETA: 3:41 - loss: 131.1880 - mae: 9.363 - ETA: 3:38 - loss: 130.7752 - mae: 9.343 - ETA: 3:35 - loss: 130.4551 - mae: 9.337 - ETA: 3:33 - loss: 131.6522 - mae: 9.382 - ETA: 3:30 - loss: 131.8589 - mae: 9.389 - ETA: 3:28 - loss: 132.2228 - mae: 9.387 - ETA: 3:25 - loss: 131.7610 - mae: 9.372 - ETA: 3:23 - loss: 132.3710 - mae: 9.379 - ETA: 3:21 - loss: 132.8352 - mae: 9.396 - ETA: 3:19 - loss: 132.6780 - mae: 9.394 - ETA: 3:17 - loss: 132.0437 - mae: 9.377 - ETA: 3:15 - loss: 131.0166 - mae: 9.333 - ETA: 3:12 - loss: 131.8322 - mae: 9.361 - ETA: 3:09 - loss: 132.6524 - mae: 9.394 - ETA: 3:07 - loss: 132.9294 - mae: 9.392 - ETA: 3:04 - loss: 132.8942 - mae: 9.399 - ETA: 3:01 - loss: 132.8798 - mae: 9.388 - ETA: 2:59 - loss: 134.0320 - mae: 9.437 - ETA: 2:56 - loss: 133.2128 - mae: 9.402 - ETA: 2:53 - loss: 133.1644 - mae: 9.410 - ETA: 2:50 - loss: 134.1485 - mae: 9.438 - ETA: 2:48 - loss: 134.2032 - mae: 9.435 - ETA: 2:45 - loss: 133.9777 - mae: 9.426 - ETA: 2:42 - loss: 133.4005 - mae: 9.403 - ETA: 2:40 - loss: 133.6376 - mae: 9.394 - ETA: 2:37 - loss: 133.3169 - mae: 9.384 - ETA: 2:34 - loss: 133.1245 - mae: 9.381 - ETA: 2:31 - loss: 132.6251 - mae: 9.360 - ETA: 2:29 - loss: 132.0076 - mae: 9.337 - ETA: 2:26 - loss: 132.1740 - mae: 9.345 - ETA: 2:24 - loss: 131.5128 - mae: 9.322 - ETA: 2:21 - loss: 131.6708 - mae: 9.331 - ETA: 2:18 - loss: 131.6569 - mae: 9.336 - ETA: 2:16 - loss: 131.8215 - mae: 9.338 - ETA: 2:14 - loss: 132.4891 - mae: 9.356 - ETA: 2:11 - loss: 132.2054 - mae: 9.352 - ETA: 2:09 - loss: 132.3790 - mae: 9.356 - ETA: 2:07 - loss: 132.3920 - mae: 9.360 - ETA: 2:05 - loss: 132.5520 - mae: 9.372 - ETA: 2:02 - loss: 132.7135 - mae: 9.379 - ETA: 2:00 - loss: 133.0019 - mae: 9.392 - ETA: 1:58 - loss: 132.6933 - mae: 9.386 - ETA: 1:55 - loss: 133.0435 - mae: 9.396 - ETA: 1:53 - loss: 133.4342 - mae: 9.415 - ETA: 1:50 - loss: 133.4187 - mae: 9.416 - ETA: 1:48 - loss: 133.7155 - mae: 9.432 - ETA: 1:45 - loss: 134.5632 - mae: 9.464 - ETA: 1:43 - loss: 134.2859 - mae: 9.454 - ETA: 1:40 - loss: 133.8083 - mae: 9.434 - ETA: 1:37 - loss: 133.4929 - mae: 9.419 - ETA: 1:34 - loss: 133.5912 - mae: 9.431 - ETA: 1:32 - loss: 134.3868 - mae: 9.455 - ETA: 1:29 - loss: 134.6972 - mae: 9.468 - ETA: 1:26 - loss: 135.3144 - mae: 9.491 - ETA: 1:24 - loss: 135.7438 - mae: 9.509 - ETA: 1:21 - loss: 135.3247 - mae: 9.488 - ETA: 1:18 - loss: 135.7430 - mae: 9.506 - ETA: 1:16 - loss: 135.6024 - mae: 9.496 - ETA: 1:13 - loss: 135.4658 - mae: 9.493 - ETA: 1:10 - loss: 135.7703 - mae: 9.501 - ETA: 1:08 - loss: 135.2551 - mae: 9.482 - ETA: 1:05 - loss: 135.2187 - mae: 9.483 - ETA: 1:02 - loss: 135.7219 - mae: 9.505 - ETA: 1:00 - loss: 135.3229 - mae: 9.494 - ETA: 57s - loss: 135.3268 - mae: 9.497 - ETA: 54s - loss: 135.2311 - mae: 9.49 - ETA: 52s - loss: 134.8523 - mae: 9.46 - ETA: 49s - loss: 134.7382 - mae: 9.46 - ETA: 46s - loss: 134.8906 - mae: 9.47 - ETA: 44s - loss: 134.9165 - mae: 9.47 - ETA: 41s - loss: 134.8966 - mae: 9.47 - ETA: 39s - loss: 134.7579 - mae: 9.46 - ETA: 36s - loss: 134.6428 - mae: 9.46 - ETA: 33s - loss: 134.7660 - mae: 9.47 - ETA: 31s - loss: 134.8259 - mae: 9.47 - ETA: 28s - loss: 135.3192 - mae: 9.48 - ETA: 26s - loss: 135.7336 - mae: 9.49 - ETA: 23s - loss: 135.7328 - mae: 9.50 - ETA: 20s - loss: 135.8355 - mae: 9.50 - ETA: 18s - loss: 135.6065 - mae: 9.49 - ETA: 15s - loss: 135.2719 - mae: 9.48 - ETA: 13s - loss: 135.1989 - mae: 9.48 - ETA: 10s - loss: 134.9834 - mae: 9.48 - ETA: 7s - loss: 134.7889 - mae: 9.4811 - ETA: 5s - loss: 134.8978 - mae: 9.485 - ETA: 2s - loss: 135.3320 - mae: 9.502 - ETA: 0s - loss: 135.5272 - mae: 9.509 - 410s 3s/step - loss: 135.5272 - mae: 9.5096 - val_loss: 128.8660 - val_mae: 9.2544\n",
      "\n",
      "Epoch 00006: saving model to CP_ResNet50_Sample100_Fine50_2\\cp-0006.ckpt\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - ETA: 5:47 - loss: 102.2205 - mae: 8.058 - ETA: 7:16 - loss: 105.5710 - mae: 8.294 - ETA: 7:15 - loss: 137.9097 - mae: 9.637 - ETA: 7:07 - loss: 130.3915 - mae: 9.281 - ETA: 6:59 - loss: 138.8050 - mae: 9.708 - ETA: 6:46 - loss: 137.5466 - mae: 9.709 - ETA: 6:34 - loss: 136.8740 - mae: 9.681 - ETA: 6:21 - loss: 134.9478 - mae: 9.578 - ETA: 6:10 - loss: 134.4042 - mae: 9.556 - ETA: 5:59 - loss: 132.2486 - mae: 9.499 - ETA: 5:50 - loss: 128.5547 - mae: 9.292 - ETA: 5:41 - loss: 125.3703 - mae: 9.163 - ETA: 5:34 - loss: 127.0270 - mae: 9.230 - ETA: 5:26 - loss: 125.5015 - mae: 9.172 - ETA: 5:20 - loss: 126.2042 - mae: 9.141 - ETA: 5:13 - loss: 124.9025 - mae: 9.109 - ETA: 5:08 - loss: 128.6092 - mae: 9.245 - ETA: 5:02 - loss: 131.3058 - mae: 9.381 - ETA: 4:57 - loss: 130.7032 - mae: 9.359 - ETA: 4:52 - loss: 134.1844 - mae: 9.476 - ETA: 4:49 - loss: 135.1627 - mae: 9.489 - ETA: 4:46 - loss: 134.7614 - mae: 9.499 - ETA: 4:43 - loss: 134.2801 - mae: 9.476 - ETA: 4:40 - loss: 134.7577 - mae: 9.503 - ETA: 4:36 - loss: 134.8026 - mae: 9.476 - ETA: 4:32 - loss: 134.4270 - mae: 9.456 - ETA: 4:29 - loss: 136.6470 - mae: 9.535 - ETA: 4:27 - loss: 135.3677 - mae: 9.485 - ETA: 4:24 - loss: 135.1494 - mae: 9.476 - ETA: 4:22 - loss: 137.1253 - mae: 9.546 - ETA: 4:21 - loss: 137.2582 - mae: 9.557 - ETA: 4:19 - loss: 135.8042 - mae: 9.504 - ETA: 4:16 - loss: 135.8856 - mae: 9.485 - ETA: 4:13 - loss: 135.0258 - mae: 9.451 - ETA: 4:10 - loss: 133.6916 - mae: 9.398 - ETA: 4:07 - loss: 134.0928 - mae: 9.421 - ETA: 4:03 - loss: 135.2484 - mae: 9.468 - ETA: 4:00 - loss: 134.5218 - mae: 9.449 - ETA: 3:57 - loss: 133.6602 - mae: 9.393 - ETA: 3:53 - loss: 132.4424 - mae: 9.360 - ETA: 3:50 - loss: 131.8712 - mae: 9.345 - ETA: 3:47 - loss: 131.5385 - mae: 9.334 - ETA: 3:44 - loss: 132.0437 - mae: 9.369 - ETA: 3:41 - loss: 132.8439 - mae: 9.385 - ETA: 3:38 - loss: 132.4362 - mae: 9.381 - ETA: 3:34 - loss: 133.5556 - mae: 9.416 - ETA: 3:31 - loss: 133.3023 - mae: 9.416 - ETA: 3:28 - loss: 133.7077 - mae: 9.432 - ETA: 3:25 - loss: 132.9609 - mae: 9.405 - ETA: 3:22 - loss: 132.6435 - mae: 9.380 - ETA: 3:19 - loss: 133.3283 - mae: 9.417 - ETA: 3:16 - loss: 132.8971 - mae: 9.408 - ETA: 3:13 - loss: 132.1700 - mae: 9.383 - ETA: 3:10 - loss: 132.3075 - mae: 9.384 - ETA: 3:07 - loss: 131.7999 - mae: 9.364 - ETA: 3:04 - loss: 130.9532 - mae: 9.319 - ETA: 3:01 - loss: 131.5538 - mae: 9.337 - ETA: 2:59 - loss: 132.5416 - mae: 9.359 - ETA: 2:56 - loss: 132.4194 - mae: 9.354 - ETA: 2:53 - loss: 132.1709 - mae: 9.342 - ETA: 2:51 - loss: 131.4311 - mae: 9.320 - ETA: 2:49 - loss: 131.3982 - mae: 9.330 - ETA: 2:46 - loss: 130.8827 - mae: 9.316 - ETA: 2:44 - loss: 131.6867 - mae: 9.339 - ETA: 2:42 - loss: 131.4067 - mae: 9.330 - ETA: 2:40 - loss: 131.5972 - mae: 9.335 - ETA: 2:37 - loss: 131.7137 - mae: 9.338 - ETA: 2:34 - loss: 131.9265 - mae: 9.339 - ETA: 2:32 - loss: 131.8609 - mae: 9.342 - ETA: 2:29 - loss: 131.3551 - mae: 9.326 - ETA: 2:26 - loss: 132.3314 - mae: 9.368 - ETA: 2:23 - loss: 132.0191 - mae: 9.360 - ETA: 2:20 - loss: 132.2078 - mae: 9.375 - ETA: 2:17 - loss: 132.7928 - mae: 9.381 - ETA: 2:14 - loss: 133.7278 - mae: 9.423 - ETA: 2:12 - loss: 134.2886 - mae: 9.441 - ETA: 2:09 - loss: 134.5128 - mae: 9.446 - ETA: 2:06 - loss: 134.0123 - mae: 9.428 - ETA: 2:03 - loss: 134.2431 - mae: 9.434 - ETA: 2:00 - loss: 134.5905 - mae: 9.456 - ETA: 1:57 - loss: 135.1503 - mae: 9.481 - ETA: 1:55 - loss: 134.6667 - mae: 9.470 - ETA: 1:52 - loss: 134.9529 - mae: 9.479 - ETA: 1:49 - loss: 134.6490 - mae: 9.469 - ETA: 1:46 - loss: 134.0896 - mae: 9.447 - ETA: 1:44 - loss: 133.9664 - mae: 9.439 - ETA: 1:41 - loss: 133.4423 - mae: 9.419 - ETA: 1:38 - loss: 133.5623 - mae: 9.420 - ETA: 1:36 - loss: 133.2407 - mae: 9.414 - ETA: 1:33 - loss: 133.0750 - mae: 9.409 - ETA: 1:30 - loss: 132.9013 - mae: 9.404 - ETA: 1:28 - loss: 133.3812 - mae: 9.420 - ETA: 1:25 - loss: 133.6231 - mae: 9.430 - ETA: 1:23 - loss: 133.7001 - mae: 9.436 - ETA: 1:20 - loss: 134.0148 - mae: 9.437 - ETA: 1:17 - loss: 134.1008 - mae: 9.442 - ETA: 1:15 - loss: 133.9972 - mae: 9.443 - ETA: 1:12 - loss: 134.0704 - mae: 9.443 - ETA: 1:09 - loss: 134.4756 - mae: 9.464 - ETA: 1:07 - loss: 134.4073 - mae: 9.457 - ETA: 1:04 - loss: 134.4700 - mae: 9.467 - ETA: 1:01 - loss: 134.4268 - mae: 9.472 - ETA: 59s - loss: 134.2388 - mae: 9.460 - ETA: 56s - loss: 134.6704 - mae: 9.47 - ETA: 53s - loss: 134.7758 - mae: 9.47 - ETA: 50s - loss: 134.9648 - mae: 9.48 - ETA: 48s - loss: 134.9358 - mae: 9.48 - ETA: 45s - loss: 135.0589 - mae: 9.49 - ETA: 42s - loss: 134.7536 - mae: 9.47 - ETA: 40s - loss: 134.9622 - mae: 9.48 - ETA: 37s - loss: 135.1209 - mae: 9.48 - ETA: 34s - loss: 135.0497 - mae: 9.48 - ETA: 31s - loss: 134.9185 - mae: 9.47 - ETA: 29s - loss: 135.1629 - mae: 9.47 - ETA: 26s - loss: 135.8166 - mae: 9.50 - ETA: 23s - loss: 135.4735 - mae: 9.49 - ETA: 21s - loss: 135.0988 - mae: 9.48 - ETA: 18s - loss: 134.9059 - mae: 9.48 - ETA: 15s - loss: 135.2292 - mae: 9.49 - ETA: 13s - loss: 135.5648 - mae: 9.50 - ETA: 10s - loss: 135.3571 - mae: 9.49 - ETA: 7s - loss: 135.0822 - mae: 9.4935 - ETA: 5s - loss: 134.8372 - mae: 9.485 - ETA: 2s - loss: 135.1407 - mae: 9.493 - ETA: 0s - loss: 134.9622 - mae: 9.492 - 423s 3s/step - loss: 134.9622 - mae: 9.4921 - val_loss: 127.5677 - val_mae: 9.1990\n",
      "\n",
      "Epoch 00007: saving model to CP_ResNet50_Sample100_Fine50_2\\cp-0007.ckpt\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - ETA: 5:33 - loss: 139.4477 - mae: 8.984 - ETA: 5:21 - loss: 127.1711 - mae: 8.581 - ETA: 5:20 - loss: 120.2501 - mae: 8.405 - ETA: 5:17 - loss: 118.1212 - mae: 8.408 - ETA: 5:17 - loss: 113.3566 - mae: 8.226 - ETA: 5:19 - loss: 119.2010 - mae: 8.508 - ETA: 5:21 - loss: 118.3935 - mae: 8.535 - ETA: 5:25 - loss: 114.5220 - mae: 8.395 - ETA: 5:31 - loss: 118.0652 - mae: 8.594 - ETA: 5:36 - loss: 120.2985 - mae: 8.638 - ETA: 5:38 - loss: 122.8349 - mae: 8.826 - ETA: 5:36 - loss: 126.6542 - mae: 8.954 - ETA: 5:32 - loss: 128.0081 - mae: 8.977 - ETA: 5:28 - loss: 129.6442 - mae: 9.040 - ETA: 5:23 - loss: 131.2348 - mae: 9.169 - ETA: 5:18 - loss: 134.2035 - mae: 9.329 - ETA: 5:13 - loss: 132.6346 - mae: 9.267 - ETA: 5:08 - loss: 131.2310 - mae: 9.231 - ETA: 5:03 - loss: 130.4582 - mae: 9.220 - ETA: 4:58 - loss: 131.6761 - mae: 9.260 - ETA: 4:53 - loss: 134.0348 - mae: 9.358 - ETA: 4:48 - loss: 134.4970 - mae: 9.372 - ETA: 4:44 - loss: 132.8214 - mae: 9.307 - ETA: 4:39 - loss: 133.7641 - mae: 9.344 - ETA: 4:35 - loss: 132.9695 - mae: 9.309 - ETA: 4:31 - loss: 131.2581 - mae: 9.241 - ETA: 4:27 - loss: 132.0243 - mae: 9.267 - ETA: 4:24 - loss: 131.8366 - mae: 9.253 - ETA: 4:20 - loss: 131.2514 - mae: 9.246 - ETA: 4:17 - loss: 132.0841 - mae: 9.277 - ETA: 4:13 - loss: 133.1340 - mae: 9.325 - ETA: 4:10 - loss: 133.7596 - mae: 9.340 - ETA: 4:07 - loss: 132.7667 - mae: 9.318 - ETA: 4:03 - loss: 133.2678 - mae: 9.350 - ETA: 4:00 - loss: 132.3967 - mae: 9.336 - ETA: 3:57 - loss: 132.1297 - mae: 9.319 - ETA: 3:55 - loss: 130.6644 - mae: 9.259 - ETA: 3:52 - loss: 130.4796 - mae: 9.256 - ETA: 3:50 - loss: 130.4191 - mae: 9.240 - ETA: 3:47 - loss: 131.1539 - mae: 9.282 - ETA: 3:45 - loss: 131.8164 - mae: 9.315 - ETA: 3:44 - loss: 131.5177 - mae: 9.295 - ETA: 3:42 - loss: 131.0860 - mae: 9.295 - ETA: 3:41 - loss: 131.6730 - mae: 9.295 - ETA: 3:39 - loss: 131.5474 - mae: 9.305 - ETA: 3:37 - loss: 130.7024 - mae: 9.282 - ETA: 3:34 - loss: 129.9786 - mae: 9.263 - ETA: 3:32 - loss: 130.6365 - mae: 9.264 - ETA: 3:29 - loss: 130.4829 - mae: 9.272 - ETA: 3:26 - loss: 130.2938 - mae: 9.270 - ETA: 3:23 - loss: 129.4738 - mae: 9.234 - ETA: 3:20 - loss: 128.9326 - mae: 9.219 - ETA: 3:17 - loss: 129.6719 - mae: 9.257 - ETA: 3:14 - loss: 129.2766 - mae: 9.239 - ETA: 3:11 - loss: 129.3137 - mae: 9.242 - ETA: 3:07 - loss: 129.1628 - mae: 9.250 - ETA: 3:04 - loss: 129.1808 - mae: 9.251 - ETA: 3:01 - loss: 128.7135 - mae: 9.240 - ETA: 2:58 - loss: 129.2004 - mae: 9.259 - ETA: 2:55 - loss: 129.6494 - mae: 9.263 - ETA: 2:52 - loss: 129.7553 - mae: 9.271 - ETA: 2:49 - loss: 130.3915 - mae: 9.288 - ETA: 2:47 - loss: 130.3406 - mae: 9.270 - ETA: 2:44 - loss: 130.2522 - mae: 9.265 - ETA: 2:41 - loss: 130.4408 - mae: 9.279 - ETA: 2:38 - loss: 130.8836 - mae: 9.291 - ETA: 2:35 - loss: 130.9393 - mae: 9.294 - ETA: 2:32 - loss: 130.8161 - mae: 9.278 - ETA: 2:29 - loss: 131.1084 - mae: 9.282 - ETA: 2:27 - loss: 130.3137 - mae: 9.251 - ETA: 2:24 - loss: 129.8216 - mae: 9.238 - ETA: 2:21 - loss: 129.8404 - mae: 9.241 - ETA: 2:19 - loss: 129.4860 - mae: 9.228 - ETA: 2:16 - loss: 129.6371 - mae: 9.232 - ETA: 2:14 - loss: 129.6504 - mae: 9.241 - ETA: 2:12 - loss: 130.2295 - mae: 9.261 - ETA: 2:09 - loss: 130.2333 - mae: 9.254 - ETA: 2:06 - loss: 129.5111 - mae: 9.227 - ETA: 2:04 - loss: 129.7917 - mae: 9.223 - ETA: 2:01 - loss: 129.6774 - mae: 9.227 - ETA: 1:58 - loss: 130.0118 - mae: 9.243 - ETA: 1:56 - loss: 129.8634 - mae: 9.241 - ETA: 1:53 - loss: 130.3503 - mae: 9.253 - ETA: 1:50 - loss: 130.8887 - mae: 9.270 - ETA: 1:47 - loss: 130.7776 - mae: 9.273 - ETA: 1:44 - loss: 131.1714 - mae: 9.288 - ETA: 1:42 - loss: 131.5525 - mae: 9.303 - ETA: 1:39 - loss: 131.7388 - mae: 9.306 - ETA: 1:36 - loss: 131.2677 - mae: 9.291 - ETA: 1:33 - loss: 131.9144 - mae: 9.322 - ETA: 1:31 - loss: 132.3056 - mae: 9.335 - ETA: 1:28 - loss: 132.3210 - mae: 9.335 - ETA: 1:25 - loss: 131.8966 - mae: 9.316 - ETA: 1:23 - loss: 132.7326 - mae: 9.350 - ETA: 1:20 - loss: 132.8257 - mae: 9.356 - ETA: 1:17 - loss: 132.2310 - mae: 9.336 - ETA: 1:14 - loss: 132.6377 - mae: 9.355 - ETA: 1:12 - loss: 132.2621 - mae: 9.346 - ETA: 1:09 - loss: 132.2236 - mae: 9.350 - ETA: 1:06 - loss: 132.4904 - mae: 9.358 - ETA: 1:04 - loss: 132.8823 - mae: 9.380 - ETA: 1:01 - loss: 132.9237 - mae: 9.383 - ETA: 59s - loss: 132.7525 - mae: 9.379 - ETA: 56s - loss: 132.7221 - mae: 9.37 - ETA: 54s - loss: 132.5957 - mae: 9.37 - ETA: 51s - loss: 132.3983 - mae: 9.36 - ETA: 48s - loss: 132.5148 - mae: 9.37 - ETA: 45s - loss: 132.4885 - mae: 9.38 - ETA: 43s - loss: 132.8024 - mae: 9.38 - ETA: 40s - loss: 132.7932 - mae: 9.38 - ETA: 37s - loss: 132.8376 - mae: 9.38 - ETA: 35s - loss: 132.7440 - mae: 9.38 - ETA: 32s - loss: 132.6753 - mae: 9.38 - ETA: 29s - loss: 132.7573 - mae: 9.38 - ETA: 26s - loss: 132.5439 - mae: 9.38 - ETA: 24s - loss: 132.1020 - mae: 9.36 - ETA: 21s - loss: 132.6216 - mae: 9.38 - ETA: 18s - loss: 132.4748 - mae: 9.37 - ETA: 16s - loss: 132.3612 - mae: 9.36 - ETA: 13s - loss: 132.1198 - mae: 9.36 - ETA: 10s - loss: 131.9872 - mae: 9.35 - ETA: 8s - loss: 131.9882 - mae: 9.3573 - ETA: 5s - loss: 132.2729 - mae: 9.375 - ETA: 2s - loss: 132.4014 - mae: 9.385 - ETA: 0s - loss: 132.3390 - mae: 9.386 - 416s 3s/step - loss: 132.3390 - mae: 9.3860 - val_loss: 125.3025 - val_mae: 9.0870\n",
      "\n",
      "Epoch 00008: saving model to CP_ResNet50_Sample100_Fine50_2\\cp-0008.ckpt\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - ETA: 5:06 - loss: 137.7908 - mae: 9.104 - ETA: 5:23 - loss: 135.3873 - mae: 9.380 - ETA: 5:08 - loss: 132.6662 - mae: 9.397 - ETA: 5:02 - loss: 126.3678 - mae: 9.258 - ETA: 4:58 - loss: 129.8502 - mae: 9.398 - ETA: 4:59 - loss: 123.4469 - mae: 9.018 - ETA: 5:01 - loss: 126.0163 - mae: 9.171 - ETA: 5:06 - loss: 125.7496 - mae: 9.098 - ETA: 5:09 - loss: 129.6337 - mae: 9.284 - ETA: 5:12 - loss: 129.5582 - mae: 9.333 - ETA: 5:14 - loss: 126.5768 - mae: 9.220 - ETA: 5:14 - loss: 129.0537 - mae: 9.320 - ETA: 5:11 - loss: 130.0170 - mae: 9.357 - ETA: 5:08 - loss: 126.9676 - mae: 9.237 - ETA: 5:04 - loss: 125.2475 - mae: 9.153 - ETA: 5:01 - loss: 126.3038 - mae: 9.174 - ETA: 4:56 - loss: 126.4814 - mae: 9.146 - ETA: 4:52 - loss: 126.3158 - mae: 9.122 - ETA: 4:48 - loss: 128.6519 - mae: 9.208 - ETA: 4:44 - loss: 129.2559 - mae: 9.226 - ETA: 4:40 - loss: 130.9893 - mae: 9.307 - ETA: 4:36 - loss: 133.3799 - mae: 9.380 - ETA: 4:32 - loss: 130.7383 - mae: 9.282 - ETA: 4:28 - loss: 130.3089 - mae: 9.282 - ETA: 4:25 - loss: 130.4505 - mae: 9.263 - ETA: 4:21 - loss: 129.4951 - mae: 9.246 - ETA: 4:18 - loss: 127.6435 - mae: 9.180 - ETA: 4:14 - loss: 127.7016 - mae: 9.204 - ETA: 4:11 - loss: 127.6118 - mae: 9.230 - ETA: 4:08 - loss: 129.1485 - mae: 9.271 - ETA: 4:05 - loss: 127.2504 - mae: 9.176 - ETA: 4:02 - loss: 126.6032 - mae: 9.164 - ETA: 3:59 - loss: 127.6920 - mae: 9.210 - ETA: 3:57 - loss: 127.1836 - mae: 9.180 - ETA: 3:54 - loss: 128.3590 - mae: 9.216 - ETA: 3:52 - loss: 128.1617 - mae: 9.183 - ETA: 3:50 - loss: 129.0018 - mae: 9.221 - ETA: 3:48 - loss: 129.3079 - mae: 9.257 - ETA: 3:47 - loss: 128.1364 - mae: 9.205 - ETA: 3:46 - loss: 128.3903 - mae: 9.208 - ETA: 3:46 - loss: 128.8904 - mae: 9.208 - ETA: 3:44 - loss: 128.4743 - mae: 9.200 - ETA: 3:42 - loss: 127.7658 - mae: 9.175 - ETA: 3:40 - loss: 129.1619 - mae: 9.237 - ETA: 3:37 - loss: 129.3727 - mae: 9.249 - ETA: 3:34 - loss: 129.0593 - mae: 9.238 - ETA: 3:31 - loss: 128.5391 - mae: 9.210 - ETA: 3:28 - loss: 128.6924 - mae: 9.228 - ETA: 3:25 - loss: 128.9290 - mae: 9.233 - ETA: 3:22 - loss: 129.1585 - mae: 9.242 - ETA: 3:19 - loss: 130.0673 - mae: 9.265 - ETA: 3:16 - loss: 129.6681 - mae: 9.261 - ETA: 3:13 - loss: 128.7849 - mae: 9.237 - ETA: 3:10 - loss: 129.2973 - mae: 9.235 - ETA: 3:07 - loss: 129.1962 - mae: 9.222 - ETA: 3:04 - loss: 129.1297 - mae: 9.227 - ETA: 3:01 - loss: 128.9443 - mae: 9.221 - ETA: 2:58 - loss: 128.3800 - mae: 9.207 - ETA: 2:55 - loss: 128.6812 - mae: 9.221 - ETA: 2:52 - loss: 129.5873 - mae: 9.254 - ETA: 2:50 - loss: 129.6073 - mae: 9.266 - ETA: 2:47 - loss: 129.2348 - mae: 9.246 - ETA: 2:44 - loss: 129.9890 - mae: 9.260 - ETA: 2:41 - loss: 129.9466 - mae: 9.252 - ETA: 2:38 - loss: 129.4796 - mae: 9.233 - ETA: 2:35 - loss: 129.9364 - mae: 9.246 - ETA: 2:33 - loss: 130.3552 - mae: 9.264 - ETA: 2:30 - loss: 130.4640 - mae: 9.267 - ETA: 2:27 - loss: 129.3690 - mae: 9.224 - ETA: 2:25 - loss: 129.0397 - mae: 9.211 - ETA: 2:22 - loss: 128.9586 - mae: 9.201 - ETA: 2:20 - loss: 128.6089 - mae: 9.179 - ETA: 2:17 - loss: 128.0670 - mae: 9.166 - ETA: 2:15 - loss: 127.7693 - mae: 9.147 - ETA: 2:13 - loss: 128.5543 - mae: 9.182 - ETA: 2:11 - loss: 128.6085 - mae: 9.187 - ETA: 2:09 - loss: 128.7617 - mae: 9.196 - ETA: 2:06 - loss: 128.8770 - mae: 9.203 - ETA: 2:04 - loss: 129.1399 - mae: 9.211 - ETA: 2:02 - loss: 129.0463 - mae: 9.205 - ETA: 1:59 - loss: 129.0926 - mae: 9.206 - ETA: 1:56 - loss: 129.1701 - mae: 9.209 - ETA: 1:54 - loss: 129.1336 - mae: 9.204 - ETA: 1:51 - loss: 128.9368 - mae: 9.196 - ETA: 1:48 - loss: 128.6599 - mae: 9.185 - ETA: 1:45 - loss: 129.3654 - mae: 9.202 - ETA: 1:42 - loss: 129.1123 - mae: 9.198 - ETA: 1:39 - loss: 129.6384 - mae: 9.220 - ETA: 1:37 - loss: 129.6053 - mae: 9.221 - ETA: 1:34 - loss: 129.5847 - mae: 9.221 - ETA: 1:31 - loss: 130.1761 - mae: 9.243 - ETA: 1:28 - loss: 130.7965 - mae: 9.260 - ETA: 1:26 - loss: 130.9842 - mae: 9.269 - ETA: 1:23 - loss: 130.9989 - mae: 9.272 - ETA: 1:20 - loss: 130.4702 - mae: 9.253 - ETA: 1:17 - loss: 131.0692 - mae: 9.275 - ETA: 1:14 - loss: 130.8781 - mae: 9.265 - ETA: 1:12 - loss: 131.0080 - mae: 9.277 - ETA: 1:09 - loss: 131.0517 - mae: 9.284 - ETA: 1:06 - loss: 130.9697 - mae: 9.282 - ETA: 1:04 - loss: 131.0187 - mae: 9.286 - ETA: 1:01 - loss: 130.9433 - mae: 9.286 - ETA: 58s - loss: 131.1095 - mae: 9.300 - ETA: 55s - loss: 131.0860 - mae: 9.30 - ETA: 53s - loss: 131.2371 - mae: 9.30 - ETA: 50s - loss: 131.8124 - mae: 9.31 - ETA: 48s - loss: 132.3444 - mae: 9.34 - ETA: 45s - loss: 132.0717 - mae: 9.32 - ETA: 42s - loss: 131.9064 - mae: 9.32 - ETA: 40s - loss: 132.2098 - mae: 9.33 - ETA: 37s - loss: 131.8002 - mae: 9.31 - ETA: 35s - loss: 131.6757 - mae: 9.30 - ETA: 32s - loss: 131.7090 - mae: 9.31 - ETA: 29s - loss: 131.2251 - mae: 9.29 - ETA: 27s - loss: 130.9643 - mae: 9.28 - ETA: 24s - loss: 130.8731 - mae: 9.28 - ETA: 21s - loss: 130.5445 - mae: 9.27 - ETA: 18s - loss: 130.7028 - mae: 9.27 - ETA: 16s - loss: 131.0703 - mae: 9.29 - ETA: 13s - loss: 131.1440 - mae: 9.30 - ETA: 10s - loss: 131.4626 - mae: 9.31 - ETA: 8s - loss: 131.3739 - mae: 9.3176 - ETA: 5s - loss: 131.4497 - mae: 9.318 - ETA: 2s - loss: 131.6218 - mae: 9.331 - ETA: 0s - loss: 131.4904 - mae: 9.328 - 417s 3s/step - loss: 131.4904 - mae: 9.3280 - val_loss: 125.5978 - val_mae: 9.0995\n",
      "\n",
      "Epoch 00009: saving model to CP_ResNet50_Sample100_Fine50_2\\cp-0009.ckpt\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - ETA: 5:22 - loss: 148.8506 - mae: 10.05 - ETA: 5:43 - loss: 146.4010 - mae: 9.8881 - ETA: 5:44 - loss: 130.9709 - mae: 9.270 - ETA: 5:44 - loss: 129.5628 - mae: 9.183 - ETA: 5:31 - loss: 129.9760 - mae: 9.225 - ETA: 5:21 - loss: 128.9246 - mae: 9.175 - ETA: 5:14 - loss: 129.5604 - mae: 9.201 - ETA: 5:09 - loss: 128.2070 - mae: 9.139 - ETA: 5:05 - loss: 124.9881 - mae: 9.037 - ETA: 5:02 - loss: 133.5370 - mae: 9.329 - ETA: 5:00 - loss: 132.1001 - mae: 9.253 - ETA: 4:58 - loss: 134.0390 - mae: 9.331 - ETA: 4:57 - loss: 132.0762 - mae: 9.254 - ETA: 4:56 - loss: 129.4898 - mae: 9.132 - ETA: 4:56 - loss: 128.9772 - mae: 9.143 - ETA: 4:57 - loss: 127.7291 - mae: 9.128 - ETA: 5:00 - loss: 129.4977 - mae: 9.222 - ETA: 5:01 - loss: 130.2896 - mae: 9.255 - ETA: 5:00 - loss: 127.1313 - mae: 9.101 - ETA: 4:58 - loss: 127.6937 - mae: 9.115 - ETA: 4:56 - loss: 125.5818 - mae: 9.035 - ETA: 4:56 - loss: 124.4522 - mae: 9.001 - ETA: 4:54 - loss: 124.8832 - mae: 9.042 - ETA: 4:51 - loss: 124.2962 - mae: 9.023 - ETA: 4:48 - loss: 125.7216 - mae: 9.083 - ETA: 4:43 - loss: 125.2038 - mae: 9.078 - ETA: 4:39 - loss: 124.9437 - mae: 9.063 - ETA: 4:35 - loss: 124.6375 - mae: 9.040 - ETA: 4:30 - loss: 125.4684 - mae: 9.055 - ETA: 4:26 - loss: 124.3303 - mae: 8.990 - ETA: 4:22 - loss: 124.4609 - mae: 9.009 - ETA: 4:19 - loss: 127.8896 - mae: 9.133 - ETA: 4:15 - loss: 127.5184 - mae: 9.116 - ETA: 4:11 - loss: 127.3855 - mae: 9.125 - ETA: 4:08 - loss: 126.1917 - mae: 9.091 - ETA: 4:04 - loss: 127.5292 - mae: 9.122 - ETA: 4:01 - loss: 126.9424 - mae: 9.113 - ETA: 3:57 - loss: 127.8398 - mae: 9.161 - ETA: 3:54 - loss: 127.4667 - mae: 9.149 - ETA: 3:51 - loss: 129.2607 - mae: 9.219 - ETA: 3:48 - loss: 128.2306 - mae: 9.175 - ETA: 3:45 - loss: 129.2200 - mae: 9.206 - ETA: 3:42 - loss: 129.2711 - mae: 9.214 - ETA: 3:39 - loss: 129.0704 - mae: 9.209 - ETA: 3:36 - loss: 128.7286 - mae: 9.206 - ETA: 3:34 - loss: 127.4237 - mae: 9.157 - ETA: 3:32 - loss: 126.8648 - mae: 9.151 - ETA: 3:30 - loss: 126.9616 - mae: 9.146 - ETA: 3:28 - loss: 126.8939 - mae: 9.135 - ETA: 3:26 - loss: 127.7046 - mae: 9.177 - ETA: 3:24 - loss: 127.6686 - mae: 9.172 - ETA: 3:21 - loss: 127.2459 - mae: 9.164 - ETA: 3:18 - loss: 126.5311 - mae: 9.132 - ETA: 3:16 - loss: 128.4286 - mae: 9.175 - ETA: 3:13 - loss: 129.4053 - mae: 9.215 - ETA: 3:10 - loss: 129.6804 - mae: 9.232 - ETA: 3:07 - loss: 129.8054 - mae: 9.232 - ETA: 3:04 - loss: 129.6147 - mae: 9.225 - ETA: 3:01 - loss: 129.5213 - mae: 9.218 - ETA: 2:58 - loss: 129.4196 - mae: 9.216 - ETA: 2:55 - loss: 128.9855 - mae: 9.206 - ETA: 2:51 - loss: 127.9960 - mae: 9.162 - ETA: 2:48 - loss: 128.4476 - mae: 9.178 - ETA: 2:46 - loss: 128.2410 - mae: 9.155 - ETA: 2:43 - loss: 128.6577 - mae: 9.178 - ETA: 2:40 - loss: 128.2596 - mae: 9.154 - ETA: 2:37 - loss: 128.2253 - mae: 9.164 - ETA: 2:34 - loss: 128.6927 - mae: 9.181 - ETA: 2:31 - loss: 128.1589 - mae: 9.166 - ETA: 2:28 - loss: 128.3848 - mae: 9.160 - ETA: 2:25 - loss: 128.4251 - mae: 9.170 - ETA: 2:22 - loss: 127.8141 - mae: 9.145 - ETA: 2:20 - loss: 127.8188 - mae: 9.144 - ETA: 2:17 - loss: 127.8538 - mae: 9.146 - ETA: 2:14 - loss: 127.5391 - mae: 9.141 - ETA: 2:12 - loss: 128.5891 - mae: 9.180 - ETA: 2:09 - loss: 128.7024 - mae: 9.184 - ETA: 2:07 - loss: 128.7224 - mae: 9.187 - ETA: 2:05 - loss: 128.6838 - mae: 9.194 - ETA: 2:03 - loss: 129.1715 - mae: 9.216 - ETA: 2:00 - loss: 129.0704 - mae: 9.203 - ETA: 1:58 - loss: 129.2065 - mae: 9.219 - ETA: 1:55 - loss: 129.3788 - mae: 9.230 - ETA: 1:53 - loss: 129.3642 - mae: 9.232 - ETA: 1:50 - loss: 129.4422 - mae: 9.228 - ETA: 1:47 - loss: 129.5171 - mae: 9.230 - ETA: 1:45 - loss: 129.0329 - mae: 9.218 - ETA: 1:42 - loss: 129.0798 - mae: 9.222 - ETA: 1:39 - loss: 129.2324 - mae: 9.233 - ETA: 1:36 - loss: 129.1706 - mae: 9.231 - ETA: 1:33 - loss: 128.6973 - mae: 9.207 - ETA: 1:30 - loss: 129.0088 - mae: 9.219 - ETA: 1:27 - loss: 129.3527 - mae: 9.230 - ETA: 1:25 - loss: 129.4484 - mae: 9.231 - ETA: 1:22 - loss: 129.0206 - mae: 9.215 - ETA: 1:19 - loss: 129.0953 - mae: 9.222 - ETA: 1:16 - loss: 129.1994 - mae: 9.223 - ETA: 1:13 - loss: 129.4827 - mae: 9.231 - ETA: 1:10 - loss: 129.5899 - mae: 9.239 - ETA: 1:08 - loss: 129.2878 - mae: 9.226 - ETA: 1:05 - loss: 129.2997 - mae: 9.232 - ETA: 1:02 - loss: 129.4423 - mae: 9.237 - ETA: 59s - loss: 129.4633 - mae: 9.238 - ETA: 57s - loss: 129.6926 - mae: 9.24 - ETA: 54s - loss: 129.9030 - mae: 9.24 - ETA: 51s - loss: 129.9433 - mae: 9.25 - ETA: 48s - loss: 129.8493 - mae: 9.24 - ETA: 46s - loss: 129.7427 - mae: 9.24 - ETA: 43s - loss: 129.6064 - mae: 9.23 - ETA: 40s - loss: 129.9982 - mae: 9.24 - ETA: 37s - loss: 129.6927 - mae: 9.23 - ETA: 35s - loss: 130.2231 - mae: 9.25 - ETA: 32s - loss: 130.0808 - mae: 9.25 - ETA: 29s - loss: 129.8736 - mae: 9.24 - ETA: 27s - loss: 129.6860 - mae: 9.23 - ETA: 24s - loss: 129.8150 - mae: 9.24 - ETA: 21s - loss: 129.6568 - mae: 9.24 - ETA: 19s - loss: 129.6301 - mae: 9.24 - ETA: 16s - loss: 129.5939 - mae: 9.24 - ETA: 13s - loss: 129.7909 - mae: 9.25 - ETA: 11s - loss: 129.6950 - mae: 9.26 - ETA: 8s - loss: 130.2903 - mae: 9.2826 - ETA: 5s - loss: 130.3278 - mae: 9.282 - ETA: 2s - loss: 130.4799 - mae: 9.284 - ETA: 0s - loss: 130.2835 - mae: 9.278 - 427s 3s/step - loss: 130.2835 - mae: 9.2782 - val_loss: 125.0603 - val_mae: 9.0744\n",
      "\n",
      "Epoch 00010: saving model to CP_ResNet50_Sample100_Fine50_2\\cp-0010.ckpt\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - ETA: 5:41 - loss: 107.8675 - mae: 8.474 - ETA: 5:35 - loss: 110.8091 - mae: 8.551 - ETA: 5:27 - loss: 110.4239 - mae: 8.474 - ETA: 5:20 - loss: 111.1714 - mae: 8.625 - ETA: 5:14 - loss: 108.7323 - mae: 8.483 - ETA: 5:07 - loss: 121.5236 - mae: 9.048 - ETA: 5:02 - loss: 118.4836 - mae: 8.940 - ETA: 4:58 - loss: 117.3669 - mae: 8.968 - ETA: 4:53 - loss: 119.8903 - mae: 9.059 - ETA: 4:49 - loss: 121.7755 - mae: 9.127 - ETA: 4:46 - loss: 120.1222 - mae: 9.018 - ETA: 4:43 - loss: 119.7096 - mae: 8.981 - ETA: 4:39 - loss: 117.8680 - mae: 8.893 - ETA: 4:37 - loss: 122.1588 - mae: 9.042 - ETA: 4:34 - loss: 121.9775 - mae: 9.030 - ETA: 4:31 - loss: 121.6795 - mae: 9.034 - ETA: 4:28 - loss: 124.2542 - mae: 9.087 - ETA: 4:26 - loss: 123.6176 - mae: 9.036 - ETA: 4:24 - loss: 124.1701 - mae: 9.034 - ETA: 4:21 - loss: 123.8977 - mae: 9.041 - ETA: 4:20 - loss: 123.0399 - mae: 9.014 - ETA: 4:18 - loss: 124.8973 - mae: 9.113 - ETA: 4:16 - loss: 126.8764 - mae: 9.191 - ETA: 4:15 - loss: 127.0667 - mae: 9.203 - ETA: 4:14 - loss: 127.8065 - mae: 9.259 - ETA: 4:13 - loss: 126.2356 - mae: 9.193 - ETA: 4:13 - loss: 125.6322 - mae: 9.170 - ETA: 4:14 - loss: 124.1840 - mae: 9.119 - ETA: 4:15 - loss: 124.3046 - mae: 9.135 - ETA: 4:16 - loss: 125.3501 - mae: 9.131 - ETA: 4:15 - loss: 124.5616 - mae: 9.092 - ETA: 4:14 - loss: 124.9651 - mae: 9.088 - ETA: 4:12 - loss: 124.8781 - mae: 9.112 - ETA: 4:09 - loss: 125.5625 - mae: 9.136 - ETA: 4:06 - loss: 126.0211 - mae: 9.167 - ETA: 4:03 - loss: 126.0545 - mae: 9.149 - ETA: 4:00 - loss: 125.5362 - mae: 9.125 - ETA: 3:57 - loss: 124.8566 - mae: 9.093 - ETA: 3:54 - loss: 124.0916 - mae: 9.055 - ETA: 3:51 - loss: 124.2474 - mae: 9.064 - ETA: 3:47 - loss: 124.7394 - mae: 9.084 - ETA: 3:44 - loss: 126.0782 - mae: 9.138 - ETA: 3:41 - loss: 126.7198 - mae: 9.156 - ETA: 3:38 - loss: 127.1653 - mae: 9.175 - ETA: 3:35 - loss: 126.2781 - mae: 9.142 - ETA: 3:31 - loss: 125.5930 - mae: 9.119 - ETA: 3:28 - loss: 126.5048 - mae: 9.160 - ETA: 3:25 - loss: 125.4250 - mae: 9.124 - ETA: 3:22 - loss: 124.6872 - mae: 9.099 - ETA: 3:19 - loss: 125.7772 - mae: 9.120 - ETA: 3:16 - loss: 128.2290 - mae: 9.196 - ETA: 3:13 - loss: 127.4819 - mae: 9.170 - ETA: 3:10 - loss: 127.1020 - mae: 9.166 - ETA: 3:08 - loss: 127.6514 - mae: 9.202 - ETA: 3:05 - loss: 127.3771 - mae: 9.188 - ETA: 3:02 - loss: 126.4615 - mae: 9.148 - ETA: 3:00 - loss: 126.2059 - mae: 9.142 - ETA: 2:57 - loss: 125.9473 - mae: 9.140 - ETA: 2:55 - loss: 126.8011 - mae: 9.144 - ETA: 2:52 - loss: 126.9026 - mae: 9.144 - ETA: 2:50 - loss: 127.4388 - mae: 9.168 - ETA: 2:48 - loss: 127.4116 - mae: 9.161 - ETA: 2:46 - loss: 127.5149 - mae: 9.163 - ETA: 2:43 - loss: 127.1572 - mae: 9.156 - ETA: 2:41 - loss: 126.8235 - mae: 9.152 - ETA: 2:38 - loss: 126.3277 - mae: 9.139 - ETA: 2:36 - loss: 126.1167 - mae: 9.128 - ETA: 2:33 - loss: 126.0457 - mae: 9.130 - ETA: 2:31 - loss: 126.2800 - mae: 9.135 - ETA: 2:28 - loss: 126.4925 - mae: 9.141 - ETA: 2:25 - loss: 126.6361 - mae: 9.143 - ETA: 2:23 - loss: 126.6140 - mae: 9.142 - ETA: 2:20 - loss: 126.7585 - mae: 9.144 - ETA: 2:17 - loss: 126.4025 - mae: 9.134 - ETA: 2:14 - loss: 126.6720 - mae: 9.149 - ETA: 2:12 - loss: 126.9202 - mae: 9.165 - ETA: 2:09 - loss: 127.2213 - mae: 9.167 - ETA: 2:06 - loss: 127.4387 - mae: 9.174 - ETA: 2:04 - loss: 127.0479 - mae: 9.159 - ETA: 2:01 - loss: 126.9543 - mae: 9.154 - ETA: 1:59 - loss: 127.0642 - mae: 9.154 - ETA: 1:56 - loss: 127.7788 - mae: 9.179 - ETA: 1:54 - loss: 128.1474 - mae: 9.189 - ETA: 1:52 - loss: 127.6469 - mae: 9.173 - ETA: 1:49 - loss: 128.0963 - mae: 9.189 - ETA: 1:46 - loss: 128.5484 - mae: 9.189 - ETA: 1:44 - loss: 128.7078 - mae: 9.196 - ETA: 1:41 - loss: 128.7424 - mae: 9.202 - ETA: 1:38 - loss: 129.1212 - mae: 9.225 - ETA: 1:35 - loss: 129.3824 - mae: 9.240 - ETA: 1:32 - loss: 129.5693 - mae: 9.247 - ETA: 1:30 - loss: 130.2456 - mae: 9.268 - ETA: 1:27 - loss: 130.3124 - mae: 9.271 - ETA: 1:24 - loss: 129.8171 - mae: 9.256 - ETA: 1:21 - loss: 130.6951 - mae: 9.286 - ETA: 1:18 - loss: 130.5809 - mae: 9.284 - ETA: 1:16 - loss: 130.1934 - mae: 9.276 - ETA: 1:13 - loss: 130.0318 - mae: 9.273 - ETA: 1:10 - loss: 129.6141 - mae: 9.259 - ETA: 1:07 - loss: 129.6971 - mae: 9.264 - ETA: 1:04 - loss: 129.5279 - mae: 9.258 - ETA: 1:02 - loss: 130.0064 - mae: 9.273 - ETA: 59s - loss: 129.5024 - mae: 9.254 - ETA: 56s - loss: 129.7770 - mae: 9.27 - ETA: 53s - loss: 129.9812 - mae: 9.28 - ETA: 51s - loss: 129.3598 - mae: 9.25 - ETA: 48s - loss: 128.7949 - mae: 9.23 - ETA: 45s - loss: 128.6653 - mae: 9.22 - ETA: 43s - loss: 129.0389 - mae: 9.23 - ETA: 40s - loss: 128.7832 - mae: 9.22 - ETA: 37s - loss: 128.7923 - mae: 9.23 - ETA: 35s - loss: 129.0479 - mae: 9.23 - ETA: 32s - loss: 129.1168 - mae: 9.23 - ETA: 29s - loss: 129.0594 - mae: 9.23 - ETA: 27s - loss: 128.7692 - mae: 9.22 - ETA: 24s - loss: 129.1822 - mae: 9.23 - ETA: 21s - loss: 129.1781 - mae: 9.23 - ETA: 19s - loss: 129.0614 - mae: 9.23 - ETA: 16s - loss: 129.0479 - mae: 9.23 - ETA: 13s - loss: 129.4674 - mae: 9.25 - ETA: 10s - loss: 129.6136 - mae: 9.25 - ETA: 8s - loss: 129.4198 - mae: 9.2549 - ETA: 5s - loss: 129.2339 - mae: 9.250 - ETA: 2s - loss: 128.9453 - mae: 9.246 - ETA: 0s - loss: 128.7752 - mae: 9.238 - 454s 4s/step - loss: 128.7752 - mae: 9.2387 - val_loss: 123.9844 - val_mae: 9.0252\n",
      "\n",
      "Epoch 00011: saving model to CP_ResNet50_Sample100_Fine50_2\\cp-0011.ckpt\n",
      "Epoch 12/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - ETA: 6:03 - loss: 177.6689 - mae: 10.77 - ETA: 6:40 - loss: 155.2271 - mae: 9.9997 - ETA: 6:38 - loss: 143.4388 - mae: 9.578 - ETA: 6:38 - loss: 135.5529 - mae: 9.469 - ETA: 6:40 - loss: 126.9933 - mae: 9.211 - ETA: 6:45 - loss: 126.8526 - mae: 9.207 - ETA: 6:56 - loss: 121.5036 - mae: 8.940 - ETA: 7:06 - loss: 123.1627 - mae: 9.034 - ETA: 7:35 - loss: 120.6318 - mae: 8.811 - ETA: 8:13 - loss: 120.1643 - mae: 8.818 - ETA: 8:18 - loss: 120.4274 - mae: 8.826 - ETA: 8:14 - loss: 122.6117 - mae: 8.845 - ETA: 8:04 - loss: 123.0104 - mae: 8.922 - ETA: 7:52 - loss: 123.3467 - mae: 8.919 - ETA: 7:44 - loss: 126.5872 - mae: 9.063 - ETA: 7:30 - loss: 127.7919 - mae: 9.141 - ETA: 7:20 - loss: 127.5631 - mae: 9.152 - ETA: 7:08 - loss: 125.9830 - mae: 9.097 - ETA: 6:56 - loss: 126.0806 - mae: 9.113 - ETA: 6:45 - loss: 128.2860 - mae: 9.185 - ETA: 6:35 - loss: 129.0047 - mae: 9.182 - ETA: 6:26 - loss: 130.7601 - mae: 9.278 - ETA: 6:17 - loss: 131.1868 - mae: 9.287 - ETA: 6:09 - loss: 130.7012 - mae: 9.272 - ETA: 6:01 - loss: 131.9553 - mae: 9.310 - ETA: 5:53 - loss: 130.9968 - mae: 9.269 - ETA: 5:47 - loss: 129.6832 - mae: 9.238 - ETA: 5:41 - loss: 128.5146 - mae: 9.188 - ETA: 5:35 - loss: 128.0880 - mae: 9.176 - ETA: 5:35 - loss: 127.8195 - mae: 9.168 - ETA: 5:32 - loss: 126.3933 - mae: 9.098 - ETA: 5:29 - loss: 128.7237 - mae: 9.149 - ETA: 5:25 - loss: 129.3401 - mae: 9.191 - ETA: 5:22 - loss: 129.6446 - mae: 9.193 - ETA: 5:19 - loss: 128.6754 - mae: 9.151 - ETA: 5:18 - loss: 129.1036 - mae: 9.185 - ETA: 5:19 - loss: 128.5697 - mae: 9.160 - ETA: 5:18 - loss: 129.0892 - mae: 9.183 - ETA: 5:18 - loss: 128.5958 - mae: 9.166 - ETA: 5:14 - loss: 128.2097 - mae: 9.163 - ETA: 5:10 - loss: 128.1051 - mae: 9.175 - ETA: 5:07 - loss: 127.6877 - mae: 9.165 - ETA: 5:02 - loss: 128.5274 - mae: 9.205 - ETA: 4:58 - loss: 128.2478 - mae: 9.206 - ETA: 4:53 - loss: 127.9403 - mae: 9.205 - ETA: 4:48 - loss: 128.7448 - mae: 9.218 - ETA: 4:43 - loss: 127.8817 - mae: 9.187 - ETA: 4:37 - loss: 127.6305 - mae: 9.189 - ETA: 4:32 - loss: 126.4060 - mae: 9.128 - ETA: 4:27 - loss: 126.1774 - mae: 9.126 - ETA: 4:22 - loss: 126.8787 - mae: 9.157 - ETA: 4:17 - loss: 127.4720 - mae: 9.182 - ETA: 4:12 - loss: 128.4352 - mae: 9.214 - ETA: 4:08 - loss: 128.5001 - mae: 9.217 - ETA: 4:03 - loss: 129.4592 - mae: 9.251 - ETA: 3:59 - loss: 129.3076 - mae: 9.243 - ETA: 3:54 - loss: 128.7426 - mae: 9.224 - ETA: 3:50 - loss: 129.0417 - mae: 9.228 - ETA: 3:46 - loss: 128.9964 - mae: 9.222 - ETA: 3:42 - loss: 128.4910 - mae: 9.209 - ETA: 3:38 - loss: 127.6290 - mae: 9.183 - ETA: 3:34 - loss: 127.5261 - mae: 9.184 - ETA: 3:31 - loss: 126.9004 - mae: 9.161 - ETA: 3:28 - loss: 127.2510 - mae: 9.173 - ETA: 3:25 - loss: 126.9137 - mae: 9.162 - ETA: 3:22 - loss: 127.0714 - mae: 9.173 - ETA: 3:20 - loss: 127.1386 - mae: 9.175 - ETA: 3:17 - loss: 126.4515 - mae: 9.152 - ETA: 3:14 - loss: 126.1351 - mae: 9.132 - ETA: 3:11 - loss: 126.1325 - mae: 9.135 - ETA: 3:08 - loss: 125.8485 - mae: 9.119 - ETA: 3:04 - loss: 126.0909 - mae: 9.133 - ETA: 3:01 - loss: 126.1945 - mae: 9.133 - ETA: 2:57 - loss: 126.6602 - mae: 9.149 - ETA: 2:53 - loss: 127.0124 - mae: 9.164 - ETA: 2:49 - loss: 127.4085 - mae: 9.174 - ETA: 2:45 - loss: 127.2196 - mae: 9.172 - ETA: 2:41 - loss: 127.5285 - mae: 9.188 - ETA: 2:37 - loss: 127.5383 - mae: 9.183 - ETA: 2:33 - loss: 127.4056 - mae: 9.174 - ETA: 2:29 - loss: 127.1723 - mae: 9.162 - ETA: 2:26 - loss: 127.4398 - mae: 9.172 - ETA: 2:22 - loss: 127.3799 - mae: 9.177 - ETA: 2:18 - loss: 127.5154 - mae: 9.175 - ETA: 2:14 - loss: 127.5123 - mae: 9.175 - ETA: 2:11 - loss: 128.2061 - mae: 9.202 - ETA: 2:07 - loss: 127.9912 - mae: 9.191 - ETA: 2:03 - loss: 127.5248 - mae: 9.169 - ETA: 2:00 - loss: 127.6019 - mae: 9.166 - ETA: 1:56 - loss: 127.5286 - mae: 9.169 - ETA: 1:52 - loss: 127.5017 - mae: 9.171 - ETA: 1:49 - loss: 128.0564 - mae: 9.190 - ETA: 1:45 - loss: 128.3243 - mae: 9.198 - ETA: 1:42 - loss: 128.6288 - mae: 9.213 - ETA: 1:39 - loss: 128.9137 - mae: 9.229 - ETA: 1:35 - loss: 128.9516 - mae: 9.233 - ETA: 1:32 - loss: 128.8181 - mae: 9.234 - ETA: 1:29 - loss: 129.2536 - mae: 9.258 - ETA: 1:26 - loss: 129.2765 - mae: 9.263 - ETA: 1:23 - loss: 129.6021 - mae: 9.275 - ETA: 1:20 - loss: 129.4278 - mae: 9.265 - ETA: 1:17 - loss: 129.8086 - mae: 9.283 - ETA: 1:14 - loss: 129.5810 - mae: 9.274 - ETA: 1:11 - loss: 129.4973 - mae: 9.270 - ETA: 1:07 - loss: 129.7185 - mae: 9.277 - ETA: 1:04 - loss: 129.5114 - mae: 9.267 - ETA: 1:01 - loss: 129.0147 - mae: 9.246 - ETA: 57s - loss: 129.0737 - mae: 9.246 - ETA: 54s - loss: 128.8247 - mae: 9.23 - ETA: 50s - loss: 128.4865 - mae: 9.22 - ETA: 47s - loss: 129.2661 - mae: 9.25 - ETA: 43s - loss: 129.0220 - mae: 9.24 - ETA: 40s - loss: 128.9464 - mae: 9.24 - ETA: 36s - loss: 128.7442 - mae: 9.23 - ETA: 33s - loss: 128.6635 - mae: 9.23 - ETA: 30s - loss: 128.2977 - mae: 9.21 - ETA: 26s - loss: 128.4914 - mae: 9.21 - ETA: 23s - loss: 128.4182 - mae: 9.21 - ETA: 19s - loss: 128.5798 - mae: 9.23 - ETA: 16s - loss: 128.9174 - mae: 9.24 - ETA: 13s - loss: 128.9394 - mae: 9.24 - ETA: 9s - loss: 128.8665 - mae: 9.2523 - ETA: 6s - loss: 129.0491 - mae: 9.254 - ETA: 3s - loss: 128.6193 - mae: 9.240 - ETA: 0s - loss: 128.5460 - mae: 9.237 - 539s 4s/step - loss: 128.5460 - mae: 9.2372 - val_loss: 123.2458 - val_mae: 8.9837\n",
      "\n",
      "Epoch 00012: saving model to CP_ResNet50_Sample100_Fine50_2\\cp-0012.ckpt\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - ETA: 7:52 - loss: 161.1959 - mae: 10.00 - ETA: 6:57 - loss: 150.4281 - mae: 9.8669 - ETA: 6:40 - loss: 135.4202 - mae: 9.084 - ETA: 6:23 - loss: 128.0938 - mae: 8.885 - ETA: 6:10 - loss: 126.2686 - mae: 8.935 - ETA: 5:58 - loss: 120.6532 - mae: 8.702 - ETA: 5:49 - loss: 123.5390 - mae: 8.928 - ETA: 5:42 - loss: 117.5814 - mae: 8.685 - ETA: 5:35 - loss: 118.6514 - mae: 8.685 - ETA: 5:28 - loss: 121.4699 - mae: 8.796 - ETA: 5:22 - loss: 121.2511 - mae: 8.819 - ETA: 5:17 - loss: 124.1466 - mae: 8.939 - ETA: 5:13 - loss: 123.8872 - mae: 8.935 - ETA: 5:08 - loss: 121.3691 - mae: 8.883 - ETA: 5:03 - loss: 120.7708 - mae: 8.849 - ETA: 4:59 - loss: 119.3669 - mae: 8.782 - ETA: 4:55 - loss: 123.6973 - mae: 8.954 - ETA: 4:52 - loss: 126.4650 - mae: 9.057 - ETA: 4:49 - loss: 125.5239 - mae: 9.008 - ETA: 4:46 - loss: 125.5179 - mae: 9.007 - ETA: 4:43 - loss: 127.1450 - mae: 9.060 - ETA: 4:41 - loss: 127.6331 - mae: 9.086 - ETA: 4:39 - loss: 128.3036 - mae: 9.110 - ETA: 4:39 - loss: 127.2911 - mae: 9.083 - ETA: 4:38 - loss: 126.7666 - mae: 9.059 - ETA: 4:39 - loss: 126.6077 - mae: 9.049 - ETA: 4:40 - loss: 125.4721 - mae: 9.007 - ETA: 4:41 - loss: 124.6160 - mae: 8.970 - ETA: 4:44 - loss: 124.6533 - mae: 8.989 - ETA: 4:47 - loss: 124.8417 - mae: 9.008 - ETA: 4:47 - loss: 126.2218 - mae: 9.083 - ETA: 4:47 - loss: 125.4055 - mae: 9.068 - ETA: 4:45 - loss: 125.2847 - mae: 9.071 - ETA: 4:43 - loss: 125.0952 - mae: 9.064 - ETA: 4:40 - loss: 126.7814 - mae: 9.112 - ETA: 4:37 - loss: 127.6050 - mae: 9.158 - ETA: 4:33 - loss: 128.0419 - mae: 9.175 - ETA: 4:29 - loss: 128.0164 - mae: 9.160 - ETA: 4:25 - loss: 127.6438 - mae: 9.154 - ETA: 4:22 - loss: 126.6562 - mae: 9.106 - ETA: 4:18 - loss: 126.9601 - mae: 9.124 - ETA: 4:14 - loss: 128.2094 - mae: 9.164 - ETA: 4:10 - loss: 127.5806 - mae: 9.134 - ETA: 4:06 - loss: 126.5829 - mae: 9.105 - ETA: 4:02 - loss: 127.3573 - mae: 9.147 - ETA: 3:59 - loss: 126.5287 - mae: 9.112 - ETA: 3:55 - loss: 127.1804 - mae: 9.125 - ETA: 3:51 - loss: 126.3566 - mae: 9.097 - ETA: 3:47 - loss: 125.5132 - mae: 9.062 - ETA: 3:44 - loss: 124.6939 - mae: 9.031 - ETA: 3:40 - loss: 125.5027 - mae: 9.067 - ETA: 3:37 - loss: 125.8495 - mae: 9.090 - ETA: 3:33 - loss: 125.9471 - mae: 9.092 - ETA: 3:30 - loss: 125.6417 - mae: 9.079 - ETA: 3:27 - loss: 125.5324 - mae: 9.066 - ETA: 3:24 - loss: 124.9838 - mae: 9.053 - ETA: 3:22 - loss: 124.6843 - mae: 9.052 - ETA: 3:19 - loss: 124.7123 - mae: 9.045 - ETA: 3:17 - loss: 124.5377 - mae: 9.045 - ETA: 3:15 - loss: 123.8880 - mae: 9.019 - ETA: 3:13 - loss: 124.7703 - mae: 9.041 - ETA: 3:12 - loss: 124.8405 - mae: 9.041 - ETA: 3:10 - loss: 124.6684 - mae: 9.040 - ETA: 3:08 - loss: 124.0641 - mae: 9.020 - ETA: 3:05 - loss: 123.4148 - mae: 9.002 - ETA: 3:02 - loss: 123.7349 - mae: 9.014 - ETA: 2:59 - loss: 124.1204 - mae: 9.020 - ETA: 2:56 - loss: 123.6719 - mae: 9.002 - ETA: 2:53 - loss: 123.5132 - mae: 9.002 - ETA: 2:49 - loss: 123.1996 - mae: 8.988 - ETA: 2:46 - loss: 122.6072 - mae: 8.962 - ETA: 2:42 - loss: 122.8045 - mae: 8.974 - ETA: 2:39 - loss: 122.7770 - mae: 8.976 - ETA: 2:36 - loss: 123.8776 - mae: 9.020 - ETA: 2:32 - loss: 124.7556 - mae: 9.051 - ETA: 2:29 - loss: 123.9004 - mae: 9.014 - ETA: 2:26 - loss: 124.5201 - mae: 9.040 - ETA: 2:22 - loss: 124.5565 - mae: 9.047 - ETA: 2:19 - loss: 124.6098 - mae: 9.048 - ETA: 2:16 - loss: 124.8777 - mae: 9.068 - ETA: 2:13 - loss: 125.4029 - mae: 9.084 - ETA: 2:09 - loss: 125.3315 - mae: 9.089 - ETA: 2:06 - loss: 125.1120 - mae: 9.077 - ETA: 2:03 - loss: 124.9980 - mae: 9.069 - ETA: 2:00 - loss: 124.7543 - mae: 9.065 - ETA: 1:57 - loss: 124.8905 - mae: 9.069 - ETA: 1:54 - loss: 124.8582 - mae: 9.072 - ETA: 1:51 - loss: 124.9051 - mae: 9.076 - ETA: 1:48 - loss: 125.1396 - mae: 9.088 - ETA: 1:45 - loss: 125.2460 - mae: 9.093 - ETA: 1:43 - loss: 125.7915 - mae: 9.115 - ETA: 1:40 - loss: 126.0146 - mae: 9.124 - ETA: 1:38 - loss: 126.1288 - mae: 9.131 - ETA: 1:35 - loss: 125.9152 - mae: 9.125 - ETA: 1:32 - loss: 125.7921 - mae: 9.118 - ETA: 1:29 - loss: 125.8371 - mae: 9.130 - ETA: 1:26 - loss: 126.7324 - mae: 9.162 - ETA: 1:23 - loss: 127.6621 - mae: 9.192 - ETA: 1:20 - loss: 127.7337 - mae: 9.200 - ETA: 1:17 - loss: 127.7873 - mae: 9.205 - ETA: 1:14 - loss: 127.7337 - mae: 9.196 - ETA: 1:11 - loss: 128.4539 - mae: 9.214 - ETA: 1:08 - loss: 128.3592 - mae: 9.216 - ETA: 1:04 - loss: 128.4019 - mae: 9.219 - ETA: 1:01 - loss: 128.1998 - mae: 9.215 - ETA: 58s - loss: 128.0942 - mae: 9.210 - ETA: 55s - loss: 127.8273 - mae: 9.19 - ETA: 52s - loss: 127.7313 - mae: 9.19 - ETA: 49s - loss: 127.5938 - mae: 9.18 - ETA: 45s - loss: 127.6158 - mae: 9.18 - ETA: 42s - loss: 127.6317 - mae: 9.18 - ETA: 39s - loss: 127.5657 - mae: 9.19 - ETA: 36s - loss: 127.3601 - mae: 9.18 - ETA: 33s - loss: 127.2586 - mae: 9.17 - ETA: 30s - loss: 127.2597 - mae: 9.16 - ETA: 27s - loss: 127.1455 - mae: 9.15 - ETA: 24s - loss: 127.5883 - mae: 9.17 - ETA: 21s - loss: 127.5639 - mae: 9.18 - ETA: 18s - loss: 127.4209 - mae: 9.17 - ETA: 15s - loss: 127.3163 - mae: 9.17 - ETA: 12s - loss: 127.2689 - mae: 9.17 - ETA: 9s - loss: 126.9147 - mae: 9.1630 - ETA: 6s - loss: 126.7180 - mae: 9.154 - ETA: 3s - loss: 126.8974 - mae: 9.162 - ETA: 0s - loss: 126.8130 - mae: 9.161 - 482s 4s/step - loss: 126.8130 - mae: 9.1614 - val_loss: 122.0285 - val_mae: 8.9262\n",
      "\n",
      "Epoch 00013: saving model to CP_ResNet50_Sample100_Fine50_2\\cp-0013.ckpt\n",
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - ETA: 7:58 - loss: 117.0731 - mae: 8.779 - ETA: 7:40 - loss: 116.5010 - mae: 8.846 - ETA: 7:09 - loss: 120.9179 - mae: 8.874 - ETA: 6:50 - loss: 122.1203 - mae: 8.894 - ETA: 6:29 - loss: 118.3354 - mae: 8.807 - ETA: 6:30 - loss: 116.8939 - mae: 8.747 - ETA: 6:22 - loss: 123.6965 - mae: 9.012 - ETA: 6:12 - loss: 120.1467 - mae: 8.811 - ETA: 6:00 - loss: 115.8727 - mae: 8.631 - ETA: 5:48 - loss: 119.0838 - mae: 8.805 - ETA: 5:38 - loss: 117.1114 - mae: 8.700 - ETA: 5:30 - loss: 119.1986 - mae: 8.755 - ETA: 5:22 - loss: 119.5443 - mae: 8.789 - ETA: 5:16 - loss: 119.6504 - mae: 8.815 - ETA: 5:10 - loss: 120.3424 - mae: 8.843 - ETA: 5:05 - loss: 121.7761 - mae: 8.894 - ETA: 4:59 - loss: 121.0320 - mae: 8.890 - ETA: 4:55 - loss: 123.3446 - mae: 9.002 - ETA: 4:50 - loss: 122.7493 - mae: 8.970 - ETA: 4:46 - loss: 121.9507 - mae: 8.955 - ETA: 4:42 - loss: 121.9479 - mae: 8.949 - ETA: 4:38 - loss: 123.6810 - mae: 8.976 - ETA: 4:35 - loss: 123.1312 - mae: 8.961 - ETA: 4:32 - loss: 124.3387 - mae: 9.015 - ETA: 4:29 - loss: 129.0809 - mae: 9.184 - ETA: 4:27 - loss: 129.9175 - mae: 9.212 - ETA: 4:25 - loss: 130.3895 - mae: 9.245 - ETA: 4:23 - loss: 129.1474 - mae: 9.199 - ETA: 4:22 - loss: 128.3074 - mae: 9.176 - ETA: 4:21 - loss: 128.2569 - mae: 9.173 - ETA: 4:21 - loss: 127.7921 - mae: 9.161 - ETA: 4:21 - loss: 129.0742 - mae: 9.180 - ETA: 4:22 - loss: 128.4986 - mae: 9.163 - ETA: 4:22 - loss: 129.2573 - mae: 9.190 - ETA: 4:20 - loss: 128.7192 - mae: 9.159 - ETA: 4:18 - loss: 127.6520 - mae: 9.109 - ETA: 4:16 - loss: 126.2372 - mae: 9.068 - ETA: 4:13 - loss: 126.2286 - mae: 9.071 - ETA: 4:10 - loss: 126.4249 - mae: 9.076 - ETA: 4:06 - loss: 125.6323 - mae: 9.050 - ETA: 4:03 - loss: 125.3526 - mae: 9.047 - ETA: 3:59 - loss: 125.5033 - mae: 9.056 - ETA: 3:56 - loss: 125.4368 - mae: 9.061 - ETA: 3:52 - loss: 125.7309 - mae: 9.070 - ETA: 3:49 - loss: 126.2219 - mae: 9.082 - ETA: 3:45 - loss: 125.8816 - mae: 9.094 - ETA: 3:41 - loss: 125.4299 - mae: 9.079 - ETA: 3:38 - loss: 125.4144 - mae: 9.073 - ETA: 3:34 - loss: 125.1725 - mae: 9.064 - ETA: 3:31 - loss: 125.8657 - mae: 9.095 - ETA: 3:28 - loss: 124.9809 - mae: 9.064 - ETA: 3:24 - loss: 124.7069 - mae: 9.065 - ETA: 3:21 - loss: 124.1362 - mae: 9.047 - ETA: 3:18 - loss: 125.0451 - mae: 9.073 - ETA: 3:15 - loss: 124.6317 - mae: 9.062 - ETA: 3:11 - loss: 123.8134 - mae: 9.028 - ETA: 3:08 - loss: 124.3873 - mae: 9.039 - ETA: 3:05 - loss: 124.6768 - mae: 9.060 - ETA: 3:02 - loss: 124.5543 - mae: 9.041 - ETA: 2:59 - loss: 124.8076 - mae: 9.043 - ETA: 2:56 - loss: 124.2104 - mae: 9.022 - ETA: 2:54 - loss: 124.6932 - mae: 9.035 - ETA: 2:51 - loss: 123.8543 - mae: 9.006 - ETA: 2:48 - loss: 123.1869 - mae: 8.986 - ETA: 2:46 - loss: 123.6530 - mae: 8.996 - ETA: 2:44 - loss: 123.1321 - mae: 8.971 - ETA: 2:42 - loss: 123.6943 - mae: 8.996 - ETA: 2:40 - loss: 123.5817 - mae: 8.992 - ETA: 2:38 - loss: 123.4454 - mae: 8.988 - ETA: 2:35 - loss: 123.5961 - mae: 9.000 - ETA: 2:33 - loss: 123.6259 - mae: 8.997 - ETA: 2:30 - loss: 124.0455 - mae: 9.007 - ETA: 2:27 - loss: 124.1335 - mae: 9.004 - ETA: 2:24 - loss: 124.1715 - mae: 9.014 - ETA: 2:21 - loss: 124.5789 - mae: 9.040 - ETA: 2:18 - loss: 125.1585 - mae: 9.061 - ETA: 2:15 - loss: 124.7464 - mae: 9.049 - ETA: 2:12 - loss: 125.3133 - mae: 9.077 - ETA: 2:09 - loss: 125.7811 - mae: 9.090 - ETA: 2:06 - loss: 125.5706 - mae: 9.086 - ETA: 2:03 - loss: 125.2927 - mae: 9.067 - ETA: 2:00 - loss: 125.4120 - mae: 9.072 - ETA: 1:57 - loss: 125.1026 - mae: 9.067 - ETA: 1:54 - loss: 124.9966 - mae: 9.063 - ETA: 1:51 - loss: 125.2136 - mae: 9.074 - ETA: 1:48 - loss: 125.4900 - mae: 9.093 - ETA: 1:45 - loss: 125.5968 - mae: 9.095 - ETA: 1:42 - loss: 125.7133 - mae: 9.098 - ETA: 1:40 - loss: 125.0752 - mae: 9.073 - ETA: 1:37 - loss: 125.1530 - mae: 9.080 - ETA: 1:34 - loss: 124.9338 - mae: 9.071 - ETA: 1:31 - loss: 124.9085 - mae: 9.068 - ETA: 1:28 - loss: 124.8922 - mae: 9.068 - ETA: 1:25 - loss: 125.2468 - mae: 9.082 - ETA: 1:22 - loss: 125.7345 - mae: 9.098 - ETA: 1:20 - loss: 125.3828 - mae: 9.089 - ETA: 1:17 - loss: 125.2016 - mae: 9.089 - ETA: 1:14 - loss: 124.7512 - mae: 9.071 - ETA: 1:12 - loss: 124.7679 - mae: 9.067 - ETA: 1:09 - loss: 125.0059 - mae: 9.083 - ETA: 1:06 - loss: 124.9971 - mae: 9.085 - ETA: 1:04 - loss: 125.2579 - mae: 9.097 - ETA: 1:01 - loss: 124.8480 - mae: 9.076 - ETA: 59s - loss: 125.1165 - mae: 9.090 - ETA: 56s - loss: 125.1793 - mae: 9.09 - ETA: 53s - loss: 124.9459 - mae: 9.08 - ETA: 50s - loss: 125.0405 - mae: 9.09 - ETA: 48s - loss: 124.6742 - mae: 9.07 - ETA: 45s - loss: 124.7727 - mae: 9.08 - ETA: 42s - loss: 124.9256 - mae: 9.08 - ETA: 39s - loss: 125.0818 - mae: 9.09 - ETA: 36s - loss: 125.0517 - mae: 9.09 - ETA: 33s - loss: 124.8460 - mae: 9.08 - ETA: 31s - loss: 125.2499 - mae: 9.10 - ETA: 28s - loss: 125.3208 - mae: 9.10 - ETA: 25s - loss: 125.3631 - mae: 9.10 - ETA: 22s - loss: 124.9791 - mae: 9.08 - ETA: 19s - loss: 124.9445 - mae: 9.09 - ETA: 16s - loss: 125.2447 - mae: 9.10 - ETA: 14s - loss: 125.2285 - mae: 9.10 - ETA: 11s - loss: 125.0876 - mae: 9.10 - ETA: 8s - loss: 124.9234 - mae: 9.1003 - ETA: 5s - loss: 125.7524 - mae: 9.129 - ETA: 2s - loss: 125.4613 - mae: 9.117 - ETA: 0s - loss: 125.6598 - mae: 9.127 - 438s 3s/step - loss: 125.6598 - mae: 9.1274 - val_loss: 121.6301 - val_mae: 8.9074\n",
      "\n",
      "Epoch 00014: saving model to CP_ResNet50_Sample100_Fine50_2\\cp-0014.ckpt\n",
      "Epoch 15/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - ETA: 5:22 - loss: 107.2320 - mae: 7.725 - ETA: 5:20 - loss: 102.9410 - mae: 7.749 - ETA: 5:06 - loss: 110.8954 - mae: 8.054 - ETA: 5:02 - loss: 105.8970 - mae: 8.057 - ETA: 5:00 - loss: 112.0563 - mae: 8.278 - ETA: 4:58 - loss: 109.1848 - mae: 8.272 - ETA: 4:57 - loss: 120.6452 - mae: 8.707 - ETA: 4:56 - loss: 121.7814 - mae: 8.753 - ETA: 4:55 - loss: 122.7142 - mae: 8.705 - ETA: 4:54 - loss: 119.6313 - mae: 8.644 - ETA: 4:54 - loss: 122.2003 - mae: 8.798 - ETA: 4:54 - loss: 123.6592 - mae: 8.877 - ETA: 4:57 - loss: 121.0955 - mae: 8.790 - ETA: 4:59 - loss: 123.4978 - mae: 8.901 - ETA: 5:04 - loss: 124.1431 - mae: 8.895 - ETA: 5:08 - loss: 124.3982 - mae: 8.935 - ETA: 5:11 - loss: 126.1637 - mae: 9.009 - ETA: 5:11 - loss: 122.0965 - mae: 8.842 - ETA: 5:09 - loss: 122.0832 - mae: 8.832 - ETA: 5:06 - loss: 123.1909 - mae: 8.900 - ETA: 5:03 - loss: 125.7191 - mae: 8.963 - ETA: 4:59 - loss: 126.1683 - mae: 9.021 - ETA: 4:55 - loss: 125.1125 - mae: 9.006 - ETA: 4:51 - loss: 125.0332 - mae: 8.995 - ETA: 4:47 - loss: 126.0282 - mae: 9.050 - ETA: 4:42 - loss: 127.1756 - mae: 9.087 - ETA: 4:39 - loss: 126.6768 - mae: 9.080 - ETA: 4:36 - loss: 126.4584 - mae: 9.064 - ETA: 4:33 - loss: 126.3679 - mae: 9.077 - ETA: 4:29 - loss: 125.6643 - mae: 9.053 - ETA: 4:25 - loss: 126.4530 - mae: 9.089 - ETA: 4:21 - loss: 125.4079 - mae: 9.042 - ETA: 4:18 - loss: 127.3611 - mae: 9.108 - ETA: 4:14 - loss: 126.6319 - mae: 9.083 - ETA: 4:11 - loss: 127.3825 - mae: 9.127 - ETA: 4:07 - loss: 127.2130 - mae: 9.127 - ETA: 4:04 - loss: 124.8557 - mae: 9.019 - ETA: 4:01 - loss: 125.2182 - mae: 9.034 - ETA: 3:58 - loss: 126.2297 - mae: 9.075 - ETA: 3:56 - loss: 126.6070 - mae: 9.080 - ETA: 3:53 - loss: 126.3430 - mae: 9.077 - ETA: 3:51 - loss: 125.9197 - mae: 9.079 - ETA: 3:50 - loss: 125.2597 - mae: 9.046 - ETA: 3:49 - loss: 124.8682 - mae: 9.032 - ETA: 3:48 - loss: 124.8365 - mae: 9.045 - ETA: 3:46 - loss: 125.0256 - mae: 9.068 - ETA: 3:44 - loss: 125.3878 - mae: 9.085 - ETA: 3:41 - loss: 124.6965 - mae: 9.069 - ETA: 3:39 - loss: 123.5256 - mae: 9.019 - ETA: 3:36 - loss: 123.2137 - mae: 9.021 - ETA: 3:33 - loss: 123.3436 - mae: 9.020 - ETA: 3:29 - loss: 123.3547 - mae: 9.027 - ETA: 3:26 - loss: 124.2961 - mae: 9.060 - ETA: 3:23 - loss: 125.2420 - mae: 9.084 - ETA: 3:19 - loss: 125.1993 - mae: 9.060 - ETA: 3:16 - loss: 124.1657 - mae: 9.021 - ETA: 3:13 - loss: 124.6686 - mae: 9.034 - ETA: 3:10 - loss: 125.4852 - mae: 9.060 - ETA: 3:06 - loss: 125.3471 - mae: 9.066 - ETA: 3:03 - loss: 125.4592 - mae: 9.072 - ETA: 3:00 - loss: 124.9888 - mae: 9.061 - ETA: 2:57 - loss: 124.3553 - mae: 9.034 - ETA: 2:54 - loss: 124.6020 - mae: 9.037 - ETA: 2:50 - loss: 125.5219 - mae: 9.061 - ETA: 2:47 - loss: 126.1283 - mae: 9.092 - ETA: 2:44 - loss: 125.4911 - mae: 9.071 - ETA: 2:41 - loss: 125.2160 - mae: 9.059 - ETA: 2:38 - loss: 125.0792 - mae: 9.064 - ETA: 2:35 - loss: 125.0976 - mae: 9.069 - ETA: 2:32 - loss: 124.1549 - mae: 9.034 - ETA: 2:29 - loss: 124.2789 - mae: 9.041 - ETA: 2:26 - loss: 124.4835 - mae: 9.046 - ETA: 2:24 - loss: 124.1215 - mae: 9.038 - ETA: 2:21 - loss: 123.8048 - mae: 9.031 - ETA: 2:18 - loss: 124.1769 - mae: 9.046 - ETA: 2:16 - loss: 124.5375 - mae: 9.064 - ETA: 2:14 - loss: 124.7226 - mae: 9.070 - ETA: 2:11 - loss: 124.5895 - mae: 9.069 - ETA: 2:09 - loss: 124.1627 - mae: 9.048 - ETA: 2:07 - loss: 124.5937 - mae: 9.072 - ETA: 2:05 - loss: 124.6123 - mae: 9.073 - ETA: 2:02 - loss: 124.3126 - mae: 9.066 - ETA: 1:59 - loss: 124.7395 - mae: 9.087 - ETA: 1:56 - loss: 124.5135 - mae: 9.069 - ETA: 1:53 - loss: 125.0971 - mae: 9.094 - ETA: 1:50 - loss: 124.9343 - mae: 9.083 - ETA: 1:47 - loss: 124.7391 - mae: 9.070 - ETA: 1:44 - loss: 125.1401 - mae: 9.086 - ETA: 1:41 - loss: 125.8184 - mae: 9.102 - ETA: 1:38 - loss: 126.8885 - mae: 9.144 - ETA: 1:35 - loss: 127.1356 - mae: 9.155 - ETA: 1:32 - loss: 126.9782 - mae: 9.150 - ETA: 1:29 - loss: 126.7988 - mae: 9.146 - ETA: 1:27 - loss: 126.7036 - mae: 9.143 - ETA: 1:24 - loss: 126.5559 - mae: 9.139 - ETA: 1:21 - loss: 126.7441 - mae: 9.154 - ETA: 1:18 - loss: 126.5627 - mae: 9.149 - ETA: 1:15 - loss: 126.6208 - mae: 9.156 - ETA: 1:12 - loss: 126.2959 - mae: 9.145 - ETA: 1:09 - loss: 126.3861 - mae: 9.147 - ETA: 1:06 - loss: 126.5217 - mae: 9.149 - ETA: 1:03 - loss: 126.9565 - mae: 9.164 - ETA: 1:01 - loss: 126.9439 - mae: 9.164 - ETA: 58s - loss: 126.9652 - mae: 9.168 - ETA: 55s - loss: 126.9284 - mae: 9.16 - ETA: 52s - loss: 126.9135 - mae: 9.16 - ETA: 49s - loss: 126.6426 - mae: 9.15 - ETA: 47s - loss: 126.5396 - mae: 9.15 - ETA: 44s - loss: 126.3939 - mae: 9.14 - ETA: 41s - loss: 126.3099 - mae: 9.14 - ETA: 39s - loss: 125.9811 - mae: 9.12 - ETA: 36s - loss: 126.0317 - mae: 9.13 - ETA: 33s - loss: 125.7464 - mae: 9.12 - ETA: 31s - loss: 125.5825 - mae: 9.11 - ETA: 28s - loss: 125.6582 - mae: 9.13 - ETA: 25s - loss: 125.9793 - mae: 9.14 - ETA: 22s - loss: 126.1191 - mae: 9.14 - ETA: 20s - loss: 126.4318 - mae: 9.16 - ETA: 17s - loss: 126.4426 - mae: 9.16 - ETA: 14s - loss: 126.1764 - mae: 9.15 - ETA: 11s - loss: 126.2670 - mae: 9.15 - ETA: 8s - loss: 126.2673 - mae: 9.1545 - ETA: 5s - loss: 126.4716 - mae: 9.161 - ETA: 2s - loss: 126.2947 - mae: 9.156 - ETA: 0s - loss: 126.6281 - mae: 9.165 - 468s 4s/step - loss: 126.6281 - mae: 9.1653 - val_loss: 120.3407 - val_mae: 8.8512\n",
      "\n",
      "Epoch 00015: saving model to CP_ResNet50_Sample100_Fine50_2\\cp-0015.ckpt\n",
      "Epoch 16/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - ETA: 5:20 - loss: 135.7001 - mae: 8.841 - ETA: 5:16 - loss: 148.2737 - mae: 9.832 - ETA: 5:16 - loss: 138.9186 - mae: 9.647 - ETA: 5:16 - loss: 128.9269 - mae: 9.356 - ETA: 5:18 - loss: 116.2316 - mae: 8.666 - ETA: 5:18 - loss: 116.6073 - mae: 8.737 - ETA: 5:19 - loss: 110.7918 - mae: 8.555 - ETA: 5:26 - loss: 112.6703 - mae: 8.670 - ETA: 5:34 - loss: 117.5420 - mae: 8.837 - ETA: 5:40 - loss: 116.7550 - mae: 8.838 - ETA: 5:43 - loss: 117.1851 - mae: 8.793 - ETA: 5:49 - loss: 114.8296 - mae: 8.687 - ETA: 5:56 - loss: 120.6784 - mae: 8.874 - ETA: 5:55 - loss: 123.2836 - mae: 9.003 - ETA: 5:52 - loss: 124.1326 - mae: 9.062 - ETA: 5:48 - loss: 123.2900 - mae: 9.037 - ETA: 5:43 - loss: 121.8742 - mae: 8.905 - ETA: 5:37 - loss: 123.1522 - mae: 8.947 - ETA: 5:31 - loss: 123.3282 - mae: 8.975 - ETA: 5:25 - loss: 123.1348 - mae: 8.959 - ETA: 5:19 - loss: 122.4094 - mae: 8.928 - ETA: 5:14 - loss: 124.0551 - mae: 9.018 - ETA: 5:08 - loss: 123.3761 - mae: 9.003 - ETA: 5:02 - loss: 121.6479 - mae: 8.925 - ETA: 4:57 - loss: 120.4227 - mae: 8.861 - ETA: 4:52 - loss: 120.7652 - mae: 8.868 - ETA: 4:47 - loss: 120.5351 - mae: 8.862 - ETA: 4:42 - loss: 122.5911 - mae: 8.915 - ETA: 4:38 - loss: 121.0697 - mae: 8.855 - ETA: 4:33 - loss: 121.8933 - mae: 8.887 - ETA: 4:29 - loss: 119.9973 - mae: 8.811 - ETA: 4:25 - loss: 120.1301 - mae: 8.812 - ETA: 4:21 - loss: 121.6645 - mae: 8.865 - ETA: 4:17 - loss: 120.8791 - mae: 8.832 - ETA: 4:13 - loss: 121.3251 - mae: 8.863 - ETA: 4:10 - loss: 121.7871 - mae: 8.886 - ETA: 4:06 - loss: 121.3337 - mae: 8.881 - ETA: 4:03 - loss: 121.6383 - mae: 8.874 - ETA: 4:00 - loss: 121.9270 - mae: 8.893 - ETA: 3:57 - loss: 122.1203 - mae: 8.896 - ETA: 3:55 - loss: 122.0737 - mae: 8.917 - ETA: 3:53 - loss: 122.2059 - mae: 8.916 - ETA: 3:51 - loss: 120.9967 - mae: 8.872 - ETA: 3:50 - loss: 121.3401 - mae: 8.869 - ETA: 3:49 - loss: 122.0461 - mae: 8.895 - ETA: 3:48 - loss: 122.2252 - mae: 8.896 - ETA: 3:46 - loss: 121.5293 - mae: 8.870 - ETA: 3:44 - loss: 122.1285 - mae: 8.899 - ETA: 3:42 - loss: 121.5617 - mae: 8.871 - ETA: 3:39 - loss: 122.2112 - mae: 8.901 - ETA: 3:36 - loss: 122.8340 - mae: 8.926 - ETA: 3:32 - loss: 123.4645 - mae: 8.956 - ETA: 3:29 - loss: 123.3671 - mae: 8.939 - ETA: 3:26 - loss: 123.1987 - mae: 8.933 - ETA: 3:23 - loss: 122.3866 - mae: 8.905 - ETA: 3:19 - loss: 122.1045 - mae: 8.900 - ETA: 3:16 - loss: 122.0096 - mae: 8.901 - ETA: 3:12 - loss: 122.1738 - mae: 8.913 - ETA: 3:09 - loss: 122.4629 - mae: 8.924 - ETA: 3:06 - loss: 121.7219 - mae: 8.898 - ETA: 3:02 - loss: 122.8018 - mae: 8.940 - ETA: 2:59 - loss: 122.2065 - mae: 8.922 - ETA: 2:56 - loss: 122.6642 - mae: 8.931 - ETA: 2:53 - loss: 122.9674 - mae: 8.940 - ETA: 2:49 - loss: 122.7280 - mae: 8.933 - ETA: 2:46 - loss: 122.0817 - mae: 8.909 - ETA: 2:43 - loss: 122.7307 - mae: 8.928 - ETA: 2:40 - loss: 122.3344 - mae: 8.912 - ETA: 2:37 - loss: 121.8632 - mae: 8.886 - ETA: 2:34 - loss: 121.5196 - mae: 8.877 - ETA: 2:31 - loss: 121.3325 - mae: 8.873 - ETA: 2:28 - loss: 121.3116 - mae: 8.877 - ETA: 2:25 - loss: 121.5464 - mae: 8.881 - ETA: 2:22 - loss: 121.9948 - mae: 8.906 - ETA: 2:20 - loss: 121.9158 - mae: 8.897 - ETA: 2:18 - loss: 121.6135 - mae: 8.888 - ETA: 2:16 - loss: 121.6278 - mae: 8.883 - ETA: 2:14 - loss: 122.3351 - mae: 8.911 - ETA: 2:12 - loss: 122.1921 - mae: 8.913 - ETA: 2:10 - loss: 122.7994 - mae: 8.934 - ETA: 2:07 - loss: 122.4696 - mae: 8.915 - ETA: 2:05 - loss: 123.1479 - mae: 8.946 - ETA: 2:02 - loss: 123.0024 - mae: 8.947 - ETA: 1:59 - loss: 123.1778 - mae: 8.954 - ETA: 1:56 - loss: 122.9609 - mae: 8.950 - ETA: 1:53 - loss: 123.4190 - mae: 8.964 - ETA: 1:50 - loss: 123.3354 - mae: 8.963 - ETA: 1:47 - loss: 123.7553 - mae: 8.977 - ETA: 1:44 - loss: 123.4723 - mae: 8.970 - ETA: 1:41 - loss: 122.9765 - mae: 8.947 - ETA: 1:38 - loss: 123.3573 - mae: 8.959 - ETA: 1:35 - loss: 123.1922 - mae: 8.950 - ETA: 1:32 - loss: 123.4040 - mae: 8.962 - ETA: 1:29 - loss: 123.4161 - mae: 8.961 - ETA: 1:26 - loss: 123.0943 - mae: 8.954 - ETA: 1:23 - loss: 123.7008 - mae: 8.967 - ETA: 1:20 - loss: 123.9291 - mae: 8.979 - ETA: 1:17 - loss: 124.1043 - mae: 8.982 - ETA: 1:14 - loss: 123.9078 - mae: 8.977 - ETA: 1:11 - loss: 123.6604 - mae: 8.968 - ETA: 1:08 - loss: 123.8643 - mae: 8.978 - ETA: 1:05 - loss: 124.5716 - mae: 9.000 - ETA: 1:02 - loss: 124.2509 - mae: 8.989 - ETA: 59s - loss: 124.4989 - mae: 8.993 - ETA: 56s - loss: 124.3837 - mae: 8.99 - ETA: 53s - loss: 123.7209 - mae: 8.96 - ETA: 51s - loss: 123.8123 - mae: 8.97 - ETA: 48s - loss: 124.0611 - mae: 8.98 - ETA: 45s - loss: 124.1156 - mae: 8.99 - ETA: 42s - loss: 124.3677 - mae: 9.00 - ETA: 39s - loss: 124.3920 - mae: 9.00 - ETA: 36s - loss: 123.9496 - mae: 8.98 - ETA: 34s - loss: 124.3785 - mae: 9.00 - ETA: 31s - loss: 124.1537 - mae: 8.99 - ETA: 28s - loss: 124.1684 - mae: 8.99 - ETA: 25s - loss: 124.0445 - mae: 8.99 - ETA: 22s - loss: 123.8759 - mae: 8.99 - ETA: 20s - loss: 123.9554 - mae: 9.00 - ETA: 17s - loss: 123.9965 - mae: 9.01 - ETA: 14s - loss: 123.8504 - mae: 9.00 - ETA: 11s - loss: 123.6925 - mae: 9.00 - ETA: 8s - loss: 124.3309 - mae: 9.0257 - ETA: 5s - loss: 124.3176 - mae: 9.027 - ETA: 2s - loss: 124.4043 - mae: 9.031 - ETA: 0s - loss: 124.1423 - mae: 9.018 - 440s 4s/step - loss: 124.1423 - mae: 9.0181 - val_loss: 121.8610 - val_mae: 8.9131\n",
      "\n",
      "Epoch 00016: saving model to CP_ResNet50_Sample100_Fine50_2\\cp-0016.ckpt\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - ETA: 5:25 - loss: 189.5283 - mae: 11.67 - ETA: 5:07 - loss: 161.5572 - mae: 10.59 - ETA: 5:01 - loss: 133.6814 - mae: 9.4864 - ETA: 4:57 - loss: 133.1228 - mae: 9.467 - ETA: 4:54 - loss: 134.5374 - mae: 9.533 - ETA: 4:51 - loss: 125.9692 - mae: 9.282 - ETA: 4:48 - loss: 132.9942 - mae: 9.571 - ETA: 4:45 - loss: 134.5859 - mae: 9.705 - ETA: 4:43 - loss: 127.9639 - mae: 9.353 - ETA: 4:44 - loss: 123.6673 - mae: 9.168 - ETA: 4:42 - loss: 127.6975 - mae: 9.343 - ETA: 4:39 - loss: 130.1373 - mae: 9.411 - ETA: 4:37 - loss: 129.1091 - mae: 9.363 - ETA: 4:36 - loss: 132.0032 - mae: 9.494 - ETA: 4:35 - loss: 126.8744 - mae: 9.281 - ETA: 4:33 - loss: 125.9534 - mae: 9.246 - ETA: 4:32 - loss: 125.0100 - mae: 9.198 - ETA: 4:31 - loss: 122.6483 - mae: 9.074 - ETA: 4:31 - loss: 120.6498 - mae: 8.966 - ETA: 4:31 - loss: 120.4948 - mae: 8.945 - ETA: 4:32 - loss: 123.2068 - mae: 9.017 - ETA: 4:34 - loss: 121.8964 - mae: 8.943 - ETA: 4:37 - loss: 124.0854 - mae: 9.030 - ETA: 4:39 - loss: 125.4844 - mae: 9.096 - ETA: 4:39 - loss: 124.4678 - mae: 9.063 - ETA: 4:39 - loss: 124.7470 - mae: 9.071 - ETA: 4:37 - loss: 127.6002 - mae: 9.188 - ETA: 4:35 - loss: 129.9499 - mae: 9.257 - ETA: 4:32 - loss: 130.0999 - mae: 9.249 - ETA: 4:29 - loss: 130.1580 - mae: 9.260 - ETA: 4:25 - loss: 129.3548 - mae: 9.228 - ETA: 4:22 - loss: 127.5342 - mae: 9.167 - ETA: 4:18 - loss: 126.8404 - mae: 9.126 - ETA: 4:15 - loss: 126.2534 - mae: 9.102 - ETA: 4:11 - loss: 125.6299 - mae: 9.095 - ETA: 4:07 - loss: 125.8578 - mae: 9.092 - ETA: 4:04 - loss: 125.9241 - mae: 9.093 - ETA: 4:00 - loss: 126.2692 - mae: 9.109 - ETA: 3:57 - loss: 126.1631 - mae: 9.119 - ETA: 3:53 - loss: 126.4286 - mae: 9.115 - ETA: 3:50 - loss: 126.0692 - mae: 9.102 - ETA: 3:46 - loss: 126.0514 - mae: 9.077 - ETA: 3:43 - loss: 125.2986 - mae: 9.048 - ETA: 3:40 - loss: 125.1122 - mae: 9.040 - ETA: 3:37 - loss: 125.3721 - mae: 9.060 - ETA: 3:33 - loss: 126.5760 - mae: 9.092 - ETA: 3:30 - loss: 127.0582 - mae: 9.127 - ETA: 3:27 - loss: 127.6930 - mae: 9.150 - ETA: 3:24 - loss: 127.0422 - mae: 9.136 - ETA: 3:21 - loss: 126.7024 - mae: 9.118 - ETA: 3:18 - loss: 126.3930 - mae: 9.127 - ETA: 3:15 - loss: 126.6104 - mae: 9.140 - ETA: 3:12 - loss: 126.8479 - mae: 9.157 - ETA: 3:10 - loss: 126.0560 - mae: 9.128 - ETA: 3:08 - loss: 124.8703 - mae: 9.077 - ETA: 3:06 - loss: 125.8884 - mae: 9.134 - ETA: 3:04 - loss: 126.0004 - mae: 9.133 - ETA: 3:02 - loss: 126.1253 - mae: 9.136 - ETA: 3:00 - loss: 125.4445 - mae: 9.109 - ETA: 2:58 - loss: 125.0563 - mae: 9.100 - ETA: 2:57 - loss: 124.8027 - mae: 9.091 - ETA: 2:54 - loss: 125.0755 - mae: 9.101 - ETA: 2:52 - loss: 125.0010 - mae: 9.095 - ETA: 2:49 - loss: 124.7608 - mae: 9.084 - ETA: 2:47 - loss: 125.2510 - mae: 9.101 - ETA: 2:44 - loss: 125.1963 - mae: 9.104 - ETA: 2:41 - loss: 125.0841 - mae: 9.104 - ETA: 2:38 - loss: 124.6472 - mae: 9.088 - ETA: 2:35 - loss: 124.4415 - mae: 9.079 - ETA: 2:32 - loss: 123.8511 - mae: 9.055 - ETA: 2:29 - loss: 124.4954 - mae: 9.071 - ETA: 2:26 - loss: 124.2536 - mae: 9.059 - ETA: 2:23 - loss: 123.7915 - mae: 9.037 - ETA: 2:20 - loss: 123.8153 - mae: 9.037 - ETA: 2:17 - loss: 123.8937 - mae: 9.040 - ETA: 2:14 - loss: 123.9513 - mae: 9.050 - ETA: 2:11 - loss: 123.8191 - mae: 9.047 - ETA: 2:08 - loss: 123.9650 - mae: 9.049 - ETA: 2:06 - loss: 124.5834 - mae: 9.069 - ETA: 2:03 - loss: 125.0427 - mae: 9.090 - ETA: 2:00 - loss: 124.9821 - mae: 9.086 - ETA: 1:58 - loss: 125.4720 - mae: 9.097 - ETA: 1:55 - loss: 125.2187 - mae: 9.092 - ETA: 1:52 - loss: 125.3234 - mae: 9.093 - ETA: 1:49 - loss: 125.6044 - mae: 9.109 - ETA: 1:47 - loss: 125.4048 - mae: 9.103 - ETA: 1:44 - loss: 125.3881 - mae: 9.108 - ETA: 1:42 - loss: 125.6868 - mae: 9.117 - ETA: 1:39 - loss: 125.7905 - mae: 9.122 - ETA: 1:37 - loss: 125.4874 - mae: 9.108 - ETA: 1:35 - loss: 125.2061 - mae: 9.099 - ETA: 1:33 - loss: 125.8283 - mae: 9.127 - ETA: 1:30 - loss: 125.8368 - mae: 9.136 - ETA: 1:28 - loss: 125.8147 - mae: 9.135 - ETA: 1:25 - loss: 125.8298 - mae: 9.138 - ETA: 1:22 - loss: 125.8744 - mae: 9.135 - ETA: 1:19 - loss: 125.3143 - mae: 9.116 - ETA: 1:17 - loss: 126.0810 - mae: 9.136 - ETA: 1:14 - loss: 126.0716 - mae: 9.140 - ETA: 1:11 - loss: 126.0185 - mae: 9.140 - ETA: 1:08 - loss: 126.5205 - mae: 9.157 - ETA: 1:05 - loss: 126.3998 - mae: 9.158 - ETA: 1:02 - loss: 126.3921 - mae: 9.159 - ETA: 59s - loss: 126.2784 - mae: 9.153 - ETA: 56s - loss: 125.8478 - mae: 9.13 - ETA: 53s - loss: 125.8134 - mae: 9.14 - ETA: 50s - loss: 125.8939 - mae: 9.14 - ETA: 47s - loss: 125.7618 - mae: 9.13 - ETA: 45s - loss: 125.4632 - mae: 9.12 - ETA: 42s - loss: 125.5770 - mae: 9.13 - ETA: 39s - loss: 126.0157 - mae: 9.14 - ETA: 36s - loss: 126.1010 - mae: 9.14 - ETA: 33s - loss: 126.3058 - mae: 9.15 - ETA: 30s - loss: 126.1038 - mae: 9.14 - ETA: 27s - loss: 125.9226 - mae: 9.14 - ETA: 25s - loss: 125.7117 - mae: 9.13 - ETA: 22s - loss: 125.5623 - mae: 9.13 - ETA: 19s - loss: 125.3444 - mae: 9.12 - ETA: 16s - loss: 125.7519 - mae: 9.14 - ETA: 13s - loss: 125.6134 - mae: 9.13 - ETA: 11s - loss: 125.6076 - mae: 9.13 - ETA: 8s - loss: 125.4467 - mae: 9.1396 - ETA: 5s - loss: 125.4699 - mae: 9.141 - ETA: 2s - loss: 125.5153 - mae: 9.144 - ETA: 0s - loss: 125.6575 - mae: 9.151 - 436s 3s/step - loss: 125.6575 - mae: 9.1518 - val_loss: 121.6898 - val_mae: 8.9003\n",
      "\n",
      "Epoch 00017: saving model to CP_ResNet50_Sample100_Fine50_2\\cp-0017.ckpt\n",
      "Epoch 18/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - ETA: 5:30 - loss: 130.9211 - mae: 9.640 - ETA: 5:26 - loss: 123.3595 - mae: 9.211 - ETA: 5:19 - loss: 129.6525 - mae: 9.068 - ETA: 5:17 - loss: 123.8708 - mae: 8.758 - ETA: 5:19 - loss: 123.0470 - mae: 8.658 - ETA: 5:19 - loss: 120.9490 - mae: 8.830 - ETA: 5:20 - loss: 128.6598 - mae: 9.115 - ETA: 5:22 - loss: 126.0828 - mae: 9.091 - ETA: 5:27 - loss: 123.5410 - mae: 9.043 - ETA: 5:32 - loss: 125.0994 - mae: 9.101 - ETA: 5:38 - loss: 122.1595 - mae: 8.972 - ETA: 5:42 - loss: 122.4334 - mae: 8.978 - ETA: 5:42 - loss: 121.5771 - mae: 8.972 - ETA: 5:40 - loss: 125.2209 - mae: 9.109 - ETA: 5:37 - loss: 126.4301 - mae: 9.144 - ETA: 5:32 - loss: 123.1846 - mae: 9.023 - ETA: 5:27 - loss: 122.6465 - mae: 9.006 - ETA: 5:22 - loss: 119.9939 - mae: 8.884 - ETA: 5:16 - loss: 121.0970 - mae: 8.941 - ETA: 5:11 - loss: 123.4821 - mae: 9.015 - ETA: 5:06 - loss: 125.3633 - mae: 9.085 - ETA: 5:00 - loss: 125.0800 - mae: 9.054 - ETA: 4:56 - loss: 124.0283 - mae: 9.044 - ETA: 4:50 - loss: 124.5676 - mae: 9.051 - ETA: 4:46 - loss: 125.0343 - mae: 9.087 - ETA: 4:41 - loss: 123.2541 - mae: 9.023 - ETA: 4:37 - loss: 122.9889 - mae: 9.005 - ETA: 4:32 - loss: 120.6323 - mae: 8.890 - ETA: 4:28 - loss: 120.3576 - mae: 8.880 - ETA: 4:24 - loss: 122.1532 - mae: 8.964 - ETA: 4:20 - loss: 122.5178 - mae: 8.975 - ETA: 4:17 - loss: 120.6073 - mae: 8.877 - ETA: 4:13 - loss: 120.5974 - mae: 8.907 - ETA: 4:09 - loss: 121.3195 - mae: 8.939 - ETA: 4:06 - loss: 120.3152 - mae: 8.902 - ETA: 4:02 - loss: 120.5976 - mae: 8.920 - ETA: 3:59 - loss: 120.3111 - mae: 8.917 - ETA: 3:56 - loss: 121.3762 - mae: 8.953 - ETA: 3:53 - loss: 122.7577 - mae: 8.975 - ETA: 3:50 - loss: 122.4432 - mae: 8.965 - ETA: 3:48 - loss: 121.7841 - mae: 8.938 - ETA: 3:45 - loss: 122.4552 - mae: 8.970 - ETA: 3:43 - loss: 122.2980 - mae: 8.961 - ETA: 3:41 - loss: 121.5186 - mae: 8.935 - ETA: 3:39 - loss: 120.4494 - mae: 8.900 - ETA: 3:38 - loss: 119.9121 - mae: 8.886 - ETA: 3:36 - loss: 121.0126 - mae: 8.933 - ETA: 3:34 - loss: 122.1290 - mae: 8.983 - ETA: 3:32 - loss: 122.1719 - mae: 8.973 - ETA: 3:30 - loss: 122.0157 - mae: 8.976 - ETA: 3:27 - loss: 122.5465 - mae: 8.990 - ETA: 3:24 - loss: 122.2888 - mae: 8.993 - ETA: 3:21 - loss: 123.3902 - mae: 9.022 - ETA: 3:18 - loss: 123.0375 - mae: 9.011 - ETA: 3:15 - loss: 123.1207 - mae: 9.025 - ETA: 3:12 - loss: 122.5444 - mae: 9.007 - ETA: 3:08 - loss: 122.8620 - mae: 9.019 - ETA: 3:05 - loss: 122.2582 - mae: 8.997 - ETA: 3:02 - loss: 122.2007 - mae: 8.986 - ETA: 2:59 - loss: 121.3598 - mae: 8.952 - ETA: 2:56 - loss: 122.1913 - mae: 8.990 - ETA: 2:53 - loss: 121.6937 - mae: 8.978 - ETA: 2:50 - loss: 122.0020 - mae: 8.985 - ETA: 2:47 - loss: 121.7968 - mae: 8.984 - ETA: 2:44 - loss: 122.3139 - mae: 8.996 - ETA: 2:41 - loss: 122.5477 - mae: 9.016 - ETA: 2:38 - loss: 122.9584 - mae: 9.031 - ETA: 2:35 - loss: 122.3260 - mae: 9.007 - ETA: 2:32 - loss: 122.2018 - mae: 9.005 - ETA: 2:29 - loss: 122.1367 - mae: 8.994 - ETA: 2:26 - loss: 121.9334 - mae: 8.989 - ETA: 2:24 - loss: 122.6391 - mae: 9.014 - ETA: 2:21 - loss: 122.4931 - mae: 9.008 - ETA: 2:18 - loss: 122.5773 - mae: 9.009 - ETA: 2:16 - loss: 122.4472 - mae: 9.009 - ETA: 2:14 - loss: 122.5754 - mae: 9.001 - ETA: 2:11 - loss: 122.3852 - mae: 8.990 - ETA: 2:09 - loss: 122.5619 - mae: 9.001 - ETA: 2:07 - loss: 122.7092 - mae: 9.014 - ETA: 2:05 - loss: 122.5055 - mae: 9.004 - ETA: 2:02 - loss: 122.4581 - mae: 9.001 - ETA: 1:59 - loss: 122.0551 - mae: 8.981 - ETA: 1:57 - loss: 123.2671 - mae: 9.013 - ETA: 1:54 - loss: 123.6600 - mae: 9.024 - ETA: 1:51 - loss: 123.1441 - mae: 9.004 - ETA: 1:48 - loss: 122.6959 - mae: 8.994 - ETA: 1:46 - loss: 122.9003 - mae: 9.004 - ETA: 1:43 - loss: 122.9034 - mae: 9.002 - ETA: 1:40 - loss: 123.4015 - mae: 9.025 - ETA: 1:37 - loss: 122.9049 - mae: 9.007 - ETA: 1:34 - loss: 123.1000 - mae: 9.012 - ETA: 1:31 - loss: 123.2340 - mae: 9.017 - ETA: 1:28 - loss: 123.7902 - mae: 9.033 - ETA: 1:25 - loss: 123.9444 - mae: 9.044 - ETA: 1:22 - loss: 123.5342 - mae: 9.031 - ETA: 1:20 - loss: 123.6510 - mae: 9.040 - ETA: 1:17 - loss: 123.3024 - mae: 9.022 - ETA: 1:14 - loss: 122.9542 - mae: 9.010 - ETA: 1:11 - loss: 123.1008 - mae: 9.021 - ETA: 1:08 - loss: 123.8527 - mae: 9.043 - ETA: 1:05 - loss: 124.0429 - mae: 9.055 - ETA: 1:03 - loss: 124.0749 - mae: 9.063 - ETA: 1:00 - loss: 124.5485 - mae: 9.086 - ETA: 57s - loss: 124.5199 - mae: 9.088 - ETA: 54s - loss: 124.2140 - mae: 9.08 - ETA: 52s - loss: 124.4379 - mae: 9.09 - ETA: 49s - loss: 124.2399 - mae: 9.08 - ETA: 46s - loss: 124.4681 - mae: 9.09 - ETA: 43s - loss: 124.1607 - mae: 9.08 - ETA: 41s - loss: 123.7682 - mae: 9.06 - ETA: 38s - loss: 123.6315 - mae: 9.05 - ETA: 35s - loss: 123.5372 - mae: 9.05 - ETA: 33s - loss: 123.3061 - mae: 9.04 - ETA: 30s - loss: 123.4498 - mae: 9.05 - ETA: 27s - loss: 123.0651 - mae: 9.03 - ETA: 25s - loss: 123.1243 - mae: 9.03 - ETA: 22s - loss: 123.6891 - mae: 9.05 - ETA: 19s - loss: 123.3246 - mae: 9.03 - ETA: 16s - loss: 123.1993 - mae: 9.03 - ETA: 13s - loss: 123.1048 - mae: 9.03 - ETA: 11s - loss: 122.8942 - mae: 9.02 - ETA: 8s - loss: 122.7918 - mae: 9.0281 - ETA: 5s - loss: 122.6865 - mae: 9.020 - ETA: 2s - loss: 122.4353 - mae: 9.007 - ETA: 0s - loss: 122.5955 - mae: 9.013 - 430s 3s/step - loss: 122.5955 - mae: 9.0137 - val_loss: 119.6733 - val_mae: 8.8178\n",
      "\n",
      "Epoch 00018: saving model to CP_ResNet50_Sample100_Fine50_2\\cp-0018.ckpt\n",
      "Epoch 19/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - ETA: 5:07 - loss: 80.4650 - mae: 7.47 - ETA: 5:27 - loss: 100.1640 - mae: 8.223 - ETA: 5:11 - loss: 101.4666 - mae: 8.305 - ETA: 5:05 - loss: 103.9581 - mae: 8.401 - ETA: 4:59 - loss: 114.7231 - mae: 8.773 - ETA: 4:55 - loss: 111.8860 - mae: 8.760 - ETA: 4:52 - loss: 110.2206 - mae: 8.667 - ETA: 4:48 - loss: 111.4311 - mae: 8.711 - ETA: 4:45 - loss: 118.1817 - mae: 8.897 - ETA: 4:42 - loss: 117.1324 - mae: 8.833 - ETA: 4:39 - loss: 118.9277 - mae: 8.920 - ETA: 4:37 - loss: 119.9568 - mae: 8.934 - ETA: 4:35 - loss: 118.0051 - mae: 8.841 - ETA: 4:33 - loss: 120.8815 - mae: 8.927 - ETA: 4:32 - loss: 121.8235 - mae: 8.980 - ETA: 4:30 - loss: 122.7814 - mae: 9.003 - ETA: 4:28 - loss: 124.2529 - mae: 9.066 - ETA: 4:27 - loss: 122.9154 - mae: 8.975 - ETA: 4:26 - loss: 124.9001 - mae: 9.004 - ETA: 4:26 - loss: 124.8319 - mae: 8.988 - ETA: 4:25 - loss: 127.2279 - mae: 9.098 - ETA: 4:26 - loss: 125.8430 - mae: 9.051 - ETA: 4:28 - loss: 125.9202 - mae: 9.044 - ETA: 4:30 - loss: 125.3383 - mae: 9.026 - ETA: 4:33 - loss: 125.9937 - mae: 9.052 - ETA: 4:34 - loss: 126.3028 - mae: 9.051 - ETA: 4:33 - loss: 125.8733 - mae: 9.014 - ETA: 4:32 - loss: 125.5362 - mae: 9.015 - ETA: 4:30 - loss: 125.8433 - mae: 9.022 - ETA: 4:27 - loss: 124.8033 - mae: 9.006 - ETA: 4:24 - loss: 123.7996 - mae: 8.966 - ETA: 4:21 - loss: 122.0488 - mae: 8.894 - ETA: 4:17 - loss: 122.6849 - mae: 8.900 - ETA: 4:14 - loss: 122.2538 - mae: 8.872 - ETA: 4:10 - loss: 122.5367 - mae: 8.857 - ETA: 4:07 - loss: 121.4974 - mae: 8.825 - ETA: 4:03 - loss: 120.8058 - mae: 8.808 - ETA: 4:00 - loss: 122.3923 - mae: 8.878 - ETA: 3:56 - loss: 122.8102 - mae: 8.894 - ETA: 3:53 - loss: 123.6479 - mae: 8.944 - ETA: 3:50 - loss: 122.3069 - mae: 8.907 - ETA: 3:48 - loss: 122.1081 - mae: 8.899 - ETA: 3:45 - loss: 122.8835 - mae: 8.940 - ETA: 3:42 - loss: 123.3356 - mae: 8.962 - ETA: 3:39 - loss: 123.9372 - mae: 8.991 - ETA: 3:36 - loss: 124.2042 - mae: 9.007 - ETA: 3:33 - loss: 123.6352 - mae: 8.987 - ETA: 3:30 - loss: 123.1020 - mae: 8.974 - ETA: 3:27 - loss: 122.5534 - mae: 8.956 - ETA: 3:25 - loss: 121.7231 - mae: 8.918 - ETA: 3:22 - loss: 121.1535 - mae: 8.901 - ETA: 3:20 - loss: 121.3608 - mae: 8.910 - ETA: 3:18 - loss: 122.0653 - mae: 8.929 - ETA: 3:16 - loss: 122.0504 - mae: 8.931 - ETA: 3:14 - loss: 121.3670 - mae: 8.898 - ETA: 3:13 - loss: 121.1305 - mae: 8.898 - ETA: 3:11 - loss: 120.6642 - mae: 8.883 - ETA: 3:08 - loss: 120.1304 - mae: 8.869 - ETA: 3:06 - loss: 121.0927 - mae: 8.913 - ETA: 3:03 - loss: 120.6625 - mae: 8.891 - ETA: 3:00 - loss: 120.4575 - mae: 8.880 - ETA: 2:57 - loss: 121.4029 - mae: 8.908 - ETA: 2:54 - loss: 121.6399 - mae: 8.919 - ETA: 2:51 - loss: 121.5976 - mae: 8.910 - ETA: 2:48 - loss: 121.6450 - mae: 8.909 - ETA: 2:45 - loss: 121.6465 - mae: 8.908 - ETA: 2:42 - loss: 121.6600 - mae: 8.918 - ETA: 2:39 - loss: 122.4573 - mae: 8.942 - ETA: 2:36 - loss: 122.3573 - mae: 8.932 - ETA: 2:33 - loss: 121.9366 - mae: 8.915 - ETA: 2:30 - loss: 122.5001 - mae: 8.939 - ETA: 2:27 - loss: 122.7909 - mae: 8.960 - ETA: 2:24 - loss: 122.6360 - mae: 8.947 - ETA: 2:21 - loss: 122.1023 - mae: 8.926 - ETA: 2:18 - loss: 122.3472 - mae: 8.942 - ETA: 2:15 - loss: 122.7017 - mae: 8.951 - ETA: 2:12 - loss: 123.2787 - mae: 8.968 - ETA: 2:09 - loss: 122.9999 - mae: 8.961 - ETA: 2:06 - loss: 122.8322 - mae: 8.958 - ETA: 2:03 - loss: 122.6882 - mae: 8.950 - ETA: 2:00 - loss: 122.4544 - mae: 8.948 - ETA: 1:57 - loss: 122.8972 - mae: 8.969 - ETA: 1:54 - loss: 122.8377 - mae: 8.968 - ETA: 1:52 - loss: 123.0404 - mae: 8.973 - ETA: 1:49 - loss: 122.6952 - mae: 8.960 - ETA: 1:46 - loss: 122.4547 - mae: 8.953 - ETA: 1:43 - loss: 122.3192 - mae: 8.956 - ETA: 1:41 - loss: 122.5381 - mae: 8.966 - ETA: 1:39 - loss: 122.7277 - mae: 8.978 - ETA: 1:36 - loss: 123.3338 - mae: 9.000 - ETA: 1:34 - loss: 123.2605 - mae: 8.994 - ETA: 1:31 - loss: 123.2349 - mae: 8.999 - ETA: 1:29 - loss: 123.5290 - mae: 9.009 - ETA: 1:26 - loss: 123.5832 - mae: 9.012 - ETA: 1:23 - loss: 123.4420 - mae: 9.002 - ETA: 1:21 - loss: 123.9781 - mae: 9.026 - ETA: 1:18 - loss: 123.7734 - mae: 9.019 - ETA: 1:15 - loss: 123.7770 - mae: 9.022 - ETA: 1:12 - loss: 123.8168 - mae: 9.032 - ETA: 1:09 - loss: 123.8009 - mae: 9.037 - ETA: 1:06 - loss: 124.0196 - mae: 9.043 - ETA: 1:04 - loss: 123.8636 - mae: 9.034 - ETA: 1:01 - loss: 124.1254 - mae: 9.044 - ETA: 58s - loss: 123.9082 - mae: 9.035 - ETA: 55s - loss: 123.6401 - mae: 9.02 - ETA: 52s - loss: 123.5206 - mae: 9.01 - ETA: 49s - loss: 123.3691 - mae: 9.01 - ETA: 47s - loss: 123.0185 - mae: 9.00 - ETA: 44s - loss: 123.5663 - mae: 9.01 - ETA: 41s - loss: 123.9674 - mae: 9.02 - ETA: 38s - loss: 124.1375 - mae: 9.04 - ETA: 35s - loss: 123.7846 - mae: 9.02 - ETA: 33s - loss: 123.4825 - mae: 9.01 - ETA: 30s - loss: 123.3217 - mae: 9.00 - ETA: 27s - loss: 123.1047 - mae: 8.99 - ETA: 24s - loss: 122.9897 - mae: 8.99 - ETA: 21s - loss: 122.5908 - mae: 8.97 - ETA: 19s - loss: 122.4705 - mae: 8.97 - ETA: 16s - loss: 122.8122 - mae: 8.99 - ETA: 13s - loss: 123.0463 - mae: 9.00 - ETA: 10s - loss: 123.3579 - mae: 9.01 - ETA: 8s - loss: 123.2898 - mae: 9.0126 - ETA: 5s - loss: 123.0978 - mae: 9.010 - ETA: 2s - loss: 123.1348 - mae: 9.010 - ETA: 0s - loss: 123.0925 - mae: 9.012 - 448s 4s/step - loss: 123.0925 - mae: 9.0128 - val_loss: 120.0140 - val_mae: 8.8234\n",
      "\n",
      "Epoch 00019: saving model to CP_ResNet50_Sample100_Fine50_2\\cp-0019.ckpt\n",
      "Epoch 20/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - ETA: 8:42 - loss: 129.8353 - mae: 9.310 - ETA: 9:28 - loss: 120.0188 - mae: 8.878 - ETA: 9:01 - loss: 114.5200 - mae: 8.757 - ETA: 8:31 - loss: 115.0009 - mae: 8.732 - ETA: 8:06 - loss: 112.5402 - mae: 8.498 - ETA: 7:44 - loss: 116.7281 - mae: 8.734 - ETA: 7:24 - loss: 114.5209 - mae: 8.592 - ETA: 7:05 - loss: 119.8460 - mae: 8.790 - ETA: 6:50 - loss: 120.1329 - mae: 8.788 - ETA: 6:37 - loss: 119.9104 - mae: 8.748 - ETA: 6:25 - loss: 117.8375 - mae: 8.640 - ETA: 6:14 - loss: 116.9190 - mae: 8.611 - ETA: 6:05 - loss: 119.8520 - mae: 8.688 - ETA: 5:56 - loss: 118.1357 - mae: 8.673 - ETA: 5:47 - loss: 118.3163 - mae: 8.673 - ETA: 5:40 - loss: 116.9066 - mae: 8.629 - ETA: 5:33 - loss: 116.1540 - mae: 8.620 - ETA: 5:27 - loss: 117.9133 - mae: 8.683 - ETA: 5:21 - loss: 119.1811 - mae: 8.728 - ETA: 5:15 - loss: 120.5765 - mae: 8.803 - ETA: 5:11 - loss: 120.2139 - mae: 8.769 - ETA: 5:07 - loss: 120.9694 - mae: 8.793 - ETA: 5:03 - loss: 124.9463 - mae: 8.940 - ETA: 5:01 - loss: 125.8914 - mae: 8.990 - ETA: 4:57 - loss: 123.5615 - mae: 8.905 - ETA: 4:53 - loss: 123.1344 - mae: 8.915 - ETA: 4:50 - loss: 123.4574 - mae: 8.896 - ETA: 4:47 - loss: 123.1093 - mae: 8.896 - ETA: 4:45 - loss: 122.1259 - mae: 8.851 - ETA: 4:44 - loss: 123.1162 - mae: 8.896 - ETA: 4:44 - loss: 123.5083 - mae: 8.919 - ETA: 4:44 - loss: 123.2339 - mae: 8.910 - ETA: 4:45 - loss: 122.0995 - mae: 8.874 - ETA: 4:45 - loss: 122.0906 - mae: 8.862 - ETA: 4:43 - loss: 122.1567 - mae: 8.857 - ETA: 4:40 - loss: 122.7487 - mae: 8.875 - ETA: 4:37 - loss: 123.7160 - mae: 8.914 - ETA: 4:34 - loss: 123.3582 - mae: 8.906 - ETA: 4:30 - loss: 122.2815 - mae: 8.869 - ETA: 4:26 - loss: 123.1169 - mae: 8.881 - ETA: 4:22 - loss: 122.1861 - mae: 8.842 - ETA: 4:18 - loss: 121.8923 - mae: 8.823 - ETA: 4:14 - loss: 122.0786 - mae: 8.830 - ETA: 4:10 - loss: 121.5569 - mae: 8.823 - ETA: 4:07 - loss: 122.3522 - mae: 8.868 - ETA: 4:03 - loss: 122.6105 - mae: 8.886 - ETA: 3:59 - loss: 122.5996 - mae: 8.889 - ETA: 3:56 - loss: 123.0572 - mae: 8.907 - ETA: 3:52 - loss: 123.1462 - mae: 8.924 - ETA: 3:48 - loss: 122.9688 - mae: 8.931 - ETA: 3:44 - loss: 122.9664 - mae: 8.925 - ETA: 3:41 - loss: 122.3559 - mae: 8.914 - ETA: 3:37 - loss: 122.5731 - mae: 8.926 - ETA: 3:34 - loss: 122.7292 - mae: 8.924 - ETA: 3:31 - loss: 122.0215 - mae: 8.904 - ETA: 3:28 - loss: 121.8995 - mae: 8.901 - ETA: 3:25 - loss: 121.8443 - mae: 8.902 - ETA: 3:23 - loss: 121.9748 - mae: 8.904 - ETA: 3:20 - loss: 122.6774 - mae: 8.925 - ETA: 3:18 - loss: 122.5873 - mae: 8.919 - ETA: 3:17 - loss: 122.3713 - mae: 8.913 - ETA: 3:15 - loss: 122.1809 - mae: 8.896 - ETA: 3:13 - loss: 121.8665 - mae: 8.890 - ETA: 3:10 - loss: 121.5391 - mae: 8.882 - ETA: 3:07 - loss: 122.1077 - mae: 8.915 - ETA: 3:04 - loss: 121.9585 - mae: 8.898 - ETA: 3:01 - loss: 121.8228 - mae: 8.893 - ETA: 2:58 - loss: 122.3711 - mae: 8.919 - ETA: 2:54 - loss: 122.2911 - mae: 8.917 - ETA: 2:51 - loss: 121.3569 - mae: 8.877 - ETA: 2:48 - loss: 121.0586 - mae: 8.863 - ETA: 2:44 - loss: 121.2993 - mae: 8.865 - ETA: 2:41 - loss: 121.3643 - mae: 8.877 - ETA: 2:37 - loss: 120.8615 - mae: 8.859 - ETA: 2:34 - loss: 121.0655 - mae: 8.871 - ETA: 2:30 - loss: 121.3798 - mae: 8.880 - ETA: 2:27 - loss: 120.9341 - mae: 8.867 - ETA: 2:24 - loss: 121.0035 - mae: 8.875 - ETA: 2:20 - loss: 121.2165 - mae: 8.882 - ETA: 2:17 - loss: 121.2717 - mae: 8.886 - ETA: 2:14 - loss: 121.5524 - mae: 8.895 - ETA: 2:10 - loss: 121.2043 - mae: 8.882 - ETA: 2:07 - loss: 121.4707 - mae: 8.888 - ETA: 2:04 - loss: 122.3687 - mae: 8.927 - ETA: 2:01 - loss: 122.0648 - mae: 8.918 - ETA: 1:57 - loss: 122.7544 - mae: 8.942 - ETA: 1:54 - loss: 123.1107 - mae: 8.949 - ETA: 1:52 - loss: 123.0716 - mae: 8.957 - ETA: 1:49 - loss: 123.2903 - mae: 8.973 - ETA: 1:46 - loss: 123.2760 - mae: 8.977 - ETA: 1:43 - loss: 123.1377 - mae: 8.972 - ETA: 1:41 - loss: 123.0653 - mae: 8.974 - ETA: 1:38 - loss: 122.9202 - mae: 8.974 - ETA: 1:36 - loss: 123.0094 - mae: 8.979 - ETA: 1:33 - loss: 122.5974 - mae: 8.966 - ETA: 1:30 - loss: 122.5389 - mae: 8.966 - ETA: 1:27 - loss: 122.2663 - mae: 8.961 - ETA: 1:24 - loss: 122.2733 - mae: 8.954 - ETA: 1:21 - loss: 122.4887 - mae: 8.970 - ETA: 1:18 - loss: 122.5164 - mae: 8.970 - ETA: 1:15 - loss: 123.0284 - mae: 8.990 - ETA: 1:12 - loss: 122.8164 - mae: 8.982 - ETA: 1:08 - loss: 122.8036 - mae: 8.984 - ETA: 1:05 - loss: 123.4043 - mae: 9.005 - ETA: 1:02 - loss: 123.9188 - mae: 9.025 - ETA: 59s - loss: 123.6963 - mae: 9.020 - ETA: 56s - loss: 123.8809 - mae: 9.01 - ETA: 52s - loss: 123.5244 - mae: 9.00 - ETA: 49s - loss: 123.3702 - mae: 8.99 - ETA: 46s - loss: 123.3549 - mae: 8.99 - ETA: 43s - loss: 123.7822 - mae: 9.00 - ETA: 40s - loss: 123.8579 - mae: 9.01 - ETA: 36s - loss: 123.5807 - mae: 9.00 - ETA: 33s - loss: 123.1836 - mae: 8.98 - ETA: 30s - loss: 123.2900 - mae: 8.98 - ETA: 27s - loss: 123.3545 - mae: 8.99 - ETA: 24s - loss: 123.5115 - mae: 9.00 - ETA: 21s - loss: 123.2222 - mae: 8.99 - ETA: 18s - loss: 123.1527 - mae: 8.99 - ETA: 15s - loss: 122.9314 - mae: 8.98 - ETA: 12s - loss: 122.9100 - mae: 8.99 - ETA: 9s - loss: 122.8472 - mae: 8.9885 - ETA: 6s - loss: 122.7065 - mae: 8.983 - ETA: 3s - loss: 122.9229 - mae: 8.996 - ETA: 0s - loss: 122.9863 - mae: 9.000 - 498s 4s/step - loss: 122.9863 - mae: 9.0000 - val_loss: 118.7670 - val_mae: 8.7658\n",
      "\n",
      "Epoch 00020: saving model to CP_ResNet50_Sample100_Fine50_2\\cp-0020.ckpt\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - ETA: 6:23 - loss: 137.2866 - mae: 9.771 - ETA: 6:20 - loss: 130.1322 - mae: 9.400 - ETA: 6:08 - loss: 129.0970 - mae: 9.084 - ETA: 5:55 - loss: 127.3444 - mae: 9.196 - ETA: 5:46 - loss: 128.8769 - mae: 9.411 - ETA: 5:40 - loss: 126.4282 - mae: 9.399 - ETA: 5:34 - loss: 126.5307 - mae: 9.368 - ETA: 5:28 - loss: 128.2016 - mae: 9.368 - ETA: 5:22 - loss: 122.9863 - mae: 9.088 - ETA: 5:16 - loss: 121.8891 - mae: 8.979 - ETA: 5:11 - loss: 117.2936 - mae: 8.784 - ETA: 5:07 - loss: 118.8263 - mae: 8.791 - ETA: 5:03 - loss: 117.6852 - mae: 8.745 - ETA: 4:59 - loss: 122.1830 - mae: 8.874 - ETA: 4:55 - loss: 121.4394 - mae: 8.855 - ETA: 4:52 - loss: 120.5736 - mae: 8.888 - ETA: 4:49 - loss: 120.5290 - mae: 8.859 - ETA: 4:47 - loss: 122.4163 - mae: 8.918 - ETA: 4:44 - loss: 121.4228 - mae: 8.916 - ETA: 4:42 - loss: 123.7351 - mae: 9.006 - ETA: 4:40 - loss: 126.6700 - mae: 9.095 - ETA: 4:39 - loss: 126.3435 - mae: 9.077 - ETA: 4:38 - loss: 127.9802 - mae: 9.097 - ETA: 4:38 - loss: 126.4326 - mae: 9.034 - ETA: 4:38 - loss: 127.2081 - mae: 9.068 - ETA: 4:40 - loss: 126.6516 - mae: 9.032 - ETA: 4:44 - loss: 125.0097 - mae: 8.977 - ETA: 4:47 - loss: 122.9861 - mae: 8.908 - ETA: 4:49 - loss: 122.1124 - mae: 8.861 - ETA: 4:49 - loss: 121.6376 - mae: 8.852 - ETA: 4:49 - loss: 121.7068 - mae: 8.852 - ETA: 4:46 - loss: 121.9762 - mae: 8.875 - ETA: 4:45 - loss: 123.6949 - mae: 8.924 - ETA: 4:42 - loss: 124.2092 - mae: 8.956 - ETA: 4:39 - loss: 124.3970 - mae: 8.962 - ETA: 4:35 - loss: 123.9192 - mae: 8.945 - ETA: 4:31 - loss: 123.7221 - mae: 8.945 - ETA: 4:27 - loss: 122.8976 - mae: 8.918 - ETA: 4:23 - loss: 121.7146 - mae: 8.868 - ETA: 4:19 - loss: 123.0019 - mae: 8.906 - ETA: 4:15 - loss: 122.3932 - mae: 8.871 - ETA: 4:11 - loss: 122.1871 - mae: 8.883 - ETA: 4:07 - loss: 121.5633 - mae: 8.856 - ETA: 4:03 - loss: 121.7351 - mae: 8.866 - ETA: 4:00 - loss: 121.7829 - mae: 8.873 - ETA: 3:56 - loss: 121.7888 - mae: 8.873 - ETA: 3:52 - loss: 120.8030 - mae: 8.837 - ETA: 3:49 - loss: 120.8418 - mae: 8.843 - ETA: 3:45 - loss: 120.2828 - mae: 8.836 - ETA: 3:42 - loss: 119.8644 - mae: 8.823 - ETA: 3:38 - loss: 120.2664 - mae: 8.818 - ETA: 3:35 - loss: 120.8620 - mae: 8.857 - ETA: 3:32 - loss: 120.7307 - mae: 8.859 - ETA: 3:28 - loss: 122.1136 - mae: 8.911 - ETA: 3:26 - loss: 121.3854 - mae: 8.876 - ETA: 3:23 - loss: 121.7485 - mae: 8.904 - ETA: 3:20 - loss: 120.9563 - mae: 8.872 - ETA: 3:18 - loss: 121.2255 - mae: 8.885 - ETA: 3:16 - loss: 120.9525 - mae: 8.869 - ETA: 3:14 - loss: 120.6937 - mae: 8.854 - ETA: 3:13 - loss: 120.1715 - mae: 8.835 - ETA: 3:11 - loss: 119.8612 - mae: 8.824 - ETA: 3:09 - loss: 120.3370 - mae: 8.841 - ETA: 3:07 - loss: 120.0741 - mae: 8.835 - ETA: 3:04 - loss: 120.7379 - mae: 8.852 - ETA: 3:01 - loss: 120.4428 - mae: 8.843 - ETA: 2:58 - loss: 120.2311 - mae: 8.837 - ETA: 2:55 - loss: 119.8225 - mae: 8.819 - ETA: 2:52 - loss: 120.0090 - mae: 8.825 - ETA: 2:48 - loss: 120.6906 - mae: 8.846 - ETA: 2:45 - loss: 120.7630 - mae: 8.853 - ETA: 2:41 - loss: 120.2823 - mae: 8.827 - ETA: 2:38 - loss: 120.3672 - mae: 8.832 - ETA: 2:35 - loss: 120.1090 - mae: 8.822 - ETA: 2:31 - loss: 120.0191 - mae: 8.825 - ETA: 2:28 - loss: 120.5778 - mae: 8.851 - ETA: 2:25 - loss: 121.8191 - mae: 8.895 - ETA: 2:21 - loss: 121.3220 - mae: 8.877 - ETA: 2:18 - loss: 120.9854 - mae: 8.862 - ETA: 2:15 - loss: 121.3855 - mae: 8.886 - ETA: 2:12 - loss: 121.3313 - mae: 8.882 - ETA: 2:08 - loss: 121.4145 - mae: 8.888 - ETA: 2:05 - loss: 121.1966 - mae: 8.879 - ETA: 2:02 - loss: 121.8953 - mae: 8.904 - ETA: 1:59 - loss: 121.6984 - mae: 8.898 - ETA: 1:56 - loss: 121.7064 - mae: 8.904 - ETA: 1:53 - loss: 122.1890 - mae: 8.921 - ETA: 1:50 - loss: 121.9657 - mae: 8.911 - ETA: 1:47 - loss: 121.5492 - mae: 8.893 - ETA: 1:45 - loss: 121.4778 - mae: 8.899 - ETA: 1:42 - loss: 121.6945 - mae: 8.905 - ETA: 1:39 - loss: 121.7434 - mae: 8.901 - ETA: 1:36 - loss: 122.0572 - mae: 8.909 - ETA: 1:34 - loss: 122.0358 - mae: 8.903 - ETA: 1:31 - loss: 122.9884 - mae: 8.941 - ETA: 1:29 - loss: 123.3235 - mae: 8.957 - ETA: 1:26 - loss: 123.3891 - mae: 8.965 - ETA: 1:23 - loss: 123.2609 - mae: 8.970 - ETA: 1:20 - loss: 123.1182 - mae: 8.966 - ETA: 1:17 - loss: 123.5339 - mae: 8.977 - ETA: 1:14 - loss: 123.4402 - mae: 8.978 - ETA: 1:11 - loss: 124.1431 - mae: 9.002 - ETA: 1:07 - loss: 123.9510 - mae: 8.998 - ETA: 1:04 - loss: 124.2336 - mae: 9.007 - ETA: 1:01 - loss: 124.3537 - mae: 9.017 - ETA: 58s - loss: 124.1081 - mae: 9.007 - ETA: 55s - loss: 124.0716 - mae: 9.00 - ETA: 51s - loss: 123.9213 - mae: 9.00 - ETA: 48s - loss: 124.0369 - mae: 9.00 - ETA: 45s - loss: 123.6915 - mae: 8.99 - ETA: 42s - loss: 123.7384 - mae: 8.99 - ETA: 39s - loss: 123.3168 - mae: 8.97 - ETA: 36s - loss: 123.1294 - mae: 8.96 - ETA: 33s - loss: 122.9552 - mae: 8.96 - ETA: 30s - loss: 122.6355 - mae: 8.95 - ETA: 27s - loss: 122.5722 - mae: 8.95 - ETA: 24s - loss: 122.5173 - mae: 8.96 - ETA: 21s - loss: 122.8038 - mae: 8.96 - ETA: 17s - loss: 122.7385 - mae: 8.96 - ETA: 14s - loss: 122.7875 - mae: 8.96 - ETA: 11s - loss: 122.5557 - mae: 8.96 - ETA: 8s - loss: 122.2654 - mae: 8.9526 - ETA: 5s - loss: 122.4093 - mae: 8.959 - ETA: 2s - loss: 122.4202 - mae: 8.963 - ETA: 0s - loss: 122.3178 - mae: 8.958 - 462s 4s/step - loss: 122.3178 - mae: 8.9584 - val_loss: 118.3192 - val_mae: 8.7508\n",
      "\n",
      "Epoch 00021: saving model to CP_ResNet50_Sample100_Fine50_2\\cp-0021.ckpt\n",
      "Epoch 22/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - ETA: 5:26 - loss: 108.7779 - mae: 8.430 - ETA: 6:00 - loss: 92.4835 - mae: 7.993 - ETA: 5:44 - loss: 106.8372 - mae: 8.528 - ETA: 5:42 - loss: 105.6877 - mae: 8.460 - ETA: 5:44 - loss: 105.9854 - mae: 8.405 - ETA: 5:47 - loss: 107.0525 - mae: 8.433 - ETA: 5:51 - loss: 103.4909 - mae: 8.287 - ETA: 5:57 - loss: 100.7222 - mae: 8.208 - ETA: 6:04 - loss: 107.3111 - mae: 8.440 - ETA: 6:08 - loss: 109.3871 - mae: 8.591 - ETA: 6:06 - loss: 111.9388 - mae: 8.667 - ETA: 6:02 - loss: 112.3640 - mae: 8.701 - ETA: 5:56 - loss: 110.9057 - mae: 8.629 - ETA: 5:50 - loss: 113.5141 - mae: 8.686 - ETA: 5:43 - loss: 111.3276 - mae: 8.595 - ETA: 5:36 - loss: 113.1798 - mae: 8.628 - ETA: 5:30 - loss: 113.2305 - mae: 8.611 - ETA: 5:23 - loss: 113.2978 - mae: 8.610 - ETA: 5:17 - loss: 113.7964 - mae: 8.615 - ETA: 5:11 - loss: 115.0604 - mae: 8.662 - ETA: 5:06 - loss: 116.4374 - mae: 8.707 - ETA: 5:00 - loss: 116.7925 - mae: 8.701 - ETA: 4:55 - loss: 117.6103 - mae: 8.761 - ETA: 4:50 - loss: 116.2620 - mae: 8.715 - ETA: 4:45 - loss: 115.8134 - mae: 8.682 - ETA: 4:41 - loss: 116.5727 - mae: 8.694 - ETA: 4:36 - loss: 118.9725 - mae: 8.778 - ETA: 4:32 - loss: 119.4634 - mae: 8.818 - ETA: 4:28 - loss: 119.3414 - mae: 8.831 - ETA: 4:24 - loss: 118.6779 - mae: 8.796 - ETA: 4:20 - loss: 117.7258 - mae: 8.738 - ETA: 4:17 - loss: 118.9450 - mae: 8.773 - ETA: 4:13 - loss: 120.0828 - mae: 8.778 - ETA: 4:10 - loss: 119.0383 - mae: 8.735 - ETA: 4:07 - loss: 118.8084 - mae: 8.726 - ETA: 4:04 - loss: 117.4950 - mae: 8.679 - ETA: 4:01 - loss: 118.2298 - mae: 8.719 - ETA: 3:59 - loss: 117.5327 - mae: 8.699 - ETA: 3:56 - loss: 117.3068 - mae: 8.680 - ETA: 3:55 - loss: 117.3148 - mae: 8.695 - ETA: 3:53 - loss: 117.6934 - mae: 8.711 - ETA: 3:52 - loss: 118.8849 - mae: 8.748 - ETA: 3:51 - loss: 119.2466 - mae: 8.765 - ETA: 3:49 - loss: 120.0268 - mae: 8.788 - ETA: 3:47 - loss: 119.5736 - mae: 8.773 - ETA: 3:45 - loss: 118.9368 - mae: 8.754 - ETA: 3:42 - loss: 119.4140 - mae: 8.787 - ETA: 3:39 - loss: 119.5523 - mae: 8.791 - ETA: 3:36 - loss: 119.7227 - mae: 8.798 - ETA: 3:33 - loss: 120.3297 - mae: 8.815 - ETA: 3:29 - loss: 119.8560 - mae: 8.798 - ETA: 3:26 - loss: 119.4727 - mae: 8.794 - ETA: 3:23 - loss: 119.4223 - mae: 8.796 - ETA: 3:19 - loss: 119.3834 - mae: 8.797 - ETA: 3:16 - loss: 119.6070 - mae: 8.810 - ETA: 3:13 - loss: 119.4160 - mae: 8.817 - ETA: 3:10 - loss: 119.2183 - mae: 8.818 - ETA: 3:07 - loss: 119.3210 - mae: 8.830 - ETA: 3:03 - loss: 119.2284 - mae: 8.829 - ETA: 3:00 - loss: 118.6656 - mae: 8.811 - ETA: 2:57 - loss: 118.7431 - mae: 8.798 - ETA: 2:54 - loss: 118.6329 - mae: 8.795 - ETA: 2:51 - loss: 118.1177 - mae: 8.777 - ETA: 2:48 - loss: 118.0007 - mae: 8.775 - ETA: 2:45 - loss: 118.6971 - mae: 8.794 - ETA: 2:42 - loss: 118.6483 - mae: 8.785 - ETA: 2:39 - loss: 119.0694 - mae: 8.797 - ETA: 2:36 - loss: 119.0480 - mae: 8.798 - ETA: 2:34 - loss: 118.2438 - mae: 8.768 - ETA: 2:31 - loss: 118.0982 - mae: 8.763 - ETA: 2:28 - loss: 117.9814 - mae: 8.753 - ETA: 2:26 - loss: 117.8600 - mae: 8.753 - ETA: 2:23 - loss: 117.8192 - mae: 8.755 - ETA: 2:21 - loss: 118.2275 - mae: 8.774 - ETA: 2:19 - loss: 118.5882 - mae: 8.797 - ETA: 2:17 - loss: 118.5154 - mae: 8.797 - ETA: 2:15 - loss: 119.1168 - mae: 8.823 - ETA: 2:12 - loss: 119.2194 - mae: 8.836 - ETA: 2:09 - loss: 119.5117 - mae: 8.842 - ETA: 2:06 - loss: 119.6257 - mae: 8.850 - ETA: 2:04 - loss: 119.3638 - mae: 8.833 - ETA: 2:01 - loss: 119.1022 - mae: 8.822 - ETA: 1:58 - loss: 119.2858 - mae: 8.833 - ETA: 1:55 - loss: 118.8072 - mae: 8.816 - ETA: 1:52 - loss: 118.5899 - mae: 8.799 - ETA: 1:49 - loss: 119.6156 - mae: 8.837 - ETA: 1:46 - loss: 120.0324 - mae: 8.854 - ETA: 1:43 - loss: 120.2248 - mae: 8.861 - ETA: 1:40 - loss: 120.3609 - mae: 8.872 - ETA: 1:37 - loss: 120.6700 - mae: 8.887 - ETA: 1:34 - loss: 120.9634 - mae: 8.898 - ETA: 1:31 - loss: 121.0836 - mae: 8.911 - ETA: 1:28 - loss: 121.2632 - mae: 8.926 - ETA: 1:26 - loss: 121.6929 - mae: 8.939 - ETA: 1:23 - loss: 121.5733 - mae: 8.935 - ETA: 1:20 - loss: 121.8039 - mae: 8.938 - ETA: 1:17 - loss: 121.9790 - mae: 8.950 - ETA: 1:14 - loss: 121.9304 - mae: 8.953 - ETA: 1:11 - loss: 121.8966 - mae: 8.955 - ETA: 1:08 - loss: 121.6264 - mae: 8.948 - ETA: 1:06 - loss: 121.7408 - mae: 8.956 - ETA: 1:03 - loss: 121.3751 - mae: 8.944 - ETA: 1:00 - loss: 121.1023 - mae: 8.933 - ETA: 57s - loss: 121.1991 - mae: 8.947 - ETA: 55s - loss: 121.4353 - mae: 8.95 - ETA: 52s - loss: 121.3127 - mae: 8.94 - ETA: 49s - loss: 121.4380 - mae: 8.94 - ETA: 47s - loss: 121.7932 - mae: 8.95 - ETA: 44s - loss: 121.7351 - mae: 8.95 - ETA: 41s - loss: 121.7814 - mae: 8.96 - ETA: 39s - loss: 122.0765 - mae: 8.97 - ETA: 36s - loss: 121.7618 - mae: 8.96 - ETA: 33s - loss: 121.8095 - mae: 8.96 - ETA: 30s - loss: 121.9909 - mae: 8.96 - ETA: 27s - loss: 121.7985 - mae: 8.96 - ETA: 25s - loss: 121.7876 - mae: 8.95 - ETA: 22s - loss: 121.5347 - mae: 8.95 - ETA: 19s - loss: 121.5418 - mae: 8.95 - ETA: 16s - loss: 121.5291 - mae: 8.95 - ETA: 13s - loss: 121.5928 - mae: 8.95 - ETA: 11s - loss: 121.5932 - mae: 8.95 - ETA: 8s - loss: 121.6342 - mae: 8.9571 - ETA: 5s - loss: 121.4425 - mae: 8.953 - ETA: 2s - loss: 121.2829 - mae: 8.949 - ETA: 0s - loss: 121.2316 - mae: 8.949 - 432s 3s/step - loss: 121.2316 - mae: 8.9499 - val_loss: 118.2112 - val_mae: 8.7519\n",
      "\n",
      "Epoch 00022: saving model to CP_ResNet50_Sample100_Fine50_2\\cp-0022.ckpt\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - ETA: 5:08 - loss: 118.5492 - mae: 8.850 - ETA: 5:09 - loss: 123.1972 - mae: 8.932 - ETA: 5:06 - loss: 113.6511 - mae: 8.647 - ETA: 5:15 - loss: 132.9468 - mae: 9.114 - ETA: 5:16 - loss: 136.6913 - mae: 9.314 - ETA: 5:13 - loss: 134.4103 - mae: 9.228 - ETA: 5:10 - loss: 129.4034 - mae: 9.009 - ETA: 5:11 - loss: 123.1847 - mae: 8.804 - ETA: 5:14 - loss: 124.0169 - mae: 8.924 - ETA: 5:18 - loss: 120.5827 - mae: 8.823 - ETA: 5:19 - loss: 122.0724 - mae: 8.894 - ETA: 5:19 - loss: 122.1787 - mae: 8.941 - ETA: 5:20 - loss: 124.5982 - mae: 9.078 - ETA: 5:24 - loss: 127.2079 - mae: 9.163 - ETA: 5:31 - loss: 125.1348 - mae: 9.081 - ETA: 5:40 - loss: 124.3940 - mae: 9.032 - ETA: 5:49 - loss: 124.4270 - mae: 8.975 - ETA: 5:55 - loss: 121.8636 - mae: 8.872 - ETA: 5:54 - loss: 122.4377 - mae: 8.916 - ETA: 5:52 - loss: 122.9448 - mae: 8.961 - ETA: 5:48 - loss: 125.3782 - mae: 9.046 - ETA: 5:44 - loss: 124.7922 - mae: 9.009 - ETA: 5:42 - loss: 123.0939 - mae: 8.956 - ETA: 5:39 - loss: 122.1132 - mae: 8.933 - ETA: 5:35 - loss: 123.1947 - mae: 8.980 - ETA: 5:29 - loss: 121.2588 - mae: 8.898 - ETA: 5:24 - loss: 121.7712 - mae: 8.950 - ETA: 5:18 - loss: 121.4081 - mae: 8.920 - ETA: 5:11 - loss: 123.3859 - mae: 8.953 - ETA: 5:06 - loss: 124.2434 - mae: 8.995 - ETA: 5:00 - loss: 123.4012 - mae: 8.974 - ETA: 4:55 - loss: 123.5229 - mae: 8.972 - ETA: 4:49 - loss: 122.8494 - mae: 8.960 - ETA: 4:44 - loss: 122.0535 - mae: 8.914 - ETA: 4:39 - loss: 123.9025 - mae: 8.989 - ETA: 4:35 - loss: 122.7688 - mae: 8.926 - ETA: 4:30 - loss: 123.2174 - mae: 8.936 - ETA: 4:25 - loss: 123.8029 - mae: 8.967 - ETA: 4:21 - loss: 123.6705 - mae: 8.984 - ETA: 4:17 - loss: 123.2872 - mae: 8.978 - ETA: 4:13 - loss: 122.0846 - mae: 8.927 - ETA: 4:09 - loss: 121.4227 - mae: 8.908 - ETA: 4:05 - loss: 121.6827 - mae: 8.916 - ETA: 4:01 - loss: 121.5127 - mae: 8.922 - ETA: 3:58 - loss: 120.9680 - mae: 8.904 - ETA: 3:54 - loss: 119.9093 - mae: 8.867 - ETA: 3:51 - loss: 119.4768 - mae: 8.849 - ETA: 3:48 - loss: 119.9886 - mae: 8.872 - ETA: 3:46 - loss: 121.0565 - mae: 8.899 - ETA: 3:43 - loss: 120.5989 - mae: 8.881 - ETA: 3:41 - loss: 119.6582 - mae: 8.844 - ETA: 3:39 - loss: 119.3521 - mae: 8.836 - ETA: 3:37 - loss: 118.6386 - mae: 8.816 - ETA: 3:34 - loss: 119.2695 - mae: 8.844 - ETA: 3:31 - loss: 118.9756 - mae: 8.838 - ETA: 3:28 - loss: 118.7180 - mae: 8.821 - ETA: 3:25 - loss: 117.9799 - mae: 8.793 - ETA: 3:22 - loss: 118.5297 - mae: 8.807 - ETA: 3:18 - loss: 118.3240 - mae: 8.807 - ETA: 3:15 - loss: 118.4819 - mae: 8.818 - ETA: 3:11 - loss: 118.1071 - mae: 8.805 - ETA: 3:08 - loss: 118.3828 - mae: 8.833 - ETA: 3:04 - loss: 118.6755 - mae: 8.845 - ETA: 3:01 - loss: 119.9675 - mae: 8.879 - ETA: 2:57 - loss: 120.0646 - mae: 8.884 - ETA: 2:54 - loss: 119.6638 - mae: 8.859 - ETA: 2:50 - loss: 120.4029 - mae: 8.883 - ETA: 2:47 - loss: 120.7372 - mae: 8.887 - ETA: 2:44 - loss: 120.8755 - mae: 8.891 - ETA: 2:41 - loss: 120.7380 - mae: 8.891 - ETA: 2:37 - loss: 120.6075 - mae: 8.885 - ETA: 2:34 - loss: 120.7323 - mae: 8.882 - ETA: 2:31 - loss: 121.0595 - mae: 8.896 - ETA: 2:28 - loss: 120.6527 - mae: 8.874 - ETA: 2:25 - loss: 120.7020 - mae: 8.873 - ETA: 2:22 - loss: 121.0954 - mae: 8.892 - ETA: 2:18 - loss: 120.8218 - mae: 8.886 - ETA: 2:15 - loss: 120.5047 - mae: 8.871 - ETA: 2:13 - loss: 120.2783 - mae: 8.858 - ETA: 2:10 - loss: 119.8985 - mae: 8.853 - ETA: 2:07 - loss: 119.5296 - mae: 8.839 - ETA: 2:04 - loss: 119.8199 - mae: 8.857 - ETA: 2:02 - loss: 119.5317 - mae: 8.851 - ETA: 1:59 - loss: 119.7346 - mae: 8.856 - ETA: 1:57 - loss: 119.5480 - mae: 8.855 - ETA: 1:54 - loss: 119.8976 - mae: 8.866 - ETA: 1:51 - loss: 120.1370 - mae: 8.871 - ETA: 1:49 - loss: 119.8253 - mae: 8.859 - ETA: 1:46 - loss: 120.5065 - mae: 8.893 - ETA: 1:43 - loss: 120.8701 - mae: 8.911 - ETA: 1:40 - loss: 120.9163 - mae: 8.914 - ETA: 1:36 - loss: 121.2189 - mae: 8.933 - ETA: 1:33 - loss: 121.3769 - mae: 8.943 - ETA: 1:30 - loss: 121.5945 - mae: 8.952 - ETA: 1:27 - loss: 121.8014 - mae: 8.953 - ETA: 1:24 - loss: 121.3362 - mae: 8.934 - ETA: 1:21 - loss: 121.1804 - mae: 8.934 - ETA: 1:18 - loss: 121.2315 - mae: 8.935 - ETA: 1:15 - loss: 121.3585 - mae: 8.946 - ETA: 1:12 - loss: 121.5892 - mae: 8.955 - ETA: 1:09 - loss: 121.9381 - mae: 8.964 - ETA: 1:06 - loss: 122.0191 - mae: 8.970 - ETA: 1:03 - loss: 122.2450 - mae: 8.980 - ETA: 1:00 - loss: 122.1092 - mae: 8.971 - ETA: 57s - loss: 121.9137 - mae: 8.971 - ETA: 54s - loss: 121.5182 - mae: 8.95 - ETA: 51s - loss: 121.8819 - mae: 8.97 - ETA: 48s - loss: 121.9239 - mae: 8.98 - ETA: 45s - loss: 121.8644 - mae: 8.97 - ETA: 42s - loss: 121.8703 - mae: 8.98 - ETA: 40s - loss: 121.9806 - mae: 8.98 - ETA: 37s - loss: 121.6030 - mae: 8.96 - ETA: 34s - loss: 121.5636 - mae: 8.96 - ETA: 31s - loss: 121.2094 - mae: 8.95 - ETA: 28s - loss: 121.4516 - mae: 8.95 - ETA: 25s - loss: 121.5895 - mae: 8.96 - ETA: 22s - loss: 121.5411 - mae: 8.96 - ETA: 20s - loss: 121.6388 - mae: 8.96 - ETA: 17s - loss: 121.5518 - mae: 8.96 - ETA: 14s - loss: 121.3694 - mae: 8.96 - ETA: 11s - loss: 121.2588 - mae: 8.96 - ETA: 8s - loss: 121.6381 - mae: 8.9748 - ETA: 5s - loss: 121.7168 - mae: 8.978 - ETA: 2s - loss: 121.5052 - mae: 8.968 - ETA: 0s - loss: 121.4474 - mae: 8.968 - 449s 4s/step - loss: 121.4474 - mae: 8.9687 - val_loss: 118.2745 - val_mae: 8.7466\n",
      "\n",
      "Epoch 00023: saving model to CP_ResNet50_Sample100_Fine50_2\\cp-0023.ckpt\n",
      "Epoch 24/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - ETA: 5:21 - loss: 102.1916 - mae: 8.388 - ETA: 5:10 - loss: 110.2392 - mae: 8.558 - ETA: 5:05 - loss: 101.4293 - mae: 8.135 - ETA: 5:02 - loss: 103.2302 - mae: 8.251 - ETA: 5:01 - loss: 109.2137 - mae: 8.535 - ETA: 4:58 - loss: 114.1777 - mae: 8.645 - ETA: 4:54 - loss: 121.9228 - mae: 9.004 - ETA: 4:51 - loss: 123.7063 - mae: 9.041 - ETA: 4:48 - loss: 120.7665 - mae: 8.900 - ETA: 4:45 - loss: 118.8436 - mae: 8.834 - ETA: 4:43 - loss: 113.9743 - mae: 8.625 - ETA: 4:41 - loss: 110.5251 - mae: 8.508 - ETA: 4:39 - loss: 113.3338 - mae: 8.558 - ETA: 4:37 - loss: 113.3949 - mae: 8.571 - ETA: 4:36 - loss: 116.1833 - mae: 8.684 - ETA: 4:36 - loss: 115.6153 - mae: 8.685 - ETA: 4:35 - loss: 114.0151 - mae: 8.598 - ETA: 4:35 - loss: 117.0132 - mae: 8.716 - ETA: 4:37 - loss: 119.7916 - mae: 8.807 - ETA: 4:39 - loss: 121.0102 - mae: 8.812 - ETA: 4:41 - loss: 118.7303 - mae: 8.732 - ETA: 4:44 - loss: 118.5077 - mae: 8.727 - ETA: 4:44 - loss: 118.2887 - mae: 8.743 - ETA: 4:44 - loss: 117.5812 - mae: 8.707 - ETA: 4:42 - loss: 117.0766 - mae: 8.677 - ETA: 4:40 - loss: 118.6409 - mae: 8.739 - ETA: 4:37 - loss: 119.2888 - mae: 8.753 - ETA: 4:33 - loss: 119.1083 - mae: 8.746 - ETA: 4:30 - loss: 119.1016 - mae: 8.755 - ETA: 4:26 - loss: 120.1869 - mae: 8.815 - ETA: 4:23 - loss: 120.9013 - mae: 8.852 - ETA: 4:19 - loss: 122.5535 - mae: 8.913 - ETA: 4:15 - loss: 123.3330 - mae: 8.933 - ETA: 4:12 - loss: 123.6641 - mae: 8.971 - ETA: 4:08 - loss: 123.7128 - mae: 8.991 - ETA: 4:04 - loss: 124.4604 - mae: 9.002 - ETA: 4:01 - loss: 122.7901 - mae: 8.925 - ETA: 3:57 - loss: 122.3442 - mae: 8.905 - ETA: 3:54 - loss: 122.2051 - mae: 8.906 - ETA: 3:51 - loss: 121.6791 - mae: 8.882 - ETA: 3:47 - loss: 121.9381 - mae: 8.890 - ETA: 3:44 - loss: 121.9595 - mae: 8.894 - ETA: 3:41 - loss: 121.7033 - mae: 8.883 - ETA: 3:38 - loss: 122.8834 - mae: 8.932 - ETA: 3:35 - loss: 122.2435 - mae: 8.918 - ETA: 3:32 - loss: 121.9632 - mae: 8.897 - ETA: 3:29 - loss: 121.2449 - mae: 8.874 - ETA: 3:26 - loss: 120.2817 - mae: 8.830 - ETA: 3:24 - loss: 119.6050 - mae: 8.799 - ETA: 3:21 - loss: 119.6927 - mae: 8.799 - ETA: 3:19 - loss: 119.6368 - mae: 8.802 - ETA: 3:17 - loss: 120.4735 - mae: 8.850 - ETA: 3:15 - loss: 119.6680 - mae: 8.821 - ETA: 3:13 - loss: 119.2295 - mae: 8.804 - ETA: 3:12 - loss: 119.2863 - mae: 8.812 - ETA: 3:10 - loss: 119.5842 - mae: 8.823 - ETA: 3:09 - loss: 120.2601 - mae: 8.857 - ETA: 3:07 - loss: 121.0667 - mae: 8.878 - ETA: 3:04 - loss: 121.2107 - mae: 8.886 - ETA: 3:02 - loss: 120.6817 - mae: 8.874 - ETA: 2:59 - loss: 120.8124 - mae: 8.878 - ETA: 2:56 - loss: 120.7112 - mae: 8.879 - ETA: 2:53 - loss: 120.5216 - mae: 8.859 - ETA: 2:50 - loss: 120.0322 - mae: 8.845 - ETA: 2:47 - loss: 120.2207 - mae: 8.841 - ETA: 2:44 - loss: 120.4728 - mae: 8.856 - ETA: 2:41 - loss: 119.7142 - mae: 8.824 - ETA: 2:38 - loss: 119.5890 - mae: 8.818 - ETA: 2:35 - loss: 119.9435 - mae: 8.834 - ETA: 2:32 - loss: 119.8130 - mae: 8.834 - ETA: 2:29 - loss: 120.0703 - mae: 8.836 - ETA: 2:26 - loss: 119.6952 - mae: 8.814 - ETA: 2:23 - loss: 119.8343 - mae: 8.829 - ETA: 2:20 - loss: 120.5754 - mae: 8.866 - ETA: 2:17 - loss: 120.4049 - mae: 8.854 - ETA: 2:14 - loss: 120.3884 - mae: 8.852 - ETA: 2:11 - loss: 120.3568 - mae: 8.851 - ETA: 2:08 - loss: 120.6565 - mae: 8.869 - ETA: 2:05 - loss: 120.6387 - mae: 8.864 - ETA: 2:02 - loss: 121.1788 - mae: 8.890 - ETA: 2:00 - loss: 121.1630 - mae: 8.888 - ETA: 1:57 - loss: 121.2838 - mae: 8.892 - ETA: 1:54 - loss: 121.6120 - mae: 8.902 - ETA: 1:52 - loss: 121.5095 - mae: 8.898 - ETA: 1:49 - loss: 121.3355 - mae: 8.898 - ETA: 1:47 - loss: 121.8255 - mae: 8.911 - ETA: 1:44 - loss: 121.7603 - mae: 8.910 - ETA: 1:42 - loss: 122.3767 - mae: 8.930 - ETA: 1:39 - loss: 122.1154 - mae: 8.927 - ETA: 1:37 - loss: 122.3154 - mae: 8.942 - ETA: 1:35 - loss: 122.3563 - mae: 8.947 - ETA: 1:32 - loss: 122.4594 - mae: 8.954 - ETA: 1:30 - loss: 122.2067 - mae: 8.940 - ETA: 1:27 - loss: 122.1256 - mae: 8.938 - ETA: 1:24 - loss: 122.4070 - mae: 8.944 - ETA: 1:22 - loss: 122.3148 - mae: 8.946 - ETA: 1:19 - loss: 121.9921 - mae: 8.934 - ETA: 1:16 - loss: 121.8717 - mae: 8.927 - ETA: 1:13 - loss: 121.7349 - mae: 8.926 - ETA: 1:10 - loss: 121.7274 - mae: 8.924 - ETA: 1:07 - loss: 121.3433 - mae: 8.908 - ETA: 1:04 - loss: 121.3258 - mae: 8.910 - ETA: 1:01 - loss: 121.9833 - mae: 8.941 - ETA: 58s - loss: 121.3757 - mae: 8.915 - ETA: 56s - loss: 121.3269 - mae: 8.91 - ETA: 53s - loss: 121.1928 - mae: 8.91 - ETA: 50s - loss: 121.4888 - mae: 8.92 - ETA: 47s - loss: 121.3431 - mae: 8.91 - ETA: 44s - loss: 121.5939 - mae: 8.92 - ETA: 41s - loss: 121.4045 - mae: 8.91 - ETA: 38s - loss: 121.3655 - mae: 8.91 - ETA: 36s - loss: 121.1107 - mae: 8.90 - ETA: 33s - loss: 120.9503 - mae: 8.89 - ETA: 30s - loss: 120.9142 - mae: 8.89 - ETA: 27s - loss: 120.7451 - mae: 8.88 - ETA: 24s - loss: 121.0228 - mae: 8.89 - ETA: 22s - loss: 120.8779 - mae: 8.88 - ETA: 19s - loss: 120.7687 - mae: 8.88 - ETA: 16s - loss: 120.7639 - mae: 8.88 - ETA: 13s - loss: 120.2963 - mae: 8.87 - ETA: 11s - loss: 120.3411 - mae: 8.87 - ETA: 8s - loss: 120.0747 - mae: 8.8676 - ETA: 5s - loss: 120.3715 - mae: 8.884 - ETA: 2s - loss: 120.5976 - mae: 8.891 - ETA: 0s - loss: 120.7749 - mae: 8.900 - 435s 3s/step - loss: 120.7749 - mae: 8.9007 - val_loss: 117.6873 - val_mae: 8.7228\n",
      "\n",
      "Epoch 00024: saving model to CP_ResNet50_Sample100_Fine50_2\\cp-0024.ckpt\n",
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - ETA: 6:54 - loss: 133.2489 - mae: 9.339 - ETA: 7:45 - loss: 129.6759 - mae: 9.336 - ETA: 7:13 - loss: 127.5350 - mae: 9.251 - ETA: 6:45 - loss: 119.0185 - mae: 8.774 - ETA: 6:27 - loss: 118.7562 - mae: 8.784 - ETA: 6:11 - loss: 112.6578 - mae: 8.510 - ETA: 5:59 - loss: 114.7770 - mae: 8.584 - ETA: 5:49 - loss: 110.1782 - mae: 8.405 - ETA: 5:39 - loss: 110.8788 - mae: 8.450 - ETA: 5:31 - loss: 111.1580 - mae: 8.412 - ETA: 5:24 - loss: 112.0934 - mae: 8.434 - ETA: 5:17 - loss: 112.8187 - mae: 8.457 - ETA: 5:12 - loss: 110.8079 - mae: 8.437 - ETA: 5:07 - loss: 110.6478 - mae: 8.455 - ETA: 5:02 - loss: 113.1385 - mae: 8.550 - ETA: 4:57 - loss: 116.6411 - mae: 8.710 - ETA: 4:52 - loss: 115.6206 - mae: 8.692 - ETA: 4:48 - loss: 116.9868 - mae: 8.703 - ETA: 4:44 - loss: 117.2040 - mae: 8.689 - ETA: 4:40 - loss: 114.9576 - mae: 8.582 - ETA: 4:36 - loss: 115.7350 - mae: 8.628 - ETA: 4:33 - loss: 116.3752 - mae: 8.652 - ETA: 4:29 - loss: 118.7548 - mae: 8.744 - ETA: 4:26 - loss: 117.7588 - mae: 8.720 - ETA: 4:23 - loss: 116.2991 - mae: 8.664 - ETA: 4:20 - loss: 117.9275 - mae: 8.742 - ETA: 4:18 - loss: 117.1976 - mae: 8.723 - ETA: 4:15 - loss: 116.5705 - mae: 8.690 - ETA: 4:13 - loss: 116.2232 - mae: 8.667 - ETA: 4:12 - loss: 114.1944 - mae: 8.569 - ETA: 4:10 - loss: 114.2315 - mae: 8.578 - ETA: 4:10 - loss: 115.1555 - mae: 8.616 - ETA: 4:09 - loss: 114.3346 - mae: 8.590 - ETA: 4:10 - loss: 113.4874 - mae: 8.545 - ETA: 4:10 - loss: 114.5347 - mae: 8.598 - ETA: 4:09 - loss: 116.2752 - mae: 8.671 - ETA: 4:07 - loss: 116.7526 - mae: 8.702 - ETA: 4:04 - loss: 117.5994 - mae: 8.748 - ETA: 4:02 - loss: 117.6334 - mae: 8.746 - ETA: 3:58 - loss: 118.6779 - mae: 8.793 - ETA: 3:55 - loss: 120.7368 - mae: 8.871 - ETA: 3:52 - loss: 120.8925 - mae: 8.891 - ETA: 3:49 - loss: 121.0328 - mae: 8.895 - ETA: 3:46 - loss: 120.6674 - mae: 8.898 - ETA: 3:42 - loss: 120.6134 - mae: 8.905 - ETA: 3:39 - loss: 119.7050 - mae: 8.879 - ETA: 3:36 - loss: 120.2636 - mae: 8.888 - ETA: 3:32 - loss: 119.5752 - mae: 8.863 - ETA: 3:29 - loss: 119.0040 - mae: 8.840 - ETA: 3:26 - loss: 119.5551 - mae: 8.855 - ETA: 3:23 - loss: 119.2767 - mae: 8.837 - ETA: 3:19 - loss: 119.2598 - mae: 8.851 - ETA: 3:16 - loss: 119.2744 - mae: 8.859 - ETA: 3:13 - loss: 120.3316 - mae: 8.910 - ETA: 3:10 - loss: 120.1561 - mae: 8.912 - ETA: 3:07 - loss: 119.2680 - mae: 8.875 - ETA: 3:04 - loss: 118.6509 - mae: 8.854 - ETA: 3:01 - loss: 118.6029 - mae: 8.860 - ETA: 2:58 - loss: 118.2820 - mae: 8.846 - ETA: 2:56 - loss: 118.2454 - mae: 8.859 - ETA: 2:53 - loss: 118.0942 - mae: 8.856 - ETA: 2:50 - loss: 117.6956 - mae: 8.839 - ETA: 2:48 - loss: 117.3903 - mae: 8.823 - ETA: 2:45 - loss: 118.4379 - mae: 8.848 - ETA: 2:43 - loss: 118.5362 - mae: 8.857 - ETA: 2:41 - loss: 119.4363 - mae: 8.898 - ETA: 2:39 - loss: 119.8401 - mae: 8.909 - ETA: 2:37 - loss: 119.6442 - mae: 8.909 - ETA: 2:35 - loss: 119.7314 - mae: 8.908 - ETA: 2:32 - loss: 119.1635 - mae: 8.884 - ETA: 2:30 - loss: 119.6640 - mae: 8.905 - ETA: 2:27 - loss: 119.8169 - mae: 8.903 - ETA: 2:24 - loss: 120.4775 - mae: 8.930 - ETA: 2:22 - loss: 119.9615 - mae: 8.904 - ETA: 2:19 - loss: 119.8448 - mae: 8.906 - ETA: 2:16 - loss: 119.6428 - mae: 8.901 - ETA: 2:13 - loss: 119.2835 - mae: 8.888 - ETA: 2:10 - loss: 118.8110 - mae: 8.867 - ETA: 2:07 - loss: 118.9669 - mae: 8.870 - ETA: 2:04 - loss: 119.3827 - mae: 8.884 - ETA: 2:01 - loss: 119.7202 - mae: 8.906 - ETA: 1:58 - loss: 119.9973 - mae: 8.915 - ETA: 1:55 - loss: 120.5274 - mae: 8.929 - ETA: 1:53 - loss: 120.7838 - mae: 8.934 - ETA: 1:50 - loss: 120.5473 - mae: 8.924 - ETA: 1:47 - loss: 120.6408 - mae: 8.941 - ETA: 1:44 - loss: 120.3127 - mae: 8.934 - ETA: 1:41 - loss: 120.7172 - mae: 8.944 - ETA: 1:38 - loss: 120.2159 - mae: 8.925 - ETA: 1:35 - loss: 120.0044 - mae: 8.922 - ETA: 1:33 - loss: 120.0353 - mae: 8.927 - ETA: 1:30 - loss: 120.4994 - mae: 8.938 - ETA: 1:27 - loss: 120.6659 - mae: 8.954 - ETA: 1:24 - loss: 120.5972 - mae: 8.951 - ETA: 1:22 - loss: 120.4155 - mae: 8.933 - ETA: 1:19 - loss: 120.4276 - mae: 8.941 - ETA: 1:16 - loss: 120.1203 - mae: 8.927 - ETA: 1:14 - loss: 120.4396 - mae: 8.942 - ETA: 1:11 - loss: 120.9129 - mae: 8.955 - ETA: 1:09 - loss: 121.3561 - mae: 8.967 - ETA: 1:06 - loss: 121.3560 - mae: 8.967 - ETA: 1:03 - loss: 121.3767 - mae: 8.967 - ETA: 1:00 - loss: 121.5612 - mae: 8.974 - ETA: 58s - loss: 121.3677 - mae: 8.967 - ETA: 55s - loss: 121.1438 - mae: 8.95 - ETA: 52s - loss: 120.9866 - mae: 8.95 - ETA: 49s - loss: 120.7065 - mae: 8.94 - ETA: 46s - loss: 120.4115 - mae: 8.93 - ETA: 44s - loss: 120.6951 - mae: 8.93 - ETA: 41s - loss: 120.3524 - mae: 8.92 - ETA: 38s - loss: 120.5605 - mae: 8.93 - ETA: 35s - loss: 120.3016 - mae: 8.92 - ETA: 32s - loss: 120.0347 - mae: 8.91 - ETA: 30s - loss: 120.1472 - mae: 8.91 - ETA: 27s - loss: 120.0278 - mae: 8.91 - ETA: 24s - loss: 120.0939 - mae: 8.91 - ETA: 21s - loss: 120.3412 - mae: 8.92 - ETA: 19s - loss: 120.7123 - mae: 8.94 - ETA: 16s - loss: 120.5426 - mae: 8.94 - ETA: 13s - loss: 120.3255 - mae: 8.93 - ETA: 10s - loss: 120.2684 - mae: 8.93 - ETA: 8s - loss: 120.2041 - mae: 8.9317 - ETA: 5s - loss: 120.5221 - mae: 8.948 - ETA: 2s - loss: 120.6480 - mae: 8.952 - ETA: 0s - loss: 120.6966 - mae: 8.955 - 428s 3s/step - loss: 120.6966 - mae: 8.9554 - val_loss: 118.2483 - val_mae: 8.7400\n",
      "\n",
      "Epoch 00025: saving model to CP_ResNet50_Sample100_Fine50_2\\cp-0025.ckpt\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - ETA: 6:42 - loss: 125.6219 - mae: 9.548 - ETA: 6:46 - loss: 129.5100 - mae: 9.473 - ETA: 6:49 - loss: 116.3618 - mae: 8.852 - ETA: 6:57 - loss: 121.4792 - mae: 9.005 - ETA: 7:05 - loss: 124.6253 - mae: 9.106 - ETA: 6:59 - loss: 133.9745 - mae: 9.442 - ETA: 6:51 - loss: 129.2372 - mae: 9.335 - ETA: 6:40 - loss: 121.3861 - mae: 9.007 - ETA: 6:29 - loss: 122.1065 - mae: 8.971 - ETA: 6:19 - loss: 122.0397 - mae: 8.990 - ETA: 6:09 - loss: 122.0160 - mae: 8.983 - ETA: 6:00 - loss: 120.2177 - mae: 8.925 - ETA: 5:51 - loss: 118.9354 - mae: 8.914 - ETA: 5:43 - loss: 116.6284 - mae: 8.770 - ETA: 5:35 - loss: 117.4538 - mae: 8.814 - ETA: 5:28 - loss: 116.3138 - mae: 8.798 - ETA: 5:22 - loss: 115.3339 - mae: 8.739 - ETA: 5:15 - loss: 114.3632 - mae: 8.678 - ETA: 5:09 - loss: 115.1579 - mae: 8.700 - ETA: 5:04 - loss: 114.8809 - mae: 8.666 - ETA: 4:59 - loss: 115.1672 - mae: 8.675 - ETA: 4:54 - loss: 114.5720 - mae: 8.656 - ETA: 4:49 - loss: 113.2026 - mae: 8.600 - ETA: 4:44 - loss: 113.6228 - mae: 8.599 - ETA: 4:40 - loss: 116.2723 - mae: 8.700 - ETA: 4:36 - loss: 115.0054 - mae: 8.656 - ETA: 4:32 - loss: 115.0419 - mae: 8.650 - ETA: 4:28 - loss: 116.0062 - mae: 8.663 - ETA: 4:24 - loss: 116.7068 - mae: 8.678 - ETA: 4:21 - loss: 117.6527 - mae: 8.724 - ETA: 4:18 - loss: 117.5632 - mae: 8.709 - ETA: 4:15 - loss: 116.3681 - mae: 8.671 - ETA: 4:12 - loss: 117.3195 - mae: 8.714 - ETA: 4:10 - loss: 116.3550 - mae: 8.675 - ETA: 4:07 - loss: 116.0949 - mae: 8.669 - ETA: 4:05 - loss: 115.6029 - mae: 8.644 - ETA: 4:04 - loss: 115.6183 - mae: 8.631 - ETA: 4:02 - loss: 118.0482 - mae: 8.706 - ETA: 4:02 - loss: 117.6910 - mae: 8.707 - ETA: 4:04 - loss: 118.9274 - mae: 8.759 - ETA: 4:04 - loss: 118.1774 - mae: 8.731 - ETA: 4:02 - loss: 117.7527 - mae: 8.719 - ETA: 4:00 - loss: 117.7756 - mae: 8.729 - ETA: 3:58 - loss: 117.7630 - mae: 8.738 - ETA: 3:55 - loss: 117.9153 - mae: 8.744 - ETA: 3:52 - loss: 117.2742 - mae: 8.731 - ETA: 3:48 - loss: 116.7652 - mae: 8.723 - ETA: 3:45 - loss: 116.0796 - mae: 8.688 - ETA: 3:42 - loss: 115.3564 - mae: 8.654 - ETA: 3:38 - loss: 116.6787 - mae: 8.686 - ETA: 3:35 - loss: 116.7512 - mae: 8.688 - ETA: 3:31 - loss: 116.9344 - mae: 8.704 - ETA: 3:28 - loss: 117.3173 - mae: 8.728 - ETA: 3:24 - loss: 117.4267 - mae: 8.741 - ETA: 3:21 - loss: 116.8942 - mae: 8.726 - ETA: 3:17 - loss: 116.6291 - mae: 8.722 - ETA: 3:14 - loss: 116.3652 - mae: 8.716 - ETA: 3:11 - loss: 116.4529 - mae: 8.709 - ETA: 3:07 - loss: 117.5625 - mae: 8.748 - ETA: 3:04 - loss: 117.4506 - mae: 8.731 - ETA: 3:01 - loss: 117.3859 - mae: 8.726 - ETA: 2:58 - loss: 117.0775 - mae: 8.718 - ETA: 2:55 - loss: 116.9502 - mae: 8.714 - ETA: 2:51 - loss: 117.4704 - mae: 8.737 - ETA: 2:48 - loss: 117.6456 - mae: 8.754 - ETA: 2:45 - loss: 117.5167 - mae: 8.752 - ETA: 2:42 - loss: 116.9446 - mae: 8.723 - ETA: 2:39 - loss: 117.1338 - mae: 8.722 - ETA: 2:36 - loss: 117.2632 - mae: 8.727 - ETA: 2:33 - loss: 116.8003 - mae: 8.702 - ETA: 2:30 - loss: 116.5448 - mae: 8.701 - ETA: 2:28 - loss: 116.6832 - mae: 8.710 - ETA: 2:25 - loss: 116.6795 - mae: 8.714 - ETA: 2:22 - loss: 117.1316 - mae: 8.742 - ETA: 2:20 - loss: 116.8097 - mae: 8.728 - ETA: 2:18 - loss: 116.1977 - mae: 8.707 - ETA: 2:16 - loss: 116.9393 - mae: 8.738 - ETA: 2:13 - loss: 117.2361 - mae: 8.746 - ETA: 2:11 - loss: 117.4820 - mae: 8.750 - ETA: 2:08 - loss: 117.4929 - mae: 8.755 - ETA: 2:05 - loss: 117.1133 - mae: 8.738 - ETA: 2:02 - loss: 117.2990 - mae: 8.737 - ETA: 1:59 - loss: 117.8683 - mae: 8.759 - ETA: 1:57 - loss: 118.1608 - mae: 8.768 - ETA: 1:54 - loss: 118.3142 - mae: 8.781 - ETA: 1:51 - loss: 118.2248 - mae: 8.773 - ETA: 1:48 - loss: 118.8233 - mae: 8.798 - ETA: 1:45 - loss: 119.5827 - mae: 8.828 - ETA: 1:42 - loss: 119.4396 - mae: 8.827 - ETA: 1:39 - loss: 119.0195 - mae: 8.809 - ETA: 1:36 - loss: 118.9133 - mae: 8.807 - ETA: 1:33 - loss: 118.6610 - mae: 8.792 - ETA: 1:30 - loss: 119.1563 - mae: 8.811 - ETA: 1:27 - loss: 119.1428 - mae: 8.805 - ETA: 1:24 - loss: 118.7483 - mae: 8.794 - ETA: 1:21 - loss: 118.8955 - mae: 8.797 - ETA: 1:18 - loss: 118.8482 - mae: 8.800 - ETA: 1:15 - loss: 118.9562 - mae: 8.803 - ETA: 1:12 - loss: 118.7397 - mae: 8.801 - ETA: 1:10 - loss: 119.0835 - mae: 8.823 - ETA: 1:07 - loss: 119.1890 - mae: 8.824 - ETA: 1:04 - loss: 119.1959 - mae: 8.827 - ETA: 1:01 - loss: 119.2234 - mae: 8.828 - ETA: 58s - loss: 119.1490 - mae: 8.821 - ETA: 55s - loss: 119.1367 - mae: 8.82 - ETA: 53s - loss: 118.9824 - mae: 8.81 - ETA: 50s - loss: 118.8935 - mae: 8.80 - ETA: 47s - loss: 119.0929 - mae: 8.81 - ETA: 44s - loss: 119.0710 - mae: 8.82 - ETA: 42s - loss: 119.3784 - mae: 8.83 - ETA: 39s - loss: 119.2460 - mae: 8.82 - ETA: 36s - loss: 119.5874 - mae: 8.84 - ETA: 34s - loss: 119.2736 - mae: 8.83 - ETA: 31s - loss: 119.4901 - mae: 8.84 - ETA: 28s - loss: 119.3511 - mae: 8.83 - ETA: 25s - loss: 119.5633 - mae: 8.84 - ETA: 22s - loss: 119.3310 - mae: 8.84 - ETA: 19s - loss: 119.5874 - mae: 8.85 - ETA: 16s - loss: 119.6837 - mae: 8.86 - ETA: 14s - loss: 119.6422 - mae: 8.86 - ETA: 11s - loss: 119.4055 - mae: 8.85 - ETA: 8s - loss: 119.6716 - mae: 8.8649 - ETA: 5s - loss: 119.5307 - mae: 8.860 - ETA: 2s - loss: 119.5339 - mae: 8.853 - ETA: 0s - loss: 119.4046 - mae: 8.848 - 437s 4s/step - loss: 119.4046 - mae: 8.8480 - val_loss: 117.5777 - val_mae: 8.7115\n",
      "\n",
      "Epoch 00026: saving model to CP_ResNet50_Sample100_Fine50_2\\cp-0026.ckpt\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - ETA: 5:18 - loss: 132.6332 - mae: 9.013 - ETA: 5:18 - loss: 104.8849 - mae: 8.072 - ETA: 5:11 - loss: 111.6816 - mae: 8.565 - ETA: 5:06 - loss: 106.9242 - mae: 8.477 - ETA: 5:01 - loss: 117.5543 - mae: 8.962 - ETA: 4:58 - loss: 118.1084 - mae: 8.855 - ETA: 4:55 - loss: 113.6412 - mae: 8.684 - ETA: 4:51 - loss: 116.2451 - mae: 8.838 - ETA: 4:48 - loss: 115.1023 - mae: 8.732 - ETA: 4:45 - loss: 114.0088 - mae: 8.680 - ETA: 4:42 - loss: 116.7046 - mae: 8.750 - ETA: 4:39 - loss: 119.0855 - mae: 8.806 - ETA: 4:37 - loss: 121.9329 - mae: 8.877 - ETA: 4:35 - loss: 120.5492 - mae: 8.847 - ETA: 4:33 - loss: 122.5026 - mae: 8.883 - ETA: 4:31 - loss: 121.1479 - mae: 8.853 - ETA: 4:30 - loss: 121.5688 - mae: 8.883 - ETA: 4:28 - loss: 120.3964 - mae: 8.828 - ETA: 4:27 - loss: 119.7014 - mae: 8.787 - ETA: 4:26 - loss: 122.3031 - mae: 8.897 - ETA: 4:25 - loss: 120.4251 - mae: 8.826 - ETA: 4:25 - loss: 119.7993 - mae: 8.782 - ETA: 4:26 - loss: 121.5157 - mae: 8.847 - ETA: 4:27 - loss: 122.0909 - mae: 8.885 - ETA: 4:29 - loss: 122.1380 - mae: 8.874 - ETA: 4:29 - loss: 122.0505 - mae: 8.896 - ETA: 4:28 - loss: 122.8119 - mae: 8.917 - ETA: 4:26 - loss: 120.5602 - mae: 8.827 - ETA: 4:24 - loss: 120.4441 - mae: 8.825 - ETA: 4:21 - loss: 119.2868 - mae: 8.774 - ETA: 4:18 - loss: 120.3554 - mae: 8.784 - ETA: 4:15 - loss: 119.9099 - mae: 8.783 - ETA: 4:11 - loss: 119.8790 - mae: 8.782 - ETA: 4:08 - loss: 119.2847 - mae: 8.768 - ETA: 4:05 - loss: 119.7845 - mae: 8.777 - ETA: 4:01 - loss: 118.7710 - mae: 8.729 - ETA: 3:58 - loss: 117.9582 - mae: 8.705 - ETA: 3:55 - loss: 117.2688 - mae: 8.694 - ETA: 3:52 - loss: 117.1946 - mae: 8.691 - ETA: 3:48 - loss: 117.1427 - mae: 8.675 - ETA: 3:45 - loss: 117.0881 - mae: 8.688 - ETA: 3:42 - loss: 116.6320 - mae: 8.678 - ETA: 3:39 - loss: 116.2127 - mae: 8.674 - ETA: 3:36 - loss: 117.7329 - mae: 8.739 - ETA: 3:33 - loss: 118.2503 - mae: 8.754 - ETA: 3:30 - loss: 118.2837 - mae: 8.776 - ETA: 3:27 - loss: 117.9142 - mae: 8.753 - ETA: 3:24 - loss: 117.5110 - mae: 8.742 - ETA: 3:22 - loss: 117.0470 - mae: 8.727 - ETA: 3:20 - loss: 116.4869 - mae: 8.707 - ETA: 3:18 - loss: 116.2498 - mae: 8.703 - ETA: 3:16 - loss: 115.9994 - mae: 8.704 - ETA: 3:13 - loss: 115.7432 - mae: 8.702 - ETA: 3:11 - loss: 116.7167 - mae: 8.730 - ETA: 3:09 - loss: 116.3777 - mae: 8.716 - ETA: 3:07 - loss: 116.5842 - mae: 8.716 - ETA: 3:06 - loss: 116.9348 - mae: 8.736 - ETA: 3:04 - loss: 116.7156 - mae: 8.732 - ETA: 3:02 - loss: 117.4447 - mae: 8.757 - ETA: 3:00 - loss: 117.3427 - mae: 8.761 - ETA: 2:57 - loss: 117.7374 - mae: 8.784 - ETA: 2:55 - loss: 117.0671 - mae: 8.754 - ETA: 2:52 - loss: 117.7670 - mae: 8.777 - ETA: 2:49 - loss: 117.4130 - mae: 8.768 - ETA: 2:46 - loss: 117.5214 - mae: 8.780 - ETA: 2:43 - loss: 117.4921 - mae: 8.774 - ETA: 2:40 - loss: 117.9592 - mae: 8.779 - ETA: 2:37 - loss: 117.5969 - mae: 8.765 - ETA: 2:35 - loss: 117.3004 - mae: 8.751 - ETA: 2:32 - loss: 117.9552 - mae: 8.773 - ETA: 2:29 - loss: 117.7767 - mae: 8.767 - ETA: 2:26 - loss: 117.4819 - mae: 8.753 - ETA: 2:23 - loss: 117.7260 - mae: 8.772 - ETA: 2:20 - loss: 118.0679 - mae: 8.784 - ETA: 2:17 - loss: 118.4513 - mae: 8.794 - ETA: 2:14 - loss: 118.0273 - mae: 8.774 - ETA: 2:11 - loss: 119.1182 - mae: 8.823 - ETA: 2:08 - loss: 118.9472 - mae: 8.819 - ETA: 2:05 - loss: 119.0232 - mae: 8.823 - ETA: 2:02 - loss: 119.0731 - mae: 8.831 - ETA: 1:59 - loss: 118.6495 - mae: 8.816 - ETA: 1:57 - loss: 118.2670 - mae: 8.808 - ETA: 1:54 - loss: 118.2261 - mae: 8.812 - ETA: 1:51 - loss: 118.1604 - mae: 8.810 - ETA: 1:48 - loss: 118.7055 - mae: 8.830 - ETA: 1:45 - loss: 118.9597 - mae: 8.848 - ETA: 1:43 - loss: 119.3034 - mae: 8.861 - ETA: 1:40 - loss: 119.4343 - mae: 8.870 - ETA: 1:37 - loss: 119.2120 - mae: 8.860 - ETA: 1:35 - loss: 119.3142 - mae: 8.856 - ETA: 1:33 - loss: 119.4218 - mae: 8.856 - ETA: 1:30 - loss: 120.0315 - mae: 8.886 - ETA: 1:28 - loss: 120.2305 - mae: 8.886 - ETA: 1:26 - loss: 119.7314 - mae: 8.872 - ETA: 1:23 - loss: 119.8383 - mae: 8.882 - ETA: 1:20 - loss: 119.7156 - mae: 8.872 - ETA: 1:18 - loss: 119.8439 - mae: 8.881 - ETA: 1:15 - loss: 120.1824 - mae: 8.895 - ETA: 1:12 - loss: 119.8781 - mae: 8.889 - ETA: 1:09 - loss: 119.9112 - mae: 8.886 - ETA: 1:06 - loss: 120.5098 - mae: 8.912 - ETA: 1:04 - loss: 120.4816 - mae: 8.914 - ETA: 1:01 - loss: 120.4873 - mae: 8.918 - ETA: 58s - loss: 120.4159 - mae: 8.912 - ETA: 55s - loss: 119.8642 - mae: 8.88 - ETA: 52s - loss: 119.9071 - mae: 8.88 - ETA: 49s - loss: 120.1306 - mae: 8.89 - ETA: 47s - loss: 119.9650 - mae: 8.89 - ETA: 44s - loss: 119.6899 - mae: 8.89 - ETA: 41s - loss: 120.0393 - mae: 8.90 - ETA: 38s - loss: 120.1523 - mae: 8.91 - ETA: 35s - loss: 120.1808 - mae: 8.91 - ETA: 33s - loss: 120.3854 - mae: 8.91 - ETA: 30s - loss: 120.7602 - mae: 8.92 - ETA: 27s - loss: 120.4322 - mae: 8.91 - ETA: 24s - loss: 120.7158 - mae: 8.92 - ETA: 21s - loss: 120.6963 - mae: 8.92 - ETA: 19s - loss: 120.3989 - mae: 8.90 - ETA: 16s - loss: 120.6444 - mae: 8.92 - ETA: 13s - loss: 120.4701 - mae: 8.91 - ETA: 10s - loss: 120.3541 - mae: 8.91 - ETA: 8s - loss: 120.3389 - mae: 8.9145 - ETA: 5s - loss: 120.2589 - mae: 8.914 - ETA: 2s - loss: 120.1288 - mae: 8.912 - ETA: 0s - loss: 120.1639 - mae: 8.914 - 427s 3s/step - loss: 120.1639 - mae: 8.9145 - val_loss: 118.0768 - val_mae: 8.7226\n",
      "\n",
      "Epoch 00027: saving model to CP_ResNet50_Sample100_Fine50_2\\cp-0027.ckpt\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - ETA: 6:15 - loss: 121.9175 - mae: 9.369 - ETA: 6:55 - loss: 113.4109 - mae: 8.467 - ETA: 6:52 - loss: 114.6961 - mae: 8.470 - ETA: 7:03 - loss: 131.1704 - mae: 9.288 - ETA: 7:13 - loss: 129.7380 - mae: 9.294 - ETA: 7:25 - loss: 124.9955 - mae: 9.122 - ETA: 7:32 - loss: 120.4888 - mae: 8.995 - ETA: 7:30 - loss: 121.6343 - mae: 8.966 - ETA: 7:23 - loss: 121.8946 - mae: 9.005 - ETA: 7:13 - loss: 123.6153 - mae: 9.085 - ETA: 7:03 - loss: 123.6917 - mae: 9.091 - ETA: 6:52 - loss: 122.2332 - mae: 9.053 - ETA: 6:41 - loss: 119.9889 - mae: 9.013 - ETA: 6:31 - loss: 119.2696 - mae: 8.942 - ETA: 6:21 - loss: 116.9790 - mae: 8.845 - ETA: 6:12 - loss: 115.7182 - mae: 8.787 - ETA: 6:03 - loss: 116.0887 - mae: 8.795 - ETA: 5:55 - loss: 116.2935 - mae: 8.774 - ETA: 5:48 - loss: 114.9642 - mae: 8.700 - ETA: 5:41 - loss: 117.7081 - mae: 8.819 - ETA: 5:34 - loss: 116.6899 - mae: 8.804 - ETA: 5:28 - loss: 114.9695 - mae: 8.700 - ETA: 5:23 - loss: 115.2293 - mae: 8.729 - ETA: 5:18 - loss: 117.1518 - mae: 8.787 - ETA: 5:13 - loss: 116.7383 - mae: 8.724 - ETA: 5:07 - loss: 116.9238 - mae: 8.732 - ETA: 5:02 - loss: 117.2529 - mae: 8.746 - ETA: 4:58 - loss: 117.9981 - mae: 8.776 - ETA: 4:54 - loss: 119.3072 - mae: 8.813 - ETA: 4:50 - loss: 118.3538 - mae: 8.781 - ETA: 4:47 - loss: 117.7888 - mae: 8.786 - ETA: 4:43 - loss: 117.7709 - mae: 8.799 - ETA: 4:40 - loss: 118.5517 - mae: 8.798 - ETA: 4:38 - loss: 118.3346 - mae: 8.798 - ETA: 4:36 - loss: 118.0114 - mae: 8.773 - ETA: 4:34 - loss: 116.8536 - mae: 8.732 - ETA: 4:33 - loss: 118.4857 - mae: 8.796 - ETA: 4:30 - loss: 118.9757 - mae: 8.833 - ETA: 4:27 - loss: 118.9462 - mae: 8.833 - ETA: 4:24 - loss: 118.3339 - mae: 8.804 - ETA: 4:21 - loss: 118.1425 - mae: 8.794 - ETA: 4:17 - loss: 118.5729 - mae: 8.821 - ETA: 4:13 - loss: 119.0361 - mae: 8.846 - ETA: 4:09 - loss: 118.7025 - mae: 8.824 - ETA: 4:05 - loss: 118.1109 - mae: 8.799 - ETA: 4:01 - loss: 117.7290 - mae: 8.787 - ETA: 3:57 - loss: 118.1205 - mae: 8.790 - ETA: 3:53 - loss: 117.9787 - mae: 8.757 - ETA: 3:49 - loss: 117.5558 - mae: 8.742 - ETA: 3:45 - loss: 118.1764 - mae: 8.748 - ETA: 3:41 - loss: 118.7181 - mae: 8.782 - ETA: 3:38 - loss: 119.1003 - mae: 8.785 - ETA: 3:34 - loss: 118.9935 - mae: 8.789 - ETA: 3:30 - loss: 118.8255 - mae: 8.785 - ETA: 3:27 - loss: 118.8701 - mae: 8.789 - ETA: 3:23 - loss: 118.3792 - mae: 8.779 - ETA: 3:20 - loss: 117.8359 - mae: 8.760 - ETA: 3:17 - loss: 118.1046 - mae: 8.775 - ETA: 3:13 - loss: 117.2403 - mae: 8.741 - ETA: 3:10 - loss: 117.4226 - mae: 8.755 - ETA: 3:07 - loss: 117.4114 - mae: 8.756 - ETA: 3:04 - loss: 117.2843 - mae: 8.754 - ETA: 3:01 - loss: 117.9034 - mae: 8.779 - ETA: 2:58 - loss: 117.5870 - mae: 8.767 - ETA: 2:55 - loss: 117.6253 - mae: 8.771 - ETA: 2:52 - loss: 117.7109 - mae: 8.783 - ETA: 2:50 - loss: 117.9442 - mae: 8.792 - ETA: 2:47 - loss: 118.2286 - mae: 8.808 - ETA: 2:45 - loss: 118.0946 - mae: 8.793 - ETA: 2:43 - loss: 118.5801 - mae: 8.804 - ETA: 2:41 - loss: 118.1367 - mae: 8.780 - ETA: 2:38 - loss: 118.6723 - mae: 8.788 - ETA: 2:35 - loss: 118.6983 - mae: 8.788 - ETA: 2:32 - loss: 119.0904 - mae: 8.813 - ETA: 2:29 - loss: 119.7202 - mae: 8.841 - ETA: 2:26 - loss: 120.1262 - mae: 8.855 - ETA: 2:23 - loss: 120.3709 - mae: 8.875 - ETA: 2:20 - loss: 119.9071 - mae: 8.859 - ETA: 2:16 - loss: 119.9280 - mae: 8.859 - ETA: 2:13 - loss: 119.8644 - mae: 8.855 - ETA: 2:10 - loss: 119.3741 - mae: 8.834 - ETA: 2:07 - loss: 119.9844 - mae: 8.854 - ETA: 2:04 - loss: 120.0855 - mae: 8.855 - ETA: 2:00 - loss: 120.0664 - mae: 8.859 - ETA: 1:57 - loss: 120.1214 - mae: 8.868 - ETA: 1:54 - loss: 120.4262 - mae: 8.877 - ETA: 1:51 - loss: 121.2032 - mae: 8.891 - ETA: 1:48 - loss: 121.4225 - mae: 8.903 - ETA: 1:45 - loss: 121.2547 - mae: 8.897 - ETA: 1:42 - loss: 121.0947 - mae: 8.894 - ETA: 1:38 - loss: 121.5553 - mae: 8.907 - ETA: 1:35 - loss: 121.3167 - mae: 8.897 - ETA: 1:32 - loss: 121.3729 - mae: 8.903 - ETA: 1:29 - loss: 121.5634 - mae: 8.913 - ETA: 1:26 - loss: 121.6201 - mae: 8.916 - ETA: 1:23 - loss: 121.4821 - mae: 8.916 - ETA: 1:20 - loss: 121.5024 - mae: 8.917 - ETA: 1:17 - loss: 121.3544 - mae: 8.918 - ETA: 1:14 - loss: 121.4023 - mae: 8.923 - ETA: 1:11 - loss: 121.5180 - mae: 8.934 - ETA: 1:09 - loss: 122.1303 - mae: 8.956 - ETA: 1:06 - loss: 121.7705 - mae: 8.947 - ETA: 1:03 - loss: 121.3659 - mae: 8.936 - ETA: 1:00 - loss: 121.2891 - mae: 8.939 - ETA: 58s - loss: 121.2533 - mae: 8.932 - ETA: 55s - loss: 121.2098 - mae: 8.92 - ETA: 52s - loss: 120.7839 - mae: 8.91 - ETA: 49s - loss: 120.6326 - mae: 8.90 - ETA: 47s - loss: 120.3952 - mae: 8.88 - ETA: 44s - loss: 120.4669 - mae: 8.89 - ETA: 41s - loss: 120.8242 - mae: 8.90 - ETA: 38s - loss: 120.5715 - mae: 8.89 - ETA: 35s - loss: 120.1315 - mae: 8.88 - ETA: 32s - loss: 119.9262 - mae: 8.87 - ETA: 29s - loss: 120.0165 - mae: 8.88 - ETA: 26s - loss: 120.0460 - mae: 8.88 - ETA: 23s - loss: 120.4401 - mae: 8.89 - ETA: 20s - loss: 120.9426 - mae: 8.91 - ETA: 17s - loss: 120.7009 - mae: 8.90 - ETA: 14s - loss: 120.3386 - mae: 8.89 - ETA: 11s - loss: 120.5040 - mae: 8.90 - ETA: 8s - loss: 120.8720 - mae: 8.9300 - ETA: 5s - loss: 120.6953 - mae: 8.922 - ETA: 2s - loss: 120.6489 - mae: 8.920 - ETA: 0s - loss: 120.3037 - mae: 8.907 - 450s 4s/step - loss: 120.3037 - mae: 8.9078 - val_loss: 117.2390 - val_mae: 8.6861\n",
      "\n",
      "Epoch 00028: saving model to CP_ResNet50_Sample100_Fine50_2\\cp-0028.ckpt\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - ETA: 5:04 - loss: 190.6832 - mae: 11.67 - ETA: 5:17 - loss: 152.6729 - mae: 10.11 - ETA: 5:17 - loss: 127.1440 - mae: 8.9853 - ETA: 5:07 - loss: 127.6334 - mae: 9.136 - ETA: 5:03 - loss: 126.2942 - mae: 9.147 - ETA: 4:58 - loss: 116.9070 - mae: 8.857 - ETA: 4:55 - loss: 114.2512 - mae: 8.795 - ETA: 4:54 - loss: 119.8827 - mae: 8.937 - ETA: 4:52 - loss: 120.6828 - mae: 8.919 - ETA: 4:50 - loss: 117.2926 - mae: 8.746 - ETA: 4:48 - loss: 116.9847 - mae: 8.736 - ETA: 4:46 - loss: 115.6894 - mae: 8.645 - ETA: 4:46 - loss: 121.7083 - mae: 8.883 - ETA: 4:45 - loss: 122.3976 - mae: 8.888 - ETA: 4:45 - loss: 121.8029 - mae: 8.889 - ETA: 4:45 - loss: 122.6029 - mae: 8.946 - ETA: 4:46 - loss: 120.6886 - mae: 8.851 - ETA: 4:48 - loss: 118.9464 - mae: 8.784 - ETA: 4:51 - loss: 118.7155 - mae: 8.771 - ETA: 4:52 - loss: 119.9919 - mae: 8.813 - ETA: 4:52 - loss: 119.2073 - mae: 8.773 - ETA: 4:51 - loss: 120.0770 - mae: 8.830 - ETA: 4:50 - loss: 121.5288 - mae: 8.876 - ETA: 4:52 - loss: 121.2182 - mae: 8.863 - ETA: 4:52 - loss: 119.5790 - mae: 8.791 - ETA: 4:51 - loss: 117.4809 - mae: 8.709 - ETA: 4:49 - loss: 118.6632 - mae: 8.762 - ETA: 4:46 - loss: 119.3636 - mae: 8.784 - ETA: 4:43 - loss: 120.9122 - mae: 8.843 - ETA: 4:40 - loss: 120.8399 - mae: 8.819 - ETA: 4:38 - loss: 121.6304 - mae: 8.863 - ETA: 4:35 - loss: 120.5935 - mae: 8.814 - ETA: 4:33 - loss: 120.1865 - mae: 8.806 - ETA: 4:30 - loss: 119.2579 - mae: 8.783 - ETA: 4:27 - loss: 118.4610 - mae: 8.749 - ETA: 4:25 - loss: 118.6881 - mae: 8.773 - ETA: 4:24 - loss: 118.2360 - mae: 8.760 - ETA: 4:23 - loss: 118.1678 - mae: 8.762 - ETA: 4:23 - loss: 117.6323 - mae: 8.765 - ETA: 4:24 - loss: 117.1706 - mae: 8.746 - ETA: 4:25 - loss: 118.6528 - mae: 8.783 - ETA: 4:26 - loss: 118.2288 - mae: 8.768 - ETA: 4:25 - loss: 117.4115 - mae: 8.742 - ETA: 4:24 - loss: 116.6691 - mae: 8.702 - ETA: 4:21 - loss: 115.7559 - mae: 8.676 - ETA: 4:18 - loss: 115.5075 - mae: 8.670 - ETA: 4:14 - loss: 115.0419 - mae: 8.641 - ETA: 4:10 - loss: 114.5549 - mae: 8.629 - ETA: 4:07 - loss: 114.6549 - mae: 8.646 - ETA: 4:03 - loss: 114.3283 - mae: 8.637 - ETA: 3:59 - loss: 114.4331 - mae: 8.653 - ETA: 3:55 - loss: 115.9061 - mae: 8.713 - ETA: 3:51 - loss: 115.7365 - mae: 8.713 - ETA: 3:47 - loss: 116.6712 - mae: 8.717 - ETA: 3:44 - loss: 117.0895 - mae: 8.719 - ETA: 3:40 - loss: 116.5279 - mae: 8.699 - ETA: 3:36 - loss: 116.2529 - mae: 8.700 - ETA: 3:32 - loss: 115.6894 - mae: 8.686 - ETA: 3:29 - loss: 115.5057 - mae: 8.683 - ETA: 3:25 - loss: 116.1685 - mae: 8.711 - ETA: 3:21 - loss: 116.6883 - mae: 8.726 - ETA: 3:18 - loss: 116.6963 - mae: 8.721 - ETA: 3:14 - loss: 116.3131 - mae: 8.705 - ETA: 3:11 - loss: 116.2052 - mae: 8.710 - ETA: 3:08 - loss: 116.1589 - mae: 8.709 - ETA: 3:05 - loss: 116.3166 - mae: 8.722 - ETA: 3:02 - loss: 116.9593 - mae: 8.737 - ETA: 3:00 - loss: 116.5028 - mae: 8.719 - ETA: 2:59 - loss: 116.5073 - mae: 8.717 - ETA: 2:57 - loss: 116.3061 - mae: 8.716 - ETA: 2:55 - loss: 117.0593 - mae: 8.743 - ETA: 2:52 - loss: 117.6770 - mae: 8.759 - ETA: 2:49 - loss: 117.9277 - mae: 8.765 - ETA: 2:46 - loss: 117.4796 - mae: 8.745 - ETA: 2:43 - loss: 117.1855 - mae: 8.739 - ETA: 2:39 - loss: 116.8228 - mae: 8.725 - ETA: 2:36 - loss: 116.7593 - mae: 8.720 - ETA: 2:32 - loss: 116.8896 - mae: 8.731 - ETA: 2:29 - loss: 117.0724 - mae: 8.747 - ETA: 2:25 - loss: 117.2343 - mae: 8.751 - ETA: 2:22 - loss: 117.1861 - mae: 8.757 - ETA: 2:18 - loss: 117.4494 - mae: 8.769 - ETA: 2:15 - loss: 117.1798 - mae: 8.755 - ETA: 2:11 - loss: 116.9482 - mae: 8.746 - ETA: 2:08 - loss: 117.0786 - mae: 8.754 - ETA: 2:04 - loss: 117.3298 - mae: 8.761 - ETA: 2:01 - loss: 117.8643 - mae: 8.776 - ETA: 1:57 - loss: 117.7308 - mae: 8.769 - ETA: 1:54 - loss: 117.3607 - mae: 8.757 - ETA: 1:50 - loss: 117.5016 - mae: 8.765 - ETA: 1:47 - loss: 118.0124 - mae: 8.779 - ETA: 1:43 - loss: 118.0194 - mae: 8.777 - ETA: 1:40 - loss: 118.3477 - mae: 8.797 - ETA: 1:37 - loss: 118.5568 - mae: 8.809 - ETA: 1:33 - loss: 119.1134 - mae: 8.838 - ETA: 1:30 - loss: 119.2267 - mae: 8.839 - ETA: 1:27 - loss: 119.4539 - mae: 8.849 - ETA: 1:24 - loss: 118.7997 - mae: 8.820 - ETA: 1:20 - loss: 119.1856 - mae: 8.835 - ETA: 1:17 - loss: 119.0612 - mae: 8.833 - ETA: 1:14 - loss: 118.8827 - mae: 8.819 - ETA: 1:11 - loss: 118.6932 - mae: 8.819 - ETA: 1:08 - loss: 119.1482 - mae: 8.841 - ETA: 1:05 - loss: 119.2092 - mae: 8.843 - ETA: 1:02 - loss: 118.9531 - mae: 8.833 - ETA: 59s - loss: 118.7934 - mae: 8.827 - ETA: 56s - loss: 118.7226 - mae: 8.82 - ETA: 53s - loss: 119.0050 - mae: 8.83 - ETA: 50s - loss: 119.0953 - mae: 8.84 - ETA: 47s - loss: 119.3870 - mae: 8.85 - ETA: 44s - loss: 119.1681 - mae: 8.84 - ETA: 40s - loss: 118.8547 - mae: 8.83 - ETA: 37s - loss: 118.8806 - mae: 8.83 - ETA: 34s - loss: 118.7730 - mae: 8.83 - ETA: 31s - loss: 118.4025 - mae: 8.81 - ETA: 28s - loss: 118.2423 - mae: 8.81 - ETA: 24s - loss: 118.2568 - mae: 8.81 - ETA: 21s - loss: 118.1891 - mae: 8.81 - ETA: 18s - loss: 118.3860 - mae: 8.82 - ETA: 15s - loss: 118.9613 - mae: 8.84 - ETA: 12s - loss: 118.7803 - mae: 8.84 - ETA: 9s - loss: 119.0955 - mae: 8.8557 - ETA: 6s - loss: 119.5050 - mae: 8.872 - ETA: 3s - loss: 119.2244 - mae: 8.860 - ETA: 0s - loss: 119.1179 - mae: 8.857 - 474s 4s/step - loss: 119.1179 - mae: 8.8578 - val_loss: 116.6258 - val_mae: 8.6704\n",
      "\n",
      "Epoch 00029: saving model to CP_ResNet50_Sample100_Fine50_2\\cp-0029.ckpt\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - ETA: 5:26 - loss: 123.3470 - mae: 8.550 - ETA: 5:11 - loss: 124.6737 - mae: 8.921 - ETA: 5:06 - loss: 121.3946 - mae: 8.980 - ETA: 5:03 - loss: 112.1816 - mae: 8.663 - ETA: 4:58 - loss: 104.9010 - mae: 8.333 - ETA: 4:55 - loss: 117.4109 - mae: 8.830 - ETA: 4:52 - loss: 118.0896 - mae: 8.861 - ETA: 4:50 - loss: 113.7356 - mae: 8.683 - ETA: 4:47 - loss: 115.5151 - mae: 8.666 - ETA: 4:46 - loss: 117.5430 - mae: 8.758 - ETA: 4:44 - loss: 117.9788 - mae: 8.775 - ETA: 4:43 - loss: 116.5681 - mae: 8.755 - ETA: 4:42 - loss: 117.5550 - mae: 8.790 - ETA: 4:41 - loss: 115.3079 - mae: 8.714 - ETA: 4:40 - loss: 116.3425 - mae: 8.775 - ETA: 4:41 - loss: 116.1452 - mae: 8.752 - ETA: 4:42 - loss: 116.3553 - mae: 8.754 - ETA: 4:50 - loss: 114.6347 - mae: 8.679 - ETA: 4:52 - loss: 114.9530 - mae: 8.687 - ETA: 4:55 - loss: 112.5719 - mae: 8.590 - ETA: 4:59 - loss: 112.3467 - mae: 8.560 - ETA: 5:02 - loss: 111.4653 - mae: 8.515 - ETA: 5:02 - loss: 110.4525 - mae: 8.470 - ETA: 5:02 - loss: 114.3285 - mae: 8.624 - ETA: 5:00 - loss: 115.8764 - mae: 8.690 - ETA: 4:57 - loss: 115.7622 - mae: 8.660 - ETA: 4:53 - loss: 117.5743 - mae: 8.725 - ETA: 4:49 - loss: 115.6375 - mae: 8.633 - ETA: 4:45 - loss: 114.8664 - mae: 8.604 - ETA: 4:41 - loss: 117.2693 - mae: 8.692 - ETA: 4:37 - loss: 117.9041 - mae: 8.708 - ETA: 4:33 - loss: 116.5546 - mae: 8.660 - ETA: 4:28 - loss: 115.4804 - mae: 8.629 - ETA: 4:24 - loss: 114.9063 - mae: 8.613 - ETA: 4:20 - loss: 114.1591 - mae: 8.565 - ETA: 4:16 - loss: 114.7228 - mae: 8.602 - ETA: 4:12 - loss: 114.5782 - mae: 8.605 - ETA: 4:09 - loss: 114.7210 - mae: 8.614 - ETA: 4:05 - loss: 115.8303 - mae: 8.668 - ETA: 4:01 - loss: 116.7966 - mae: 8.717 - ETA: 3:57 - loss: 117.2977 - mae: 8.749 - ETA: 3:54 - loss: 116.6605 - mae: 8.742 - ETA: 3:50 - loss: 116.5714 - mae: 8.736 - ETA: 3:47 - loss: 116.4843 - mae: 8.731 - ETA: 3:43 - loss: 116.1062 - mae: 8.729 - ETA: 3:40 - loss: 116.5693 - mae: 8.746 - ETA: 3:37 - loss: 117.5717 - mae: 8.781 - ETA: 3:33 - loss: 117.3434 - mae: 8.785 - ETA: 3:30 - loss: 116.6075 - mae: 8.764 - ETA: 3:27 - loss: 116.0648 - mae: 8.741 - ETA: 3:24 - loss: 117.3197 - mae: 8.777 - ETA: 3:22 - loss: 117.0792 - mae: 8.771 - ETA: 3:19 - loss: 116.8674 - mae: 8.767 - ETA: 3:16 - loss: 116.2757 - mae: 8.745 - ETA: 3:14 - loss: 116.2708 - mae: 8.748 - ETA: 3:12 - loss: 115.3595 - mae: 8.711 - ETA: 3:10 - loss: 115.1710 - mae: 8.695 - ETA: 3:09 - loss: 114.7214 - mae: 8.669 - ETA: 3:07 - loss: 115.0056 - mae: 8.677 - ETA: 3:04 - loss: 115.7216 - mae: 8.690 - ETA: 3:02 - loss: 115.4653 - mae: 8.679 - ETA: 2:59 - loss: 115.4680 - mae: 8.685 - ETA: 2:56 - loss: 115.5621 - mae: 8.687 - ETA: 2:53 - loss: 116.3708 - mae: 8.719 - ETA: 2:50 - loss: 116.6411 - mae: 8.739 - ETA: 2:47 - loss: 116.3168 - mae: 8.741 - ETA: 2:44 - loss: 115.9715 - mae: 8.734 - ETA: 2:41 - loss: 115.3747 - mae: 8.706 - ETA: 2:38 - loss: 115.6306 - mae: 8.713 - ETA: 2:35 - loss: 115.7040 - mae: 8.705 - ETA: 2:32 - loss: 115.4712 - mae: 8.699 - ETA: 2:28 - loss: 116.1403 - mae: 8.726 - ETA: 2:25 - loss: 115.7923 - mae: 8.712 - ETA: 2:22 - loss: 115.9334 - mae: 8.712 - ETA: 2:19 - loss: 115.5467 - mae: 8.696 - ETA: 2:16 - loss: 115.8458 - mae: 8.702 - ETA: 2:13 - loss: 116.3918 - mae: 8.720 - ETA: 2:10 - loss: 116.9615 - mae: 8.755 - ETA: 2:07 - loss: 116.9879 - mae: 8.751 - ETA: 2:04 - loss: 117.1785 - mae: 8.766 - ETA: 2:02 - loss: 116.8171 - mae: 8.760 - ETA: 1:59 - loss: 117.3559 - mae: 8.786 - ETA: 1:56 - loss: 116.8098 - mae: 8.760 - ETA: 1:53 - loss: 116.6240 - mae: 8.754 - ETA: 1:50 - loss: 116.7359 - mae: 8.762 - ETA: 1:47 - loss: 116.8079 - mae: 8.773 - ETA: 1:45 - loss: 116.6530 - mae: 8.762 - ETA: 1:42 - loss: 117.0976 - mae: 8.775 - ETA: 1:40 - loss: 117.3012 - mae: 8.783 - ETA: 1:37 - loss: 117.4930 - mae: 8.786 - ETA: 1:35 - loss: 118.0558 - mae: 8.804 - ETA: 1:32 - loss: 118.0980 - mae: 8.806 - ETA: 1:30 - loss: 117.6961 - mae: 8.790 - ETA: 1:27 - loss: 118.0304 - mae: 8.805 - ETA: 1:25 - loss: 117.9227 - mae: 8.804 - ETA: 1:22 - loss: 118.2590 - mae: 8.823 - ETA: 1:19 - loss: 118.1293 - mae: 8.825 - ETA: 1:16 - loss: 117.5621 - mae: 8.798 - ETA: 1:13 - loss: 117.5757 - mae: 8.804 - ETA: 1:10 - loss: 117.7064 - mae: 8.812 - ETA: 1:08 - loss: 117.8915 - mae: 8.818 - ETA: 1:05 - loss: 118.2385 - mae: 8.832 - ETA: 1:02 - loss: 118.2317 - mae: 8.828 - ETA: 59s - loss: 118.4781 - mae: 8.843 - ETA: 56s - loss: 118.3058 - mae: 8.83 - ETA: 53s - loss: 118.0347 - mae: 8.82 - ETA: 50s - loss: 117.9276 - mae: 8.81 - ETA: 47s - loss: 117.7787 - mae: 8.81 - ETA: 44s - loss: 117.5360 - mae: 8.80 - ETA: 42s - loss: 117.6674 - mae: 8.81 - ETA: 39s - loss: 117.7079 - mae: 8.81 - ETA: 36s - loss: 117.7764 - mae: 8.81 - ETA: 33s - loss: 117.9311 - mae: 8.82 - ETA: 30s - loss: 117.8984 - mae: 8.82 - ETA: 27s - loss: 117.6696 - mae: 8.81 - ETA: 25s - loss: 117.3343 - mae: 8.79 - ETA: 22s - loss: 117.2799 - mae: 8.79 - ETA: 19s - loss: 117.1939 - mae: 8.79 - ETA: 16s - loss: 117.1208 - mae: 8.78 - ETA: 13s - loss: 117.4655 - mae: 8.80 - ETA: 11s - loss: 117.3581 - mae: 8.80 - ETA: 8s - loss: 117.1960 - mae: 8.7985 - ETA: 5s - loss: 117.1899 - mae: 8.796 - ETA: 2s - loss: 117.5441 - mae: 8.805 - ETA: 0s - loss: 117.5218 - mae: 8.804 - 431s 3s/step - loss: 117.5218 - mae: 8.8044 - val_loss: 115.9131 - val_mae: 8.6365\n",
      "\n",
      "Epoch 00030: saving model to CP_ResNet50_Sample100_Fine50_2\\cp-0030.ckpt\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds,\n",
    "                     epochs=30,\n",
    "                     callbacks=[cp_callback],\n",
    "                     validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [194.4598846435547,\n",
       "  153.9873504638672,\n",
       "  146.11264038085938,\n",
       "  141.2102508544922,\n",
       "  138.9334259033203,\n",
       "  135.52719116210938,\n",
       "  134.9622344970703,\n",
       "  132.33900451660156,\n",
       "  131.4904327392578,\n",
       "  130.28353881835938,\n",
       "  128.77520751953125,\n",
       "  128.54603576660156,\n",
       "  126.8129653930664,\n",
       "  125.65975189208984,\n",
       "  126.62812042236328,\n",
       "  124.14226531982422,\n",
       "  125.65745544433594,\n",
       "  122.59550476074219,\n",
       "  123.09249114990234,\n",
       "  122.986328125,\n",
       "  122.3177719116211,\n",
       "  121.2315673828125,\n",
       "  121.44738006591797,\n",
       "  120.77493286132812,\n",
       "  120.69660949707031,\n",
       "  119.40460205078125,\n",
       "  120.16385650634766,\n",
       "  120.30366516113281,\n",
       "  119.1178970336914,\n",
       "  117.5218276977539],\n",
       " 'mae': [11.69827651977539,\n",
       "  10.361684799194336,\n",
       "  9.968050003051758,\n",
       "  9.726761817932129,\n",
       "  9.656944274902344,\n",
       "  9.509648323059082,\n",
       "  9.492093086242676,\n",
       "  9.386033058166504,\n",
       "  9.327998161315918,\n",
       "  9.27818775177002,\n",
       "  9.238670349121094,\n",
       "  9.237186431884766,\n",
       "  9.161361694335938,\n",
       "  9.127394676208496,\n",
       "  9.165328979492188,\n",
       "  9.018085479736328,\n",
       "  9.151766777038574,\n",
       "  9.013748168945312,\n",
       "  9.012826919555664,\n",
       "  8.999988555908203,\n",
       "  8.958412170410156,\n",
       "  8.94994068145752,\n",
       "  8.96870231628418,\n",
       "  8.90073013305664,\n",
       "  8.955437660217285,\n",
       "  8.8479585647583,\n",
       "  8.914470672607422,\n",
       "  8.90775203704834,\n",
       "  8.857797622680664,\n",
       "  8.80439567565918],\n",
       " 'val_loss': [161.21685791015625,\n",
       "  140.0269775390625,\n",
       "  136.45217895507812,\n",
       "  133.81259155273438,\n",
       "  130.31051635742188,\n",
       "  128.86598205566406,\n",
       "  127.56774139404297,\n",
       "  125.30253601074219,\n",
       "  125.5977783203125,\n",
       "  125.06031799316406,\n",
       "  123.98444366455078,\n",
       "  123.24579620361328,\n",
       "  122.02850341796875,\n",
       "  121.63006591796875,\n",
       "  120.3406753540039,\n",
       "  121.86102294921875,\n",
       "  121.68982696533203,\n",
       "  119.6733169555664,\n",
       "  120.0140151977539,\n",
       "  118.76701354980469,\n",
       "  118.3192138671875,\n",
       "  118.2112045288086,\n",
       "  118.2745361328125,\n",
       "  117.68729400634766,\n",
       "  118.24829864501953,\n",
       "  117.5777359008789,\n",
       "  118.07679748535156,\n",
       "  117.23899841308594,\n",
       "  116.62578582763672,\n",
       "  115.91310119628906],\n",
       " 'val_mae': [10.641620635986328,\n",
       "  9.801176071166992,\n",
       "  9.606216430664062,\n",
       "  9.47787094116211,\n",
       "  9.322558403015137,\n",
       "  9.254409790039062,\n",
       "  9.199010848999023,\n",
       "  9.0869722366333,\n",
       "  9.099478721618652,\n",
       "  9.074441909790039,\n",
       "  9.02524185180664,\n",
       "  8.983684539794922,\n",
       "  8.926192283630371,\n",
       "  8.907376289367676,\n",
       "  8.851176261901855,\n",
       "  8.91312313079834,\n",
       "  8.90029239654541,\n",
       "  8.81784439086914,\n",
       "  8.823406219482422,\n",
       "  8.765775680541992,\n",
       "  8.750832557678223,\n",
       "  8.751885414123535,\n",
       "  8.746624946594238,\n",
       "  8.722797393798828,\n",
       "  8.74004077911377,\n",
       "  8.711518287658691,\n",
       "  8.722633361816406,\n",
       "  8.686139106750488,\n",
       "  8.670430183410645,\n",
       "  8.636510848999023]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제로 True값과 Predicted값을 비교해보기 위한 코드. val_ds에서 3개만 가져와서 해봄\n",
    "i = 1\n",
    "image_batch_list = []\n",
    "label_batch_list = []\n",
    "for image_batch, label_batch in val_ds:\n",
    "    image_batch_list.append(image_batch)\n",
    "    label_batch_list.append(label_batch)\n",
    "    i+=1\n",
    "    if i == 4: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    true       pred       diff\n",
      "0     24  30.419407  -6.419407\n",
      "1     31  42.145233 -11.145233\n",
      "2     55  46.795982   8.204018\n",
      "3     31  35.352753  -4.352753\n",
      "4     51  50.975094   0.024906\n",
      "5     19  25.202307  -6.202307\n",
      "6     49  47.136391   1.863609\n",
      "7     60  52.503967   7.496033\n",
      "8     37  40.006660  -3.006660\n",
      "9     56  46.213005   9.786995\n",
      "10    43  41.927734   1.072266\n",
      "11    66  54.970798  11.029202\n",
      "12    18  24.986128  -6.986128\n",
      "13    54  56.537502  -2.537502\n",
      "14    55  51.517136   3.482864\n",
      "15    37  32.424129   4.575871\n",
      "16    61  54.436050   6.563950\n",
      "17    67  48.100098  18.899902\n",
      "18    18  29.910381 -11.910381\n",
      "19    37  37.433708  -0.433708\n",
      "20    28  37.094604  -9.094604\n",
      "21    66  47.224365  18.775635\n",
      "22    23  29.154343  -6.154343\n",
      "23    41  47.630074  -6.630074\n",
      "24    23  25.663458  -2.663458\n",
      "25    43  47.905441  -4.905441\n",
      "26    63  43.832397  19.167603\n",
      "27    30  38.953300  -8.953300\n",
      "28    46  44.618370   1.381630\n",
      "29    52  39.304825  12.695175\n",
      "30    57  51.727013   5.272987\n",
      "31    67  49.835861  17.164139\n",
      "    true       pred       diff\n",
      "0     46  27.856197  18.143803\n",
      "1     34  39.355633  -5.355633\n",
      "2     26  40.401733 -14.401733\n",
      "3     21  32.588787 -11.588787\n",
      "4     45  31.334755  13.665245\n",
      "5     36  43.179592  -7.179592\n",
      "6     40  49.553764  -9.553764\n",
      "7     37  38.500256  -1.500256\n",
      "8     37  32.589561   4.410439\n",
      "9     55  59.235981  -4.235981\n",
      "10    18  27.437868  -9.437868\n",
      "11    36  42.820667  -6.820667\n",
      "12    60  63.521160  -3.521160\n",
      "13    52  57.269146  -5.269146\n",
      "14    64  49.896172  14.103828\n",
      "15    35  29.513668   5.486332\n",
      "16    62  58.425030   3.574970\n",
      "17    67  51.362804  15.637196\n",
      "18    42  34.616322   7.383678\n",
      "19    62  43.970497  18.029503\n",
      "20    45  42.158379   2.841621\n",
      "21    61  52.584873   8.415127\n",
      "22    31  50.617439 -19.617439\n",
      "23    68  51.804295  16.195705\n",
      "24    41  45.423798  -4.423798\n",
      "25    58  54.607243   3.392757\n",
      "26    23  48.771339 -25.771339\n",
      "27    22  38.237892 -16.237892\n",
      "28    34  45.796608 -11.796608\n",
      "29    44  53.498196  -9.498196\n",
      "30    37  30.742817   6.257183\n",
      "31    56  55.023624   0.976376\n",
      "    true       pred       diff\n",
      "0     67  59.046127   7.953873\n",
      "1     53  27.760273  25.239727\n",
      "2     42  42.857765  -0.857765\n",
      "3     66  50.697086  15.302914\n",
      "4     46  46.337120  -0.337120\n",
      "5     53  40.747437  12.252563\n",
      "6     52  45.225479   6.774521\n",
      "7     31  27.692217   3.307783\n",
      "8     22  36.462776 -14.462776\n",
      "9     36  30.805729   5.194271\n",
      "10    56  39.713234  16.286766\n",
      "11    63  49.483421  13.516579\n",
      "12    21  34.080185 -13.080185\n",
      "13    33  34.369446  -1.369446\n",
      "14    41  40.339394   0.660606\n",
      "15    40  39.575417   0.424583\n",
      "16    29  38.057121  -9.057121\n",
      "17    39  46.379765  -7.379765\n",
      "18    67  58.625244   8.374756\n",
      "19    62  52.792507   9.207493\n",
      "20    46  43.064972   2.935028\n",
      "21    37  39.392090  -2.392090\n",
      "22    25  51.221775 -26.221775\n",
      "23    49  54.179188  -5.179188\n",
      "24    37  31.770538   5.229462\n",
      "25    40  41.100883  -1.100883\n",
      "26    64  41.365578  22.634422\n",
      "27    36  38.979851  -2.979851\n",
      "28    32  31.373966   0.626034\n",
      "29    55  47.558746   7.441254\n",
      "30    32  43.461990 -11.461990\n",
      "31    18  26.714024  -8.714024\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "for image_batch, label_batch in zip(image_batch_list, label_batch_list):\n",
    "    predicted_labels = model.predict(image_batch)\n",
    "    df = pd.DataFrame({'true':np.array(label_batch).reshape(-1,), \n",
    "                       'pred':predicted_labels.reshape(-1,)})\n",
    "    df = df + 18\n",
    "    df['diff'] = df['true']-df['pred']\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frank\\Anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    }
   ],
   "source": [
    "model.save('ResNet50_Sample100_Epoch30_BeforeFine50.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning : 50 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers in the base model:  175\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look to see how many layers are in the base model\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 125\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable =  False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 낮은 학습률 사용\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=base_learning_rate/10),\n",
    "              loss='mse',\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "tf.__operators__.getitem (Sl (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "tf.nn.bias_add (TFOpLambda)  (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 23,589,761\n",
      "Trainable params: 16,952,577\n",
      "Non-trainable params: 6,637,184\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path_for_fine = \"CP_ResNet50_Sample100_Fine50_Fine/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir_for_fine = os.path.dirname(checkpoint_path_for_fine)\n",
    "\n",
    "cp_callback_for_fine = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path_for_fine, \n",
    "    verbose=1, \n",
    "    save_weights_only=True,\n",
    "    save_freq='epoch')\n",
    "\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    min_delta=0, \n",
    "    patience=2, \n",
    "    verbose=1, \n",
    "    mode='min', \n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/40\n",
      "125/125 [==============================] - ETA: 12:26 - loss: 105.0330 - mae: 8.66 - ETA: 8:30 - loss: 130.0981 - mae: 9.4762 - ETA: 7:49 - loss: 129.6350 - mae: 9.603 - ETA: 7:31 - loss: 129.2332 - mae: 9.542 - ETA: 7:24 - loss: 131.4759 - mae: 9.480 - ETA: 7:20 - loss: 130.8796 - mae: 9.448 - ETA: 7:37 - loss: 124.7091 - mae: 9.167 - ETA: 7:40 - loss: 122.9880 - mae: 9.115 - ETA: 7:37 - loss: 121.9365 - mae: 9.073 - ETA: 7:42 - loss: 128.5849 - mae: 9.267 - ETA: 7:52 - loss: 125.7355 - mae: 9.215 - ETA: 7:54 - loss: 126.1085 - mae: 9.198 - ETA: 7:56 - loss: 123.5113 - mae: 9.076 - ETA: 7:59 - loss: 123.1566 - mae: 9.037 - ETA: 8:02 - loss: 122.3376 - mae: 8.936 - ETA: 8:03 - loss: 125.8570 - mae: 9.083 - ETA: 8:03 - loss: 128.9335 - mae: 9.251 - ETA: 8:03 - loss: 130.4735 - mae: 9.289 - ETA: 8:00 - loss: 130.4667 - mae: 9.266 - ETA: 7:56 - loss: 129.7880 - mae: 9.260 - ETA: 7:52 - loss: 131.6007 - mae: 9.337 - ETA: 7:47 - loss: 132.0140 - mae: 9.314 - ETA: 7:42 - loss: 133.8552 - mae: 9.413 - ETA: 7:37 - loss: 135.8118 - mae: 9.503 - ETA: 7:35 - loss: 136.6935 - mae: 9.512 - ETA: 7:32 - loss: 136.1599 - mae: 9.488 - ETA: 7:28 - loss: 136.0503 - mae: 9.464 - ETA: 7:22 - loss: 135.1873 - mae: 9.433 - ETA: 7:18 - loss: 135.0089 - mae: 9.458 - ETA: 7:13 - loss: 134.9469 - mae: 9.435 - ETA: 7:07 - loss: 134.7382 - mae: 9.447 - ETA: 7:02 - loss: 133.2387 - mae: 9.413 - ETA: 6:58 - loss: 132.3173 - mae: 9.371 - ETA: 6:55 - loss: 132.5111 - mae: 9.377 - ETA: 6:51 - loss: 132.0772 - mae: 9.354 - ETA: 6:47 - loss: 132.7121 - mae: 9.387 - ETA: 6:46 - loss: 131.6356 - mae: 9.360 - ETA: 6:44 - loss: 131.8703 - mae: 9.372 - ETA: 6:47 - loss: 132.3438 - mae: 9.361 - ETA: 6:54 - loss: 132.2509 - mae: 9.362 - ETA: 6:56 - loss: 131.0548 - mae: 9.324 - ETA: 6:53 - loss: 130.7849 - mae: 9.301 - ETA: 6:48 - loss: 132.1656 - mae: 9.340 - ETA: 6:42 - loss: 131.2556 - mae: 9.314 - ETA: 6:37 - loss: 131.0478 - mae: 9.289 - ETA: 6:31 - loss: 130.1436 - mae: 9.265 - ETA: 6:25 - loss: 129.3969 - mae: 9.240 - ETA: 6:19 - loss: 129.3009 - mae: 9.219 - ETA: 6:13 - loss: 128.5550 - mae: 9.187 - ETA: 6:07 - loss: 127.5632 - mae: 9.149 - ETA: 6:02 - loss: 127.9933 - mae: 9.159 - ETA: 5:56 - loss: 127.8556 - mae: 9.159 - ETA: 5:52 - loss: 127.4978 - mae: 9.135 - ETA: 5:47 - loss: 127.6561 - mae: 9.139 - ETA: 5:43 - loss: 127.0232 - mae: 9.111 - ETA: 5:38 - loss: 126.5381 - mae: 9.097 - ETA: 5:37 - loss: 126.2643 - mae: 9.083 - ETA: 5:39 - loss: 126.0971 - mae: 9.074 - ETA: 5:48 - loss: 126.9557 - mae: 9.109 - ETA: 5:48 - loss: 126.8170 - mae: 9.117 - ETA: 5:45 - loss: 126.4707 - mae: 9.104 - ETA: 5:42 - loss: 126.5012 - mae: 9.100 - ETA: 5:38 - loss: 126.9050 - mae: 9.116 - ETA: 5:33 - loss: 126.2732 - mae: 9.093 - ETA: 5:28 - loss: 125.4970 - mae: 9.068 - ETA: 5:23 - loss: 124.5563 - mae: 9.028 - ETA: 5:17 - loss: 124.8023 - mae: 9.036 - ETA: 5:13 - loss: 124.5184 - mae: 9.018 - ETA: 5:10 - loss: 124.5487 - mae: 9.025 - ETA: 5:06 - loss: 123.9918 - mae: 9.011 - ETA: 5:09 - loss: 123.5195 - mae: 8.976 - ETA: 5:06 - loss: 123.6250 - mae: 8.976 - ETA: 5:01 - loss: 123.5155 - mae: 8.981 - ETA: 4:55 - loss: 123.0563 - mae: 8.971 - ETA: 4:49 - loss: 123.6019 - mae: 8.988 - ETA: 4:43 - loss: 123.1263 - mae: 8.966 - ETA: 4:37 - loss: 123.3035 - mae: 8.968 - ETA: 4:31 - loss: 123.0977 - mae: 8.969 - ETA: 4:26 - loss: 123.2388 - mae: 8.969 - ETA: 4:21 - loss: 122.8314 - mae: 8.957 - ETA: 4:16 - loss: 122.3307 - mae: 8.941 - ETA: 4:12 - loss: 122.0984 - mae: 8.933 - ETA: 4:08 - loss: 121.7761 - mae: 8.922 - ETA: 4:03 - loss: 121.9593 - mae: 8.930 - ETA: 3:57 - loss: 122.2338 - mae: 8.938 - ETA: 3:51 - loss: 122.0657 - mae: 8.937 - ETA: 3:45 - loss: 121.8715 - mae: 8.928 - ETA: 3:39 - loss: 122.5400 - mae: 8.951 - ETA: 3:32 - loss: 121.9728 - mae: 8.934 - ETA: 3:26 - loss: 121.5895 - mae: 8.923 - ETA: 3:20 - loss: 122.2953 - mae: 8.951 - ETA: 3:14 - loss: 121.9041 - mae: 8.935 - ETA: 3:08 - loss: 121.8347 - mae: 8.936 - ETA: 3:02 - loss: 121.9541 - mae: 8.944 - ETA: 2:58 - loss: 122.1225 - mae: 8.942 - ETA: 2:54 - loss: 121.7416 - mae: 8.932 - ETA: 2:50 - loss: 121.6882 - mae: 8.928 - ETA: 2:45 - loss: 121.7431 - mae: 8.922 - ETA: 2:39 - loss: 121.3625 - mae: 8.906 - ETA: 2:34 - loss: 121.7105 - mae: 8.928 - ETA: 2:27 - loss: 121.5055 - mae: 8.923 - ETA: 2:21 - loss: 121.4100 - mae: 8.923 - ETA: 2:15 - loss: 121.4573 - mae: 8.925 - ETA: 2:08 - loss: 121.1201 - mae: 8.918 - ETA: 2:02 - loss: 121.0023 - mae: 8.916 - ETA: 1:56 - loss: 120.8680 - mae: 8.910 - ETA: 1:50 - loss: 121.0074 - mae: 8.919 - ETA: 1:44 - loss: 121.0877 - mae: 8.926 - ETA: 1:38 - loss: 120.9780 - mae: 8.921 - ETA: 1:33 - loss: 120.8553 - mae: 8.914 - ETA: 1:27 - loss: 120.5683 - mae: 8.907 - ETA: 1:21 - loss: 120.6417 - mae: 8.903 - ETA: 1:14 - loss: 120.8107 - mae: 8.908 - ETA: 1:08 - loss: 120.7049 - mae: 8.905 - ETA: 1:02 - loss: 120.7890 - mae: 8.915 - ETA: 55s - loss: 120.5865 - mae: 8.908 - ETA: 49s - loss: 120.8631 - mae: 8.91 - ETA: 43s - loss: 120.8505 - mae: 8.91 - ETA: 37s - loss: 121.1045 - mae: 8.92 - ETA: 30s - loss: 120.9375 - mae: 8.92 - ETA: 24s - loss: 120.5555 - mae: 8.90 - ETA: 18s - loss: 120.2049 - mae: 8.89 - ETA: 12s - loss: 120.3778 - mae: 8.90 - ETA: 6s - loss: 120.3476 - mae: 8.9081 - ETA: 0s - loss: 120.0632 - mae: 8.893 - 902s 7s/step - loss: 120.0632 - mae: 8.8931 - val_loss: 105.2245 - val_mae: 8.1156\n",
      "\n",
      "Epoch 00031: saving model to CP_ResNet50_Sample100_Fine50_Fine\\cp-0031.ckpt\n",
      "Epoch 32/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - ETA: 10:26 - loss: 66.3776 - mae: 6.875 - ETA: 12:00 - loss: 73.9316 - mae: 6.961 - ETA: 11:22 - loss: 85.7529 - mae: 7.460 - ETA: 11:33 - loss: 97.5927 - mae: 7.761 - ETA: 12:16 - loss: 99.3921 - mae: 7.821 - ETA: 14:32 - loss: 105.3472 - mae: 8.14 - ETA: 16:35 - loss: 103.5773 - mae: 8.02 - ETA: 16:42 - loss: 106.2209 - mae: 8.24 - ETA: 16:01 - loss: 105.0271 - mae: 8.23 - ETA: 15:22 - loss: 104.4491 - mae: 8.25 - ETA: 14:47 - loss: 103.0205 - mae: 8.18 - ETA: 14:23 - loss: 107.0994 - mae: 8.36 - ETA: 13:59 - loss: 104.5689 - mae: 8.25 - ETA: 13:37 - loss: 105.8230 - mae: 8.28 - ETA: 13:35 - loss: 107.3378 - mae: 8.35 - ETA: 13:37 - loss: 105.1181 - mae: 8.28 - ETA: 13:56 - loss: 109.6358 - mae: 8.43 - ETA: 14:25 - loss: 110.2462 - mae: 8.46 - ETA: 14:37 - loss: 109.4825 - mae: 8.40 - ETA: 14:42 - loss: 108.7612 - mae: 8.36 - ETA: 14:35 - loss: 108.9925 - mae: 8.40 - ETA: 14:20 - loss: 109.3232 - mae: 8.40 - ETA: 14:03 - loss: 108.3421 - mae: 8.35 - ETA: 13:51 - loss: 106.1069 - mae: 8.26 - ETA: 13:38 - loss: 105.4958 - mae: 8.24 - ETA: 13:36 - loss: 106.2205 - mae: 8.29 - ETA: 13:54 - loss: 107.7450 - mae: 8.34 - ETA: 14:00 - loss: 108.6327 - mae: 8.39 - ETA: 13:51 - loss: 108.4142 - mae: 8.36 - ETA: 13:35 - loss: 107.9478 - mae: 8.34 - ETA: 13:20 - loss: 106.9719 - mae: 8.31 - ETA: 13:03 - loss: 106.0896 - mae: 8.26 - ETA: 12:45 - loss: 106.3724 - mae: 8.26 - ETA: 12:28 - loss: 106.0078 - mae: 8.22 - ETA: 12:11 - loss: 107.3492 - mae: 8.27 - ETA: 11:57 - loss: 106.6639 - mae: 8.24 - ETA: 11:43 - loss: 106.6290 - mae: 8.25 - ETA: 11:33 - loss: 107.3781 - mae: 8.30 - ETA: 11:31 - loss: 107.9642 - mae: 8.32 - ETA: 11:33 - loss: 106.9864 - mae: 8.28 - ETA: 11:27 - loss: 108.1087 - mae: 8.31 - ETA: 11:17 - loss: 107.6537 - mae: 8.30 - ETA: 11:05 - loss: 107.3752 - mae: 8.29 - ETA: 10:53 - loss: 107.0776 - mae: 8.28 - ETA: 10:41 - loss: 107.1537 - mae: 8.27 - ETA: 10:27 - loss: 106.9416 - mae: 8.26 - ETA: 10:14 - loss: 107.0921 - mae: 8.26 - ETA: 10:01 - loss: 107.4690 - mae: 8.27 - ETA: 9:49 - loss: 107.1046 - mae: 8.2472 - ETA: 9:38 - loss: 106.4308 - mae: 8.214 - ETA: 9:32 - loss: 105.9914 - mae: 8.202 - ETA: 9:39 - loss: 105.5184 - mae: 8.192 - ETA: 9:37 - loss: 105.2590 - mae: 8.189 - ETA: 9:29 - loss: 105.4442 - mae: 8.188 - ETA: 9:19 - loss: 105.8288 - mae: 8.215 - ETA: 9:08 - loss: 105.3638 - mae: 8.195 - ETA: 8:57 - loss: 105.0146 - mae: 8.181 - ETA: 8:45 - loss: 104.9223 - mae: 8.166 - ETA: 8:34 - loss: 104.3592 - mae: 8.136 - ETA: 8:23 - loss: 104.7877 - mae: 8.137 - ETA: 8:12 - loss: 104.3256 - mae: 8.113 - ETA: 8:01 - loss: 104.0904 - mae: 8.105 - ETA: 7:50 - loss: 103.8156 - mae: 8.090 - ETA: 7:40 - loss: 103.5864 - mae: 8.083 - ETA: 7:32 - loss: 103.8796 - mae: 8.102 - ETA: 7:23 - loss: 104.1258 - mae: 8.114 - ETA: 7:16 - loss: 104.1512 - mae: 8.126 - ETA: 7:10 - loss: 103.9982 - mae: 8.122 - ETA: 7:07 - loss: 103.8502 - mae: 8.124 - ETA: 7:01 - loss: 104.1756 - mae: 8.140 - ETA: 6:52 - loss: 103.8672 - mae: 8.122 - ETA: 6:43 - loss: 103.6260 - mae: 8.106 - ETA: 6:34 - loss: 103.1358 - mae: 8.082 - ETA: 6:24 - loss: 103.6506 - mae: 8.113 - ETA: 6:15 - loss: 104.4641 - mae: 8.146 - ETA: 6:05 - loss: 104.1062 - mae: 8.132 - ETA: 5:56 - loss: 103.8179 - mae: 8.127 - ETA: 5:47 - loss: 104.4211 - mae: 8.146 - ETA: 5:38 - loss: 104.0882 - mae: 8.134 - ETA: 5:30 - loss: 104.4707 - mae: 8.147 - ETA: 5:23 - loss: 104.3277 - mae: 8.142 - ETA: 5:15 - loss: 104.7501 - mae: 8.157 - ETA: 5:08 - loss: 104.8954 - mae: 8.169 - ETA: 5:02 - loss: 104.9876 - mae: 8.169 - ETA: 4:54 - loss: 105.0770 - mae: 8.173 - ETA: 4:46 - loss: 105.6537 - mae: 8.198 - ETA: 4:38 - loss: 105.3773 - mae: 8.193 - ETA: 4:30 - loss: 105.4529 - mae: 8.198 - ETA: 4:22 - loss: 105.3607 - mae: 8.202 - ETA: 4:14 - loss: 105.0170 - mae: 8.184 - ETA: 4:05 - loss: 105.5815 - mae: 8.203 - ETA: 3:57 - loss: 105.6172 - mae: 8.211 - ETA: 3:49 - loss: 105.3876 - mae: 8.206 - ETA: 3:41 - loss: 105.6685 - mae: 8.215 - ETA: 3:34 - loss: 105.8703 - mae: 8.221 - ETA: 3:26 - loss: 105.3063 - mae: 8.199 - ETA: 3:19 - loss: 105.2988 - mae: 8.196 - ETA: 3:13 - loss: 105.6139 - mae: 8.211 - ETA: 3:06 - loss: 105.8007 - mae: 8.223 - ETA: 3:00 - loss: 105.9155 - mae: 8.235 - ETA: 2:52 - loss: 105.7061 - mae: 8.229 - ETA: 2:45 - loss: 105.8227 - mae: 8.237 - ETA: 2:37 - loss: 105.7899 - mae: 8.238 - ETA: 2:30 - loss: 105.4454 - mae: 8.221 - ETA: 2:23 - loss: 105.0862 - mae: 8.207 - ETA: 2:16 - loss: 105.2347 - mae: 8.219 - ETA: 2:09 - loss: 104.8582 - mae: 8.207 - ETA: 2:02 - loss: 104.5142 - mae: 8.194 - ETA: 1:55 - loss: 104.3434 - mae: 8.183 - ETA: 1:49 - loss: 104.7192 - mae: 8.197 - ETA: 1:42 - loss: 104.6224 - mae: 8.195 - ETA: 1:35 - loss: 104.8150 - mae: 8.206 - ETA: 1:27 - loss: 104.9184 - mae: 8.214 - ETA: 1:20 - loss: 104.6188 - mae: 8.204 - ETA: 1:12 - loss: 104.7275 - mae: 8.209 - ETA: 1:05 - loss: 104.8681 - mae: 8.220 - ETA: 58s - loss: 104.9795 - mae: 8.227 - ETA: 50s - loss: 104.9810 - mae: 8.23 - ETA: 43s - loss: 105.0315 - mae: 8.22 - ETA: 36s - loss: 104.9306 - mae: 8.22 - ETA: 28s - loss: 104.9829 - mae: 8.22 - ETA: 21s - loss: 104.6318 - mae: 8.21 - ETA: 14s - loss: 104.8214 - mae: 8.22 - ETA: 7s - loss: 104.7217 - mae: 8.2293 - ETA: 0s - loss: 104.5169 - mae: 8.222 - 1028s 8s/step - loss: 104.5169 - mae: 8.2228 - val_loss: 103.9994 - val_mae: 8.0481\n",
      "\n",
      "Epoch 00032: saving model to CP_ResNet50_Sample100_Fine50_Fine\\cp-0032.ckpt\n",
      "Epoch 33/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - ETA: 12:51 - loss: 156.9714 - mae: 9.53 - ETA: 12:50 - loss: 132.0297 - mae: 9.11 - ETA: 14:46 - loss: 124.0870 - mae: 8.89 - ETA: 16:58 - loss: 125.6752 - mae: 8.84 - ETA: 18:38 - loss: 114.5259 - mae: 8.48 - ETA: 19:08 - loss: 107.9291 - mae: 8.22 - ETA: 18:00 - loss: 103.8371 - mae: 7.99 - ETA: 16:52 - loss: 100.7892 - mae: 7.92 - ETA: 16:00 - loss: 97.5193 - mae: 7.8419 - ETA: 15:11 - loss: 98.9502 - mae: 7.900 - ETA: 14:39 - loss: 97.3118 - mae: 7.828 - ETA: 14:05 - loss: 99.7913 - mae: 7.945 - ETA: 13:42 - loss: 97.8862 - mae: 7.882 - ETA: 13:26 - loss: 98.6943 - mae: 7.901 - ETA: 13:22 - loss: 101.1324 - mae: 7.99 - ETA: 13:22 - loss: 99.5522 - mae: 7.9734 - ETA: 14:04 - loss: 101.1073 - mae: 8.03 - ETA: 14:43 - loss: 101.5411 - mae: 8.05 - ETA: 14:31 - loss: 102.7044 - mae: 8.08 - ETA: 14:13 - loss: 101.6091 - mae: 8.04 - ETA: 13:54 - loss: 103.1544 - mae: 8.06 - ETA: 13:32 - loss: 101.9657 - mae: 8.00 - ETA: 13:11 - loss: 101.6619 - mae: 8.00 - ETA: 12:58 - loss: 104.5956 - mae: 8.10 - ETA: 12:49 - loss: 105.5705 - mae: 8.16 - ETA: 12:46 - loss: 104.9823 - mae: 8.14 - ETA: 12:40 - loss: 104.5405 - mae: 8.13 - ETA: 12:41 - loss: 103.3444 - mae: 8.08 - ETA: 12:41 - loss: 103.0315 - mae: 8.07 - ETA: 12:34 - loss: 105.1311 - mae: 8.10 - ETA: 12:25 - loss: 103.4826 - mae: 8.03 - ETA: 12:10 - loss: 103.4292 - mae: 8.05 - ETA: 11:55 - loss: 103.3272 - mae: 8.07 - ETA: 11:44 - loss: 104.5685 - mae: 8.14 - ETA: 11:32 - loss: 104.3714 - mae: 8.13 - ETA: 11:22 - loss: 103.5456 - mae: 8.08 - ETA: 11:13 - loss: 103.1556 - mae: 8.06 - ETA: 11:10 - loss: 102.7840 - mae: 8.05 - ETA: 11:17 - loss: 102.5386 - mae: 8.04 - ETA: 11:25 - loss: 102.9369 - mae: 8.07 - ETA: 11:21 - loss: 103.2235 - mae: 8.09 - ETA: 11:13 - loss: 102.8346 - mae: 8.06 - ETA: 11:03 - loss: 102.8731 - mae: 8.07 - ETA: 10:51 - loss: 103.2963 - mae: 8.08 - ETA: 10:39 - loss: 103.6276 - mae: 8.09 - ETA: 10:29 - loss: 103.3234 - mae: 8.07 - ETA: 10:20 - loss: 103.3684 - mae: 8.07 - ETA: 10:17 - loss: 104.2640 - mae: 8.10 - ETA: 10:21 - loss: 103.2200 - mae: 8.06 - ETA: 10:22 - loss: 102.5965 - mae: 8.03 - ETA: 10:16 - loss: 102.5338 - mae: 8.03 - ETA: 10:09 - loss: 102.6817 - mae: 8.04 - ETA: 10:03 - loss: 102.4643 - mae: 8.04 - ETA: 10:00 - loss: 101.8813 - mae: 8.02 - ETA: 10:02 - loss: 102.0314 - mae: 8.01 - ETA: 10:03 - loss: 101.5999 - mae: 7.99 - ETA: 9:55 - loss: 100.8490 - mae: 7.9682 - ETA: 9:45 - loss: 100.3768 - mae: 7.952 - ETA: 9:34 - loss: 99.8559 - mae: 7.925 - ETA: 9:22 - loss: 98.8871 - mae: 7.88 - ETA: 9:12 - loss: 98.6858 - mae: 7.87 - ETA: 9:02 - loss: 98.5787 - mae: 7.87 - ETA: 8:53 - loss: 98.1031 - mae: 7.86 - ETA: 8:47 - loss: 98.3962 - mae: 7.86 - ETA: 8:40 - loss: 98.5810 - mae: 7.87 - ETA: 8:30 - loss: 98.2813 - mae: 7.86 - ETA: 8:19 - loss: 98.2079 - mae: 7.86 - ETA: 8:09 - loss: 97.6677 - mae: 7.84 - ETA: 7:57 - loss: 97.3902 - mae: 7.83 - ETA: 7:46 - loss: 97.2541 - mae: 7.83 - ETA: 7:35 - loss: 97.1306 - mae: 7.83 - ETA: 7:24 - loss: 98.2375 - mae: 7.86 - ETA: 7:14 - loss: 98.6363 - mae: 7.88 - ETA: 7:05 - loss: 98.4656 - mae: 7.87 - ETA: 6:57 - loss: 98.7244 - mae: 7.88 - ETA: 6:51 - loss: 98.7430 - mae: 7.88 - ETA: 6:43 - loss: 98.5501 - mae: 7.88 - ETA: 6:36 - loss: 98.7179 - mae: 7.89 - ETA: 6:29 - loss: 98.8307 - mae: 7.90 - ETA: 6:19 - loss: 98.5990 - mae: 7.90 - ETA: 6:10 - loss: 98.7095 - mae: 7.90 - ETA: 6:00 - loss: 98.9467 - mae: 7.92 - ETA: 5:53 - loss: 98.9284 - mae: 7.92 - ETA: 5:46 - loss: 98.7611 - mae: 7.92 - ETA: 5:38 - loss: 98.6130 - mae: 7.91 - ETA: 5:29 - loss: 98.9382 - mae: 7.91 - ETA: 5:20 - loss: 98.8478 - mae: 7.91 - ETA: 5:10 - loss: 98.6191 - mae: 7.90 - ETA: 5:01 - loss: 99.0499 - mae: 7.91 - ETA: 4:52 - loss: 99.0583 - mae: 7.91 - ETA: 4:42 - loss: 99.2581 - mae: 7.92 - ETA: 4:33 - loss: 98.8974 - mae: 7.91 - ETA: 4:25 - loss: 99.3312 - mae: 7.93 - ETA: 4:18 - loss: 99.8185 - mae: 7.95 - ETA: 4:12 - loss: 99.5607 - mae: 7.94 - ETA: 4:05 - loss: 99.5813 - mae: 7.94 - ETA: 3:56 - loss: 99.1225 - mae: 7.92 - ETA: 3:47 - loss: 99.0299 - mae: 7.92 - ETA: 3:38 - loss: 99.2201 - mae: 7.93 - ETA: 3:29 - loss: 99.3225 - mae: 7.94 - ETA: 3:20 - loss: 99.2427 - mae: 7.93 - ETA: 3:10 - loss: 99.3699 - mae: 7.94 - ETA: 3:02 - loss: 99.2113 - mae: 7.94 - ETA: 2:53 - loss: 98.9872 - mae: 7.93 - ETA: 2:46 - loss: 98.5322 - mae: 7.91 - ETA: 2:39 - loss: 98.2277 - mae: 7.89 - ETA: 2:31 - loss: 98.2780 - mae: 7.89 - ETA: 2:23 - loss: 98.4101 - mae: 7.90 - ETA: 2:14 - loss: 98.3674 - mae: 7.91 - ETA: 2:06 - loss: 98.1073 - mae: 7.90 - ETA: 1:57 - loss: 98.2388 - mae: 7.90 - ETA: 1:48 - loss: 98.2695 - mae: 7.90 - ETA: 1:40 - loss: 98.1281 - mae: 7.90 - ETA: 1:32 - loss: 98.0616 - mae: 7.90 - ETA: 1:24 - loss: 98.3815 - mae: 7.91 - ETA: 1:15 - loss: 98.5151 - mae: 7.92 - ETA: 1:07 - loss: 98.3888 - mae: 7.92 - ETA: 58s - loss: 98.5171 - mae: 7.9236 - ETA: 50s - loss: 98.3605 - mae: 7.918 - ETA: 41s - loss: 98.4861 - mae: 7.930 - ETA: 33s - loss: 98.5334 - mae: 7.937 - ETA: 24s - loss: 98.3003 - mae: 7.926 - ETA: 16s - loss: 98.0354 - mae: 7.914 - ETA: 8s - loss: 97.8296 - mae: 7.903 - ETA: 0s - loss: 98.1663 - mae: 7.91 - 1187s 10s/step - loss: 98.1663 - mae: 7.9115 - val_loss: 106.6427 - val_mae: 8.1432\n",
      "\n",
      "Epoch 00033: saving model to CP_ResNet50_Sample100_Fine50_Fine\\cp-0033.ckpt\n",
      "Epoch 34/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - ETA: 12:49 - loss: 68.9477 - mae: 6.514 - ETA: 14:26 - loss: 70.2583 - mae: 6.435 - ETA: 16:40 - loss: 86.5087 - mae: 7.149 - ETA: 18:50 - loss: 89.8603 - mae: 7.515 - ETA: 18:27 - loss: 95.7406 - mae: 7.790 - ETA: 17:31 - loss: 100.5326 - mae: 8.01 - ETA: 16:54 - loss: 95.8813 - mae: 7.8333 - ETA: 15:59 - loss: 95.0128 - mae: 7.766 - ETA: 15:06 - loss: 94.0146 - mae: 7.717 - ETA: 14:25 - loss: 93.6573 - mae: 7.720 - ETA: 13:51 - loss: 90.7904 - mae: 7.564 - ETA: 13:31 - loss: 91.0345 - mae: 7.638 - ETA: 13:12 - loss: 94.5682 - mae: 7.731 - ETA: 13:01 - loss: 94.0311 - mae: 7.736 - ETA: 12:57 - loss: 93.0407 - mae: 7.673 - ETA: 13:08 - loss: 90.7442 - mae: 7.563 - ETA: 14:12 - loss: 89.6996 - mae: 7.518 - ETA: 14:26 - loss: 90.2114 - mae: 7.550 - ETA: 14:22 - loss: 89.1308 - mae: 7.492 - ETA: 14:06 - loss: 88.7446 - mae: 7.449 - ETA: 13:50 - loss: 88.3759 - mae: 7.431 - ETA: 13:29 - loss: 89.5631 - mae: 7.442 - ETA: 13:08 - loss: 89.7277 - mae: 7.450 - ETA: 12:50 - loss: 90.6338 - mae: 7.481 - ETA: 12:35 - loss: 91.0236 - mae: 7.520 - ETA: 12:28 - loss: 91.6991 - mae: 7.539 - ETA: 12:26 - loss: 91.8200 - mae: 7.553 - ETA: 12:38 - loss: 92.0869 - mae: 7.577 - ETA: 12:39 - loss: 91.2088 - mae: 7.552 - ETA: 12:28 - loss: 90.4833 - mae: 7.527 - ETA: 12:14 - loss: 90.9561 - mae: 7.575 - ETA: 11:59 - loss: 90.4830 - mae: 7.548 - ETA: 11:43 - loss: 90.1289 - mae: 7.526 - ETA: 11:28 - loss: 90.9177 - mae: 7.555 - ETA: 11:14 - loss: 90.2843 - mae: 7.530 - ETA: 11:01 - loss: 89.5300 - mae: 7.510 - ETA: 10:49 - loss: 89.8407 - mae: 7.531 - ETA: 10:38 - loss: 90.0360 - mae: 7.539 - ETA: 10:28 - loss: 90.6349 - mae: 7.562 - ETA: 10:20 - loss: 91.8910 - mae: 7.595 - ETA: 10:18 - loss: 91.4897 - mae: 7.577 - ETA: 10:19 - loss: 91.8178 - mae: 7.592 - ETA: 10:16 - loss: 92.2040 - mae: 7.619 - ETA: 10:09 - loss: 91.9544 - mae: 7.619 - ETA: 10:01 - loss: 91.6455 - mae: 7.624 - ETA: 9:50 - loss: 92.3765 - mae: 7.661 - ETA: 9:39 - loss: 92.0666 - mae: 7.64 - ETA: 9:27 - loss: 91.0733 - mae: 7.61 - ETA: 9:16 - loss: 90.9488 - mae: 7.60 - ETA: 9:05 - loss: 92.0598 - mae: 7.64 - ETA: 8:54 - loss: 92.0419 - mae: 7.65 - ETA: 8:45 - loss: 92.1922 - mae: 7.66 - ETA: 8:36 - loss: 92.3825 - mae: 7.67 - ETA: 8:29 - loss: 93.5939 - mae: 7.71 - ETA: 8:23 - loss: 92.8268 - mae: 7.67 - ETA: 8:20 - loss: 91.9306 - mae: 7.64 - ETA: 8:17 - loss: 91.4241 - mae: 7.61 - ETA: 8:10 - loss: 91.4783 - mae: 7.62 - ETA: 8:02 - loss: 91.2824 - mae: 7.61 - ETA: 7:52 - loss: 91.0622 - mae: 7.58 - ETA: 7:43 - loss: 91.4757 - mae: 7.61 - ETA: 7:34 - loss: 91.4491 - mae: 7.61 - ETA: 7:24 - loss: 91.4245 - mae: 7.60 - ETA: 7:15 - loss: 91.3205 - mae: 7.60 - ETA: 7:05 - loss: 90.8995 - mae: 7.59 - ETA: 6:57 - loss: 90.9633 - mae: 7.60 - ETA: 6:51 - loss: 90.6643 - mae: 7.58 - ETA: 6:47 - loss: 90.4607 - mae: 7.57 - ETA: 6:46 - loss: 90.5498 - mae: 7.58 - ETA: 6:42 - loss: 90.5772 - mae: 7.57 - ETA: 6:36 - loss: 90.5853 - mae: 7.58 - ETA: 6:29 - loss: 90.3196 - mae: 7.57 - ETA: 6:21 - loss: 90.2466 - mae: 7.56 - ETA: 6:13 - loss: 90.6711 - mae: 7.58 - ETA: 6:04 - loss: 90.7329 - mae: 7.57 - ETA: 5:55 - loss: 90.4241 - mae: 7.56 - ETA: 5:46 - loss: 90.3304 - mae: 7.56 - ETA: 5:38 - loss: 90.2293 - mae: 7.56 - ETA: 5:29 - loss: 90.4256 - mae: 7.57 - ETA: 5:21 - loss: 89.9439 - mae: 7.55 - ETA: 5:14 - loss: 89.7775 - mae: 7.54 - ETA: 5:07 - loss: 89.6134 - mae: 7.53 - ETA: 5:04 - loss: 89.6877 - mae: 7.53 - ETA: 5:00 - loss: 89.7557 - mae: 7.53 - ETA: 4:53 - loss: 89.5922 - mae: 7.53 - ETA: 4:45 - loss: 89.4320 - mae: 7.53 - ETA: 4:38 - loss: 89.2604 - mae: 7.52 - ETA: 4:29 - loss: 89.7517 - mae: 7.54 - ETA: 4:21 - loss: 89.5660 - mae: 7.54 - ETA: 4:13 - loss: 89.7038 - mae: 7.54 - ETA: 4:05 - loss: 90.0330 - mae: 7.56 - ETA: 3:57 - loss: 89.7751 - mae: 7.55 - ETA: 3:49 - loss: 90.5014 - mae: 7.57 - ETA: 3:41 - loss: 90.9284 - mae: 7.59 - ETA: 3:33 - loss: 90.7879 - mae: 7.58 - ETA: 3:27 - loss: 90.5632 - mae: 7.57 - ETA: 3:20 - loss: 90.3424 - mae: 7.56 - ETA: 3:14 - loss: 90.4556 - mae: 7.57 - ETA: 3:07 - loss: 90.9728 - mae: 7.59 - ETA: 3:00 - loss: 91.3080 - mae: 7.61 - ETA: 2:52 - loss: 91.4530 - mae: 7.61 - ETA: 2:44 - loss: 91.5433 - mae: 7.62 - ETA: 2:37 - loss: 91.7684 - mae: 7.63 - ETA: 2:29 - loss: 91.5085 - mae: 7.62 - ETA: 2:22 - loss: 91.3370 - mae: 7.62 - ETA: 2:15 - loss: 91.2240 - mae: 7.61 - ETA: 2:08 - loss: 91.0415 - mae: 7.61 - ETA: 2:00 - loss: 91.1105 - mae: 7.61 - ETA: 1:54 - loss: 90.9487 - mae: 7.61 - ETA: 1:47 - loss: 90.6861 - mae: 7.60 - ETA: 1:40 - loss: 90.7152 - mae: 7.60 - ETA: 1:33 - loss: 90.8025 - mae: 7.60 - ETA: 1:26 - loss: 90.7183 - mae: 7.60 - ETA: 1:18 - loss: 90.3733 - mae: 7.59 - ETA: 1:11 - loss: 90.1797 - mae: 7.58 - ETA: 1:04 - loss: 90.0491 - mae: 7.58 - ETA: 56s - loss: 89.9464 - mae: 7.5832 - ETA: 49s - loss: 90.0215 - mae: 7.589 - ETA: 42s - loss: 90.0510 - mae: 7.592 - ETA: 35s - loss: 89.9254 - mae: 7.585 - ETA: 28s - loss: 89.6130 - mae: 7.572 - ETA: 21s - loss: 89.7252 - mae: 7.580 - ETA: 14s - loss: 89.6892 - mae: 7.582 - ETA: 7s - loss: 89.6771 - mae: 7.580 - ETA: 0s - loss: 89.8148 - mae: 7.59 - 1014s 8s/step - loss: 89.8148 - mae: 7.5926 - val_loss: 119.7342 - val_mae: 8.6841\n",
      "\n",
      "Epoch 00034: saving model to CP_ResNet50_Sample100_Fine50_Fine\\cp-0034.ckpt\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00034: early stopping\n"
     ]
    }
   ],
   "source": [
    "fine_tune_epochs = 10\n",
    "total_epochs =  30 + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(train_ds,\n",
    "                         epochs=total_epochs,\n",
    "                         initial_epoch=30,\n",
    "                         validation_data=val_ds,\n",
    "                         callbacks=[cp_callback_for_fine, es_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [120.06315612792969,\n",
       "  104.51685333251953,\n",
       "  98.16634368896484,\n",
       "  89.81478881835938],\n",
       " 'mae': [8.89305591583252,\n",
       "  8.222777366638184,\n",
       "  7.911494731903076,\n",
       "  7.592556953430176],\n",
       " 'val_loss': [105.22453308105469,\n",
       "  103.9993667602539,\n",
       "  106.64266204833984,\n",
       "  119.73419189453125],\n",
       " 'val_mae': [8.115606307983398,\n",
       "  8.048077583312988,\n",
       "  8.143150329589844,\n",
       "  8.684100151062012]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_fine.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제로 True값과 Predicted값을 비교해보기 위한 코드. val_ds에서 3개만 가져와서 해봄\n",
    "i = 1\n",
    "image_batch_list = []\n",
    "label_batch_list = []\n",
    "for image_batch, label_batch in val_ds:\n",
    "    image_batch_list.append(image_batch)\n",
    "    label_batch_list.append(label_batch)\n",
    "    i+=1\n",
    "    if i == 4: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    true       pred       diff\n",
      "0     67  62.848686   4.151314\n",
      "1     24  29.857414  -5.857414\n",
      "2     27  30.166740  -3.166740\n",
      "3     54  51.914112   2.085888\n",
      "4     67  64.855240   2.144760\n",
      "5     42  42.038483  -0.038483\n",
      "6     42  39.390419   2.609581\n",
      "7     35  34.643768   0.356232\n",
      "8     59  59.714088  -0.714088\n",
      "9     60  53.406387   6.593613\n",
      "10    31  39.895622  -8.895622\n",
      "11    41  46.874939  -5.874939\n",
      "12    59  65.135986  -6.135986\n",
      "13    53  43.248108   9.751892\n",
      "14    64  55.482067   8.517933\n",
      "15    39  31.647432   7.352568\n",
      "16    61  60.492321   0.507679\n",
      "17    44  49.813332  -5.813332\n",
      "18    57  53.320782   3.679218\n",
      "19    59  43.217003  15.782997\n",
      "20    62  59.662350   2.337650\n",
      "21    20  30.911236 -10.911236\n",
      "22    32  31.541950   0.458050\n",
      "23    41  40.276566   0.723434\n",
      "24    64  60.911404   3.088596\n",
      "25    58  56.143112   1.856888\n",
      "26    49  49.176201  -0.176201\n",
      "27    23  30.518116  -7.518116\n",
      "28    48  53.442665  -5.442665\n",
      "29    37  43.752548  -6.752548\n",
      "30    55  52.241684   2.758316\n",
      "31    26  45.601505 -19.601505\n",
      "    true       pred       diff\n",
      "0     19  30.773964 -11.773964\n",
      "1     52  57.887558  -5.887558\n",
      "2     42  42.236748  -0.236748\n",
      "3     50  58.923645  -8.923645\n",
      "4     52  40.422760  11.577240\n",
      "5     53  58.364891  -5.364891\n",
      "6     36  47.966133 -11.966133\n",
      "7     33  39.143192  -6.143192\n",
      "8     20  37.390579 -17.390579\n",
      "9     61  49.146782  11.853218\n",
      "10    37  54.891232 -17.891232\n",
      "11    53  56.795567  -3.795567\n",
      "12    29  39.088478 -10.088478\n",
      "13    40  44.723160  -4.723160\n",
      "14    37  45.255669  -8.255669\n",
      "15    37  34.484253   2.515747\n",
      "16    19  44.933701 -25.933701\n",
      "17    28  41.642494 -13.642494\n",
      "18    56  54.232594   1.767406\n",
      "19    65  65.975029  -0.975029\n",
      "20    58  56.419930   1.580070\n",
      "21    37  39.309223  -2.309223\n",
      "22    24  41.831085 -17.831085\n",
      "23    26  31.185966  -5.185966\n",
      "24    34  39.140503  -5.140503\n",
      "25    23  40.044991 -17.044991\n",
      "26    63  41.681683  21.318317\n",
      "27    60  65.004440  -5.004440\n",
      "28    31  32.499245  -1.499245\n",
      "29    50  37.953728  12.046272\n",
      "30    21  32.484283 -11.484283\n",
      "31    46  61.757046 -15.757046\n",
      "    true       pred       diff\n",
      "0     34  38.345345  -4.345345\n",
      "1     68  56.461918  11.538082\n",
      "2     58  59.177269  -1.177269\n",
      "3     25  37.943535 -12.943535\n",
      "4     49  47.702473   1.297527\n",
      "5     67  46.813782  20.186218\n",
      "6     47  44.919937   2.080063\n",
      "7     30  35.995155  -5.995155\n",
      "8     26  40.679199 -14.679199\n",
      "9     31  41.211803 -10.211803\n",
      "10    20  35.498970 -15.498970\n",
      "11    50  42.631882   7.368118\n",
      "12    33  52.835659 -19.835659\n",
      "13    18  24.720030  -6.720030\n",
      "14    55  43.470108  11.529892\n",
      "15    59  38.885704  20.114296\n",
      "16    34  44.493729 -10.493729\n",
      "17    57  26.989113  30.010887\n",
      "18    35  37.464249  -2.464249\n",
      "19    66  59.637600   6.362400\n",
      "20    52  58.067844  -6.067844\n",
      "21    23  25.345142  -2.345142\n",
      "22    33  30.426613   2.573387\n",
      "23    50  47.151199   2.848801\n",
      "24    63  43.289413  19.710587\n",
      "25    40  48.538857  -8.538857\n",
      "26    52  47.610073   4.389927\n",
      "27    43  45.543018  -2.543018\n",
      "28    66  52.829670  13.170330\n",
      "29    66  54.407139  11.592861\n",
      "30    26  31.805828  -5.805828\n",
      "31    46  46.629227  -0.629227\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "for image_batch, label_batch in zip(image_batch_list, label_batch_list):\n",
    "    predicted_labels = model.predict(image_batch)\n",
    "    df = pd.DataFrame({'true':np.array(label_batch).reshape(-1,), \n",
    "                       'pred':predicted_labels.reshape(-1,)})\n",
    "    df = df + 18\n",
    "    df['diff'] = df['true']-df['pred']\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_loss = history.history['loss']+history_fine.history['loss']\n",
    "all_val_loss = history.history['val_loss']+history_fine.history['val_loss']\n",
    "all_mae = history.history['mae']+history_fine.history['mae']\n",
    "all_val_mae = history.history['val_mae']+history_fine.history['val_mae']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "\n",
    "plt.subplot(1, 2 ,1)\n",
    "plt.title('mse')\n",
    "plt.plot(all_loss, label='loss')\n",
    "plt.plot(all_val_loss, label='val_loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('mae')\n",
    "plt.plot(all_mae, label='mae')\n",
    "plt.plot(all_val_mae, label='val_mae')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('mae')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
